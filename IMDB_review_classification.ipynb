{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB review classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9lsRVgpr4lEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GOsxiyf6v9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "Source: http://ai.stanford.edu/~amaas/data/sentiment/index.html \\\\\n",
        "Description: \\\\\n",
        "The core dataset contains 50,000 reviews split evenly into 25k train\n",
        "and 25k test sets. The overall distribution of labels is balanced (25k\n",
        "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
        "documents for unsupervised learning. \n",
        "\n",
        "In the entire collection, no more than 30 reviews are allowed for any\n",
        "given movie because reviews for the same movie tend to have correlated\n",
        "ratings. Further, the train and test sets contain a disjoint set of\n",
        "movies, so no significant performance is obtained by memorizing\n",
        "movie-unique terms and their associated with observed labels.  In the\n",
        "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
        "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
        "more neutral ratings are not included in the train/test sets. In the\n",
        "unsupervised set, reviews of any rating are included and there are an\n",
        "even number of reviews > 5 and <= 5.\n"
      ]
    },
    {
      "metadata": {
        "id": "rWyNIHqYgldf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from keras import layers as L\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "#I used TweetTokenizer, because it includes some non-word tokens that may occur in reviews and may be sentiment markers (i. e., ':-)')\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X9uND-G1mW3Q",
        "colab_type": "code",
        "outputId": "dd1771f9-f822-48c2-9fed-5da931dd5c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vyhuholl/imdb_review_classification.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'imdb_review_classification' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mHK4O8Q2HdOM",
        "colab_type": "code",
        "outputId": "a1ab3613-0a14-48dc-c023-f4d975640cc6",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f274dabe-3ebb-49f1-9a3f-d92ad017de15\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f274dabe-3ebb-49f1-9a3f-d92ad017de15\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving embeddings.zip to embeddings (1).zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bDYFXagflfns",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "zUV0d7YjhviO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = 'imdb_review_classification/data/'\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "for file in os.listdir(PATH + 'train/pos'):\n",
        "  rating = int(re.match('\\d*_(\\d*)', file).group(1))\n",
        "  with open(PATH + 'train/pos/' + file) as text:\n",
        "    review = text.read()\n",
        "    X_train.append(review)\n",
        "    y_train.append(rating)\n",
        "for file in os.listdir(PATH + 'train/neg'):\n",
        "  rating = int(re.match('\\d*_(\\d*)', file).group(1))\n",
        "  with open(PATH + 'train/neg/' + file) as text:\n",
        "    review = text.read()\n",
        "    X_train.append(review)\n",
        "    y_train.append(rating)\n",
        "for file in os.listdir(PATH + 'test/pos'):\n",
        "  rating = int(re.match('\\d*_(\\d*)', file).group(1))\n",
        "  with open(PATH + 'test/pos/' + file) as text:\n",
        "    review = text.read()\n",
        "    X_test.append(review)\n",
        "    y_test.append(rating)\n",
        "for file in os.listdir(PATH + 'test/neg'):\n",
        "  rating = int(re.match('\\d*_(\\d*)', file).group(1))\n",
        "  with open(PATH + 'test/neg/' + file) as text:\n",
        "    review = text.read()\n",
        "    X_test.append(review)\n",
        "    y_test.append(rating)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LiVHbIPSeBIX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_sequence(text, vocab, vocab_size):\n",
        "  seq = []\n",
        "  for token in text:\n",
        "    if token in vocab:\n",
        "      seq.append(vocab[token])\n",
        "    else:\n",
        "      seq.append(vocab_size)\n",
        "  return seq\n",
        "\n",
        "#превращаем метки класса в one-hot векторы\n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit([1, 2, 3, 4, 7, 8, 9, 10])\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)\n",
        "#токенизируем и векторизуем\n",
        "tokenizer = TweetTokenizer()\n",
        "training_corpus = ' '.join(map(str, X_train))\n",
        "tokens = set(tokenizer.tokenize(training_corpus))\n",
        "#для чистоты эксперимента обучать токенайзер будем только на обучающей выборке\n",
        "vocab_size = len(tokens) + 1\n",
        "vocab = {word: index for index, word in dict(enumerate(tokens, start=1)).items()}\n",
        "#не удаляла стоп-слова, т. к., некоторые стоп-слова (например, отрицания) указывают на sentiment\n",
        "\n",
        "#нейросеть, обученная на текстах, полученных с помощью texts_to_matrix(mode='tfidf'), давала очень низкую accuracy (около 0.2), поэтому я решила использовать text_to_sequences\n",
        "X_train = [text_to_sequence(tokenizer.tokenize(text), vocab, vocab_size) for text in X_train]\n",
        "X_test = [text_to_sequence(tokenizer.tokenize(text), vocab, vocab_size) for text in X_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1aeiXAdnOl7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# padding sequences to len 100\n",
        "X_train = pad_sequences(X_train, maxlen=100, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=100, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bs7CuPIRim6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training simple neural network"
      ]
    },
    {
      "metadata": {
        "id": "ZegQdKRFi34E",
        "colab_type": "code",
        "outputId": "f19377b8-f2e3-4b46-a341-6a32888e9262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34425
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(L.Dense(512, input_shape=(100,)))\n",
        "model.add(L.Activation('sigmoid'))\n",
        "model.add(L.BatchNormalization())\n",
        "model.add(L.Dense(256))\n",
        "model.add(L.Activation('relu'))\n",
        "model.add(L.BatchNormalization())\n",
        "model.add(L.Dense(8))\n",
        "model.add(L.Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=1000,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               51712     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 2056      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 188,168\n",
            "Trainable params: 186,632\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n",
            "Train on 22500 samples, validate on 2500 samples\n",
            "Epoch 1/1000\n",
            "22500/22500 [==============================] - 3s 123us/step - loss: 2.3105 - acc: 0.1563 - val_loss: 2.5257 - val_acc: 0.0460\n",
            "Epoch 2/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 2.0848 - acc: 0.1950 - val_loss: 2.2545 - val_acc: 0.1888\n",
            "Epoch 3/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 2.0172 - acc: 0.2144 - val_loss: 2.2410 - val_acc: 0.1268\n",
            "Epoch 4/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.9905 - acc: 0.2250 - val_loss: 2.2088 - val_acc: 0.1252\n",
            "Epoch 5/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.9602 - acc: 0.2357 - val_loss: 2.3000 - val_acc: 0.1560\n",
            "Epoch 6/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.9309 - acc: 0.2535 - val_loss: 2.3618 - val_acc: 0.2104\n",
            "Epoch 7/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.8959 - acc: 0.2677 - val_loss: 2.3651 - val_acc: 0.1788\n",
            "Epoch 8/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.8579 - acc: 0.2843 - val_loss: 2.4328 - val_acc: 0.1024\n",
            "Epoch 9/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.8199 - acc: 0.3030 - val_loss: 2.4884 - val_acc: 0.1080\n",
            "Epoch 10/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.7723 - acc: 0.3267 - val_loss: 2.5838 - val_acc: 0.1880\n",
            "Epoch 11/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.7368 - acc: 0.3394 - val_loss: 2.6207 - val_acc: 0.1192\n",
            "Epoch 12/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.6952 - acc: 0.3577 - val_loss: 2.7807 - val_acc: 0.1904\n",
            "Epoch 13/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.6668 - acc: 0.3704 - val_loss: 2.8248 - val_acc: 0.0944\n",
            "Epoch 14/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.6291 - acc: 0.3869 - val_loss: 2.9066 - val_acc: 0.0964\n",
            "Epoch 15/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.5948 - acc: 0.3987 - val_loss: 2.9671 - val_acc: 0.0908\n",
            "Epoch 16/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.5686 - acc: 0.4097 - val_loss: 3.0643 - val_acc: 0.1028\n",
            "Epoch 17/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.5511 - acc: 0.4170 - val_loss: 3.0281 - val_acc: 0.1148\n",
            "Epoch 18/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.5192 - acc: 0.4271 - val_loss: 3.1626 - val_acc: 0.0940\n",
            "Epoch 19/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.4947 - acc: 0.4394 - val_loss: 3.1848 - val_acc: 0.0900\n",
            "Epoch 20/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.4838 - acc: 0.4417 - val_loss: 3.2482 - val_acc: 0.0948\n",
            "Epoch 21/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.4643 - acc: 0.4495 - val_loss: 3.2864 - val_acc: 0.1020\n",
            "Epoch 22/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.4523 - acc: 0.4529 - val_loss: 3.3842 - val_acc: 0.1116\n",
            "Epoch 23/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.4391 - acc: 0.4584 - val_loss: 3.3346 - val_acc: 0.1000\n",
            "Epoch 24/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.4272 - acc: 0.4628 - val_loss: 3.3769 - val_acc: 0.1916\n",
            "Epoch 25/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.4194 - acc: 0.4645 - val_loss: 3.4964 - val_acc: 0.1720\n",
            "Epoch 26/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.4048 - acc: 0.4729 - val_loss: 3.4148 - val_acc: 0.1084\n",
            "Epoch 27/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.3967 - acc: 0.4700 - val_loss: 3.4621 - val_acc: 0.1064\n",
            "Epoch 28/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3923 - acc: 0.4746 - val_loss: 3.4737 - val_acc: 0.1196\n",
            "Epoch 29/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3804 - acc: 0.4831 - val_loss: 3.5655 - val_acc: 0.0840\n",
            "Epoch 30/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3712 - acc: 0.4826 - val_loss: 3.6857 - val_acc: 0.0804\n",
            "Epoch 31/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3674 - acc: 0.4864 - val_loss: 3.6186 - val_acc: 0.0980\n",
            "Epoch 32/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.3639 - acc: 0.4883 - val_loss: 3.5307 - val_acc: 0.1180\n",
            "Epoch 33/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.3579 - acc: 0.4874 - val_loss: 3.6510 - val_acc: 0.1752\n",
            "Epoch 34/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3482 - acc: 0.4927 - val_loss: 3.5891 - val_acc: 0.1892\n",
            "Epoch 35/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3530 - acc: 0.4917 - val_loss: 3.6358 - val_acc: 0.0960\n",
            "Epoch 36/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3423 - acc: 0.4978 - val_loss: 3.7143 - val_acc: 0.0880\n",
            "Epoch 37/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.3381 - acc: 0.4967 - val_loss: 3.6357 - val_acc: 0.1844\n",
            "Epoch 38/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3346 - acc: 0.4981 - val_loss: 3.6877 - val_acc: 0.0956\n",
            "Epoch 39/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3302 - acc: 0.4996 - val_loss: 3.7142 - val_acc: 0.1072\n",
            "Epoch 40/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3309 - acc: 0.4966 - val_loss: 3.8149 - val_acc: 0.1804\n",
            "Epoch 41/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.3197 - acc: 0.5022 - val_loss: 3.6975 - val_acc: 0.1964\n",
            "Epoch 42/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3225 - acc: 0.5033 - val_loss: 3.8516 - val_acc: 0.1712\n",
            "Epoch 43/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3203 - acc: 0.5021 - val_loss: 3.7632 - val_acc: 0.0976\n",
            "Epoch 44/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3133 - acc: 0.5040 - val_loss: 3.8308 - val_acc: 0.0896\n",
            "Epoch 45/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.3062 - acc: 0.5058 - val_loss: 3.8911 - val_acc: 0.0888\n",
            "Epoch 46/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3084 - acc: 0.5046 - val_loss: 3.7362 - val_acc: 0.1004\n",
            "Epoch 47/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3067 - acc: 0.5087 - val_loss: 3.8723 - val_acc: 0.0844\n",
            "Epoch 48/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.3026 - acc: 0.5076 - val_loss: 3.9215 - val_acc: 0.1708\n",
            "Epoch 49/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.3009 - acc: 0.5107 - val_loss: 3.8449 - val_acc: 0.0996\n",
            "Epoch 50/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2995 - acc: 0.5063 - val_loss: 3.9415 - val_acc: 0.0864\n",
            "Epoch 51/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2926 - acc: 0.5111 - val_loss: 3.8813 - val_acc: 0.0884\n",
            "Epoch 52/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2946 - acc: 0.5098 - val_loss: 4.0111 - val_acc: 0.0684\n",
            "Epoch 53/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2897 - acc: 0.5147 - val_loss: 3.8630 - val_acc: 0.1060\n",
            "Epoch 54/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2897 - acc: 0.5099 - val_loss: 3.9403 - val_acc: 0.1792\n",
            "Epoch 55/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2929 - acc: 0.5120 - val_loss: 3.9741 - val_acc: 0.0968\n",
            "Epoch 56/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2854 - acc: 0.5134 - val_loss: 3.8562 - val_acc: 0.1064\n",
            "Epoch 57/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2831 - acc: 0.5125 - val_loss: 3.8599 - val_acc: 0.0852\n",
            "Epoch 58/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2774 - acc: 0.5148 - val_loss: 3.8564 - val_acc: 0.0992\n",
            "Epoch 59/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2879 - acc: 0.5146 - val_loss: 3.7605 - val_acc: 0.1260\n",
            "Epoch 60/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2804 - acc: 0.5169 - val_loss: 3.9743 - val_acc: 0.0936\n",
            "Epoch 61/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2803 - acc: 0.5177 - val_loss: 3.9049 - val_acc: 0.1064\n",
            "Epoch 62/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2790 - acc: 0.5180 - val_loss: 3.8844 - val_acc: 0.1092\n",
            "Epoch 63/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2706 - acc: 0.5199 - val_loss: 3.8897 - val_acc: 0.0984\n",
            "Epoch 64/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2748 - acc: 0.5211 - val_loss: 3.9845 - val_acc: 0.1788\n",
            "Epoch 65/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2771 - acc: 0.5184 - val_loss: 3.9542 - val_acc: 0.0976\n",
            "Epoch 66/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2712 - acc: 0.5196 - val_loss: 3.9768 - val_acc: 0.1796\n",
            "Epoch 67/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2685 - acc: 0.5203 - val_loss: 3.9764 - val_acc: 0.0976\n",
            "Epoch 68/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2590 - acc: 0.5228 - val_loss: 3.9064 - val_acc: 0.1020\n",
            "Epoch 69/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2671 - acc: 0.5209 - val_loss: 3.9275 - val_acc: 0.1816\n",
            "Epoch 70/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2675 - acc: 0.5221 - val_loss: 3.8958 - val_acc: 0.0912\n",
            "Epoch 71/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2590 - acc: 0.5236 - val_loss: 3.9424 - val_acc: 0.1004\n",
            "Epoch 72/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2617 - acc: 0.5229 - val_loss: 3.9385 - val_acc: 0.0840\n",
            "Epoch 73/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2609 - acc: 0.5227 - val_loss: 3.9988 - val_acc: 0.0868\n",
            "Epoch 74/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.2629 - acc: 0.5233 - val_loss: 3.9186 - val_acc: 0.1892\n",
            "Epoch 75/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.2584 - acc: 0.5240 - val_loss: 3.9253 - val_acc: 0.1176\n",
            "Epoch 76/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.2585 - acc: 0.5233 - val_loss: 4.0122 - val_acc: 0.0864\n",
            "Epoch 77/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2554 - acc: 0.5249 - val_loss: 3.9453 - val_acc: 0.1172\n",
            "Epoch 78/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2645 - acc: 0.5197 - val_loss: 3.9179 - val_acc: 0.1112\n",
            "Epoch 79/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2578 - acc: 0.5234 - val_loss: 3.9684 - val_acc: 0.0952\n",
            "Epoch 80/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2561 - acc: 0.5217 - val_loss: 3.8921 - val_acc: 0.1064\n",
            "Epoch 81/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2555 - acc: 0.5217 - val_loss: 3.8978 - val_acc: 0.0980\n",
            "Epoch 82/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2526 - acc: 0.5249 - val_loss: 3.9326 - val_acc: 0.0964\n",
            "Epoch 83/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2494 - acc: 0.5233 - val_loss: 3.9314 - val_acc: 0.0880\n",
            "Epoch 84/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2478 - acc: 0.5250 - val_loss: 4.0529 - val_acc: 0.0872\n",
            "Epoch 85/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2457 - acc: 0.5261 - val_loss: 3.9321 - val_acc: 0.1768\n",
            "Epoch 86/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2478 - acc: 0.5254 - val_loss: 3.9114 - val_acc: 0.1064\n",
            "Epoch 87/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.2503 - acc: 0.5279 - val_loss: 3.9949 - val_acc: 0.1860\n",
            "Epoch 88/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2466 - acc: 0.5254 - val_loss: 3.8738 - val_acc: 0.1164\n",
            "Epoch 89/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2487 - acc: 0.5269 - val_loss: 3.9335 - val_acc: 0.0936\n",
            "Epoch 90/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2461 - acc: 0.5284 - val_loss: 3.9849 - val_acc: 0.1812\n",
            "Epoch 91/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2533 - acc: 0.5256 - val_loss: 3.9852 - val_acc: 0.0936\n",
            "Epoch 92/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2523 - acc: 0.5220 - val_loss: 3.8764 - val_acc: 0.1064\n",
            "Epoch 93/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2453 - acc: 0.5247 - val_loss: 4.0858 - val_acc: 0.0832\n",
            "Epoch 94/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.2472 - acc: 0.5272 - val_loss: 4.0321 - val_acc: 0.0840\n",
            "Epoch 95/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2419 - acc: 0.5288 - val_loss: 4.0239 - val_acc: 0.1876\n",
            "Epoch 96/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2418 - acc: 0.5292 - val_loss: 4.0038 - val_acc: 0.1084\n",
            "Epoch 97/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2482 - acc: 0.5262 - val_loss: 3.9966 - val_acc: 0.1744\n",
            "Epoch 98/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2376 - acc: 0.5322 - val_loss: 4.0057 - val_acc: 0.0952\n",
            "Epoch 99/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2414 - acc: 0.5300 - val_loss: 3.9282 - val_acc: 0.1020\n",
            "Epoch 100/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2406 - acc: 0.5286 - val_loss: 4.0030 - val_acc: 0.0940\n",
            "Epoch 101/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2365 - acc: 0.5302 - val_loss: 4.0481 - val_acc: 0.0984\n",
            "Epoch 102/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2421 - acc: 0.5244 - val_loss: 4.0403 - val_acc: 0.1092\n",
            "Epoch 103/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2363 - acc: 0.5301 - val_loss: 3.9711 - val_acc: 0.1140\n",
            "Epoch 104/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2334 - acc: 0.5297 - val_loss: 3.9821 - val_acc: 0.1900\n",
            "Epoch 105/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2323 - acc: 0.5283 - val_loss: 4.0662 - val_acc: 0.1764\n",
            "Epoch 106/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2318 - acc: 0.5280 - val_loss: 4.0554 - val_acc: 0.0872\n",
            "Epoch 107/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2338 - acc: 0.5328 - val_loss: 4.0912 - val_acc: 0.0864\n",
            "Epoch 108/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2404 - acc: 0.5281 - val_loss: 4.0186 - val_acc: 0.2044\n",
            "Epoch 109/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2298 - acc: 0.5320 - val_loss: 3.9759 - val_acc: 0.1156\n",
            "Epoch 110/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2303 - acc: 0.5344 - val_loss: 4.0980 - val_acc: 0.1004\n",
            "Epoch 111/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2312 - acc: 0.5340 - val_loss: 4.0275 - val_acc: 0.0980\n",
            "Epoch 112/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2291 - acc: 0.5327 - val_loss: 3.9719 - val_acc: 0.1248\n",
            "Epoch 113/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2344 - acc: 0.5291 - val_loss: 3.9918 - val_acc: 0.0884\n",
            "Epoch 114/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2324 - acc: 0.5319 - val_loss: 3.8987 - val_acc: 0.1176\n",
            "Epoch 115/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2285 - acc: 0.5328 - val_loss: 4.0589 - val_acc: 0.1048\n",
            "Epoch 116/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2282 - acc: 0.5288 - val_loss: 4.0408 - val_acc: 0.1020\n",
            "Epoch 117/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2275 - acc: 0.5301 - val_loss: 4.1339 - val_acc: 0.0824\n",
            "Epoch 118/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2319 - acc: 0.5303 - val_loss: 3.9847 - val_acc: 0.1076\n",
            "Epoch 119/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2253 - acc: 0.5346 - val_loss: 4.0710 - val_acc: 0.1040\n",
            "Epoch 120/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2285 - acc: 0.5319 - val_loss: 4.0597 - val_acc: 0.0916\n",
            "Epoch 121/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2268 - acc: 0.5310 - val_loss: 4.0657 - val_acc: 0.1124\n",
            "Epoch 122/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2289 - acc: 0.5306 - val_loss: 4.0162 - val_acc: 0.1100\n",
            "Epoch 123/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2286 - acc: 0.5341 - val_loss: 4.0097 - val_acc: 0.1076\n",
            "Epoch 124/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2290 - acc: 0.5324 - val_loss: 4.1483 - val_acc: 0.0796\n",
            "Epoch 125/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2219 - acc: 0.5345 - val_loss: 4.0782 - val_acc: 0.0892\n",
            "Epoch 126/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2236 - acc: 0.5344 - val_loss: 4.0439 - val_acc: 0.1152\n",
            "Epoch 127/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2254 - acc: 0.5325 - val_loss: 3.9590 - val_acc: 0.1052\n",
            "Epoch 128/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2215 - acc: 0.5333 - val_loss: 4.0481 - val_acc: 0.1020\n",
            "Epoch 129/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2208 - acc: 0.5333 - val_loss: 4.0984 - val_acc: 0.1916\n",
            "Epoch 130/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2236 - acc: 0.5313 - val_loss: 4.0352 - val_acc: 0.1144\n",
            "Epoch 131/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2302 - acc: 0.5309 - val_loss: 4.0435 - val_acc: 0.1008\n",
            "Epoch 132/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.2203 - acc: 0.5343 - val_loss: 4.0546 - val_acc: 0.1920\n",
            "Epoch 133/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2225 - acc: 0.5332 - val_loss: 4.0735 - val_acc: 0.0964\n",
            "Epoch 134/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2214 - acc: 0.5357 - val_loss: 3.9840 - val_acc: 0.0940\n",
            "Epoch 135/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2237 - acc: 0.5339 - val_loss: 4.0615 - val_acc: 0.0988\n",
            "Epoch 136/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2230 - acc: 0.5316 - val_loss: 4.1302 - val_acc: 0.0872\n",
            "Epoch 137/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2204 - acc: 0.5328 - val_loss: 4.1234 - val_acc: 0.0848\n",
            "Epoch 138/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2240 - acc: 0.5331 - val_loss: 4.0794 - val_acc: 0.1012\n",
            "Epoch 139/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2233 - acc: 0.5353 - val_loss: 4.0309 - val_acc: 0.1112\n",
            "Epoch 140/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2195 - acc: 0.5339 - val_loss: 3.9607 - val_acc: 0.1208\n",
            "Epoch 141/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2191 - acc: 0.5353 - val_loss: 4.0397 - val_acc: 0.1080\n",
            "Epoch 142/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2199 - acc: 0.5327 - val_loss: 4.1080 - val_acc: 0.1216\n",
            "Epoch 143/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2162 - acc: 0.5384 - val_loss: 4.0805 - val_acc: 0.1064\n",
            "Epoch 144/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2167 - acc: 0.5347 - val_loss: 4.0491 - val_acc: 0.1120\n",
            "Epoch 145/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2105 - acc: 0.5390 - val_loss: 4.0236 - val_acc: 0.1076\n",
            "Epoch 146/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2207 - acc: 0.5347 - val_loss: 4.0262 - val_acc: 0.1088\n",
            "Epoch 147/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2133 - acc: 0.5363 - val_loss: 4.0296 - val_acc: 0.1072\n",
            "Epoch 148/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2140 - acc: 0.5377 - val_loss: 4.1725 - val_acc: 0.0896\n",
            "Epoch 149/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2170 - acc: 0.5391 - val_loss: 4.0205 - val_acc: 0.1188\n",
            "Epoch 150/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2164 - acc: 0.5343 - val_loss: 4.0468 - val_acc: 0.0980\n",
            "Epoch 151/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2150 - acc: 0.5387 - val_loss: 4.0137 - val_acc: 0.1048\n",
            "Epoch 152/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2126 - acc: 0.5377 - val_loss: 4.0378 - val_acc: 0.0984\n",
            "Epoch 153/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2115 - acc: 0.5365 - val_loss: 4.0838 - val_acc: 0.0996\n",
            "Epoch 154/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2099 - acc: 0.5394 - val_loss: 4.0672 - val_acc: 0.1860\n",
            "Epoch 155/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2109 - acc: 0.5360 - val_loss: 4.1406 - val_acc: 0.0824\n",
            "Epoch 156/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2116 - acc: 0.5371 - val_loss: 4.0324 - val_acc: 0.2040\n",
            "Epoch 157/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2156 - acc: 0.5370 - val_loss: 4.0817 - val_acc: 0.1860\n",
            "Epoch 158/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2095 - acc: 0.5386 - val_loss: 4.0929 - val_acc: 0.1040\n",
            "Epoch 159/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2152 - acc: 0.5355 - val_loss: 4.0804 - val_acc: 0.1040\n",
            "Epoch 160/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2089 - acc: 0.5395 - val_loss: 4.0464 - val_acc: 0.1040\n",
            "Epoch 161/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2114 - acc: 0.5387 - val_loss: 4.0787 - val_acc: 0.1800\n",
            "Epoch 162/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2046 - acc: 0.5404 - val_loss: 4.0460 - val_acc: 0.1076\n",
            "Epoch 163/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2132 - acc: 0.5358 - val_loss: 4.0515 - val_acc: 0.1128\n",
            "Epoch 164/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2115 - acc: 0.5361 - val_loss: 4.0188 - val_acc: 0.1104\n",
            "Epoch 165/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2128 - acc: 0.5352 - val_loss: 4.0525 - val_acc: 0.1008\n",
            "Epoch 166/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2060 - acc: 0.5390 - val_loss: 4.1010 - val_acc: 0.1884\n",
            "Epoch 167/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2082 - acc: 0.5393 - val_loss: 4.1260 - val_acc: 0.0892\n",
            "Epoch 168/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2085 - acc: 0.5383 - val_loss: 4.1072 - val_acc: 0.1756\n",
            "Epoch 169/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2080 - acc: 0.5347 - val_loss: 4.0454 - val_acc: 0.1072\n",
            "Epoch 170/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2079 - acc: 0.5359 - val_loss: 4.0939 - val_acc: 0.1040\n",
            "Epoch 171/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2125 - acc: 0.5370 - val_loss: 4.1355 - val_acc: 0.1872\n",
            "Epoch 172/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2001 - acc: 0.5365 - val_loss: 4.1452 - val_acc: 0.0980\n",
            "Epoch 173/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2029 - acc: 0.5367 - val_loss: 4.0496 - val_acc: 0.1128\n",
            "Epoch 174/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2094 - acc: 0.5367 - val_loss: 4.1809 - val_acc: 0.0928\n",
            "Epoch 175/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1980 - acc: 0.5402 - val_loss: 4.1179 - val_acc: 0.1868\n",
            "Epoch 176/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2094 - acc: 0.5364 - val_loss: 4.0724 - val_acc: 0.1144\n",
            "Epoch 177/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.2089 - acc: 0.5403 - val_loss: 4.1114 - val_acc: 0.0952\n",
            "Epoch 178/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.2039 - acc: 0.5386 - val_loss: 4.0019 - val_acc: 0.1200\n",
            "Epoch 179/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2064 - acc: 0.5393 - val_loss: 4.0305 - val_acc: 0.1156\n",
            "Epoch 180/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2049 - acc: 0.5390 - val_loss: 4.0592 - val_acc: 0.1036\n",
            "Epoch 181/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2087 - acc: 0.5373 - val_loss: 4.0924 - val_acc: 0.1036\n",
            "Epoch 182/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2032 - acc: 0.5386 - val_loss: 4.0855 - val_acc: 0.0972\n",
            "Epoch 183/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2059 - acc: 0.5400 - val_loss: 4.0630 - val_acc: 0.0868\n",
            "Epoch 184/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2022 - acc: 0.5399 - val_loss: 4.0587 - val_acc: 0.1972\n",
            "Epoch 185/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2067 - acc: 0.5358 - val_loss: 4.0936 - val_acc: 0.0928\n",
            "Epoch 186/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2062 - acc: 0.5373 - val_loss: 4.1161 - val_acc: 0.0940\n",
            "Epoch 187/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2068 - acc: 0.5364 - val_loss: 4.1067 - val_acc: 0.1016\n",
            "Epoch 188/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2018 - acc: 0.5386 - val_loss: 4.1032 - val_acc: 0.1088\n",
            "Epoch 189/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2032 - acc: 0.5391 - val_loss: 4.0550 - val_acc: 0.1192\n",
            "Epoch 190/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1986 - acc: 0.5402 - val_loss: 4.0924 - val_acc: 0.1012\n",
            "Epoch 191/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2086 - acc: 0.5400 - val_loss: 4.1933 - val_acc: 0.1792\n",
            "Epoch 192/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2000 - acc: 0.5400 - val_loss: 4.1158 - val_acc: 0.0992\n",
            "Epoch 193/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1995 - acc: 0.5406 - val_loss: 4.0386 - val_acc: 0.1272\n",
            "Epoch 194/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2028 - acc: 0.5414 - val_loss: 4.1079 - val_acc: 0.1908\n",
            "Epoch 195/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2017 - acc: 0.5391 - val_loss: 4.0485 - val_acc: 0.2016\n",
            "Epoch 196/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.2060 - acc: 0.5370 - val_loss: 4.0624 - val_acc: 0.1960\n",
            "Epoch 197/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2031 - acc: 0.5410 - val_loss: 4.2044 - val_acc: 0.0928\n",
            "Epoch 198/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2023 - acc: 0.5394 - val_loss: 4.0868 - val_acc: 0.1164\n",
            "Epoch 199/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.2017 - acc: 0.5406 - val_loss: 4.0786 - val_acc: 0.1056\n",
            "Epoch 200/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1983 - acc: 0.5397 - val_loss: 4.1497 - val_acc: 0.1864\n",
            "Epoch 201/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1971 - acc: 0.5420 - val_loss: 4.1048 - val_acc: 0.1860\n",
            "Epoch 202/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1980 - acc: 0.5397 - val_loss: 4.1543 - val_acc: 0.0884\n",
            "Epoch 203/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2011 - acc: 0.5398 - val_loss: 4.0860 - val_acc: 0.1056\n",
            "Epoch 204/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2002 - acc: 0.5385 - val_loss: 4.1005 - val_acc: 0.1024\n",
            "Epoch 205/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2011 - acc: 0.5400 - val_loss: 4.1622 - val_acc: 0.1924\n",
            "Epoch 206/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2006 - acc: 0.5390 - val_loss: 4.0484 - val_acc: 0.1080\n",
            "Epoch 207/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1982 - acc: 0.5411 - val_loss: 4.1503 - val_acc: 0.1900\n",
            "Epoch 208/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1975 - acc: 0.5426 - val_loss: 4.1558 - val_acc: 0.0964\n",
            "Epoch 209/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1916 - acc: 0.5437 - val_loss: 4.1404 - val_acc: 0.1812\n",
            "Epoch 210/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1932 - acc: 0.5427 - val_loss: 4.1612 - val_acc: 0.0996\n",
            "Epoch 211/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1979 - acc: 0.5426 - val_loss: 4.1204 - val_acc: 0.1088\n",
            "Epoch 212/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1988 - acc: 0.5410 - val_loss: 4.1778 - val_acc: 0.0956\n",
            "Epoch 213/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1934 - acc: 0.5414 - val_loss: 4.1560 - val_acc: 0.1856\n",
            "Epoch 214/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1933 - acc: 0.5443 - val_loss: 4.2334 - val_acc: 0.0912\n",
            "Epoch 215/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1951 - acc: 0.5423 - val_loss: 4.1008 - val_acc: 0.1972\n",
            "Epoch 216/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1952 - acc: 0.5399 - val_loss: 4.2029 - val_acc: 0.1852\n",
            "Epoch 217/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1926 - acc: 0.5429 - val_loss: 4.2224 - val_acc: 0.0900\n",
            "Epoch 218/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1933 - acc: 0.5440 - val_loss: 4.1739 - val_acc: 0.1868\n",
            "Epoch 219/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.2011 - acc: 0.5382 - val_loss: 4.1559 - val_acc: 0.1052\n",
            "Epoch 220/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1918 - acc: 0.5425 - val_loss: 4.1349 - val_acc: 0.1048\n",
            "Epoch 221/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1946 - acc: 0.5419 - val_loss: 4.2230 - val_acc: 0.0912\n",
            "Epoch 222/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1939 - acc: 0.5411 - val_loss: 4.1992 - val_acc: 0.1940\n",
            "Epoch 223/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1962 - acc: 0.5424 - val_loss: 4.1997 - val_acc: 0.1036\n",
            "Epoch 224/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1974 - acc: 0.5428 - val_loss: 4.1706 - val_acc: 0.0992\n",
            "Epoch 225/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1976 - acc: 0.5402 - val_loss: 4.2024 - val_acc: 0.0948\n",
            "Epoch 226/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1906 - acc: 0.5434 - val_loss: 4.0985 - val_acc: 0.1176\n",
            "Epoch 227/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1957 - acc: 0.5428 - val_loss: 4.1330 - val_acc: 0.2100\n",
            "Epoch 228/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1946 - acc: 0.5405 - val_loss: 4.1657 - val_acc: 0.1060\n",
            "Epoch 229/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1934 - acc: 0.5417 - val_loss: 4.1369 - val_acc: 0.1916\n",
            "Epoch 230/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1878 - acc: 0.5458 - val_loss: 4.1413 - val_acc: 0.1084\n",
            "Epoch 231/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1972 - acc: 0.5438 - val_loss: 4.1790 - val_acc: 0.1016\n",
            "Epoch 232/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1936 - acc: 0.5433 - val_loss: 4.1809 - val_acc: 0.1100\n",
            "Epoch 233/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1907 - acc: 0.5437 - val_loss: 4.1709 - val_acc: 0.1088\n",
            "Epoch 234/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1908 - acc: 0.5400 - val_loss: 4.2330 - val_acc: 0.0948\n",
            "Epoch 235/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1926 - acc: 0.5421 - val_loss: 4.2105 - val_acc: 0.0944\n",
            "Epoch 236/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1893 - acc: 0.5424 - val_loss: 4.1756 - val_acc: 0.1028\n",
            "Epoch 237/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1868 - acc: 0.5416 - val_loss: 4.1322 - val_acc: 0.1236\n",
            "Epoch 238/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1895 - acc: 0.5416 - val_loss: 4.2276 - val_acc: 0.1880\n",
            "Epoch 239/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1953 - acc: 0.5435 - val_loss: 4.1695 - val_acc: 0.1044\n",
            "Epoch 240/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1915 - acc: 0.5398 - val_loss: 4.2985 - val_acc: 0.0944\n",
            "Epoch 241/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1925 - acc: 0.5426 - val_loss: 4.2128 - val_acc: 0.0940\n",
            "Epoch 242/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1892 - acc: 0.5427 - val_loss: 4.1627 - val_acc: 0.1024\n",
            "Epoch 243/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1943 - acc: 0.5399 - val_loss: 4.1863 - val_acc: 0.1056\n",
            "Epoch 244/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1936 - acc: 0.5403 - val_loss: 4.2140 - val_acc: 0.0932\n",
            "Epoch 245/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1917 - acc: 0.5416 - val_loss: 4.1560 - val_acc: 0.1152\n",
            "Epoch 246/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1933 - acc: 0.5420 - val_loss: 4.1771 - val_acc: 0.0960\n",
            "Epoch 247/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1892 - acc: 0.5421 - val_loss: 4.2022 - val_acc: 0.0980\n",
            "Epoch 248/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1853 - acc: 0.5453 - val_loss: 4.1738 - val_acc: 0.1000\n",
            "Epoch 249/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1927 - acc: 0.5418 - val_loss: 4.1878 - val_acc: 0.1056\n",
            "Epoch 250/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1886 - acc: 0.5403 - val_loss: 4.2047 - val_acc: 0.0984\n",
            "Epoch 251/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1891 - acc: 0.5426 - val_loss: 4.1943 - val_acc: 0.1940\n",
            "Epoch 252/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1865 - acc: 0.5440 - val_loss: 4.1935 - val_acc: 0.1032\n",
            "Epoch 253/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1913 - acc: 0.5440 - val_loss: 4.1774 - val_acc: 0.1904\n",
            "Epoch 254/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1900 - acc: 0.5447 - val_loss: 4.2298 - val_acc: 0.0936\n",
            "Epoch 255/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1891 - acc: 0.5435 - val_loss: 4.1521 - val_acc: 0.1056\n",
            "Epoch 256/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1903 - acc: 0.5420 - val_loss: 4.0914 - val_acc: 0.1240\n",
            "Epoch 257/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1915 - acc: 0.5404 - val_loss: 4.0965 - val_acc: 0.1072\n",
            "Epoch 258/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1862 - acc: 0.5419 - val_loss: 4.2192 - val_acc: 0.0960\n",
            "Epoch 259/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1892 - acc: 0.5384 - val_loss: 4.2364 - val_acc: 0.0872\n",
            "Epoch 260/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1870 - acc: 0.5459 - val_loss: 4.0925 - val_acc: 0.1144\n",
            "Epoch 261/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1891 - acc: 0.5427 - val_loss: 4.1132 - val_acc: 0.1204\n",
            "Epoch 262/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1905 - acc: 0.5423 - val_loss: 4.1826 - val_acc: 0.0968\n",
            "Epoch 263/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1860 - acc: 0.5434 - val_loss: 4.2909 - val_acc: 0.1692\n",
            "Epoch 264/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1891 - acc: 0.5450 - val_loss: 4.2132 - val_acc: 0.0920\n",
            "Epoch 265/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1879 - acc: 0.5455 - val_loss: 4.1717 - val_acc: 0.1068\n",
            "Epoch 266/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1920 - acc: 0.5390 - val_loss: 4.2554 - val_acc: 0.1808\n",
            "Epoch 267/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1867 - acc: 0.5459 - val_loss: 4.1053 - val_acc: 0.1112\n",
            "Epoch 268/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1848 - acc: 0.5421 - val_loss: 4.1648 - val_acc: 0.1016\n",
            "Epoch 269/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1897 - acc: 0.5417 - val_loss: 4.2581 - val_acc: 0.0928\n",
            "Epoch 270/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1877 - acc: 0.5428 - val_loss: 4.1394 - val_acc: 0.1160\n",
            "Epoch 271/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1877 - acc: 0.5412 - val_loss: 4.2171 - val_acc: 0.1848\n",
            "Epoch 272/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1915 - acc: 0.5402 - val_loss: 4.1302 - val_acc: 0.1924\n",
            "Epoch 273/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1827 - acc: 0.5432 - val_loss: 4.2640 - val_acc: 0.0808\n",
            "Epoch 274/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1900 - acc: 0.5402 - val_loss: 4.2591 - val_acc: 0.0860\n",
            "Epoch 275/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1887 - acc: 0.5435 - val_loss: 4.1412 - val_acc: 0.0980\n",
            "Epoch 276/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1870 - acc: 0.5463 - val_loss: 4.1680 - val_acc: 0.1164\n",
            "Epoch 277/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1892 - acc: 0.5419 - val_loss: 4.1297 - val_acc: 0.1048\n",
            "Epoch 278/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1837 - acc: 0.5462 - val_loss: 4.1544 - val_acc: 0.0932\n",
            "Epoch 279/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1882 - acc: 0.5426 - val_loss: 4.2227 - val_acc: 0.1860\n",
            "Epoch 280/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1831 - acc: 0.5449 - val_loss: 4.1998 - val_acc: 0.0920\n",
            "Epoch 281/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1797 - acc: 0.5434 - val_loss: 4.1758 - val_acc: 0.0968\n",
            "Epoch 282/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1943 - acc: 0.5384 - val_loss: 4.2074 - val_acc: 0.1056\n",
            "Epoch 283/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1871 - acc: 0.5435 - val_loss: 4.1669 - val_acc: 0.1000\n",
            "Epoch 284/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1847 - acc: 0.5439 - val_loss: 4.2200 - val_acc: 0.1840\n",
            "Epoch 285/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1874 - acc: 0.5426 - val_loss: 4.1608 - val_acc: 0.0976\n",
            "Epoch 286/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1840 - acc: 0.5452 - val_loss: 4.1439 - val_acc: 0.1152\n",
            "Epoch 287/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1873 - acc: 0.5425 - val_loss: 4.1708 - val_acc: 0.1140\n",
            "Epoch 288/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1863 - acc: 0.5464 - val_loss: 4.2630 - val_acc: 0.0916\n",
            "Epoch 289/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1849 - acc: 0.5451 - val_loss: 4.1285 - val_acc: 0.0996\n",
            "Epoch 290/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1821 - acc: 0.5451 - val_loss: 4.1930 - val_acc: 0.1036\n",
            "Epoch 291/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1818 - acc: 0.5466 - val_loss: 4.2206 - val_acc: 0.0944\n",
            "Epoch 292/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1831 - acc: 0.5453 - val_loss: 4.1816 - val_acc: 0.1012\n",
            "Epoch 293/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1841 - acc: 0.5452 - val_loss: 4.1932 - val_acc: 0.1080\n",
            "Epoch 294/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1863 - acc: 0.5430 - val_loss: 4.3105 - val_acc: 0.0920\n",
            "Epoch 295/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1859 - acc: 0.5422 - val_loss: 4.1780 - val_acc: 0.1032\n",
            "Epoch 296/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1827 - acc: 0.5470 - val_loss: 4.2759 - val_acc: 0.1688\n",
            "Epoch 297/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1812 - acc: 0.5438 - val_loss: 4.2261 - val_acc: 0.1024\n",
            "Epoch 298/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1800 - acc: 0.5420 - val_loss: 4.2698 - val_acc: 0.0936\n",
            "Epoch 299/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1793 - acc: 0.5427 - val_loss: 4.2166 - val_acc: 0.1004\n",
            "Epoch 300/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1820 - acc: 0.5442 - val_loss: 4.2476 - val_acc: 0.1000\n",
            "Epoch 301/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1847 - acc: 0.5424 - val_loss: 4.2530 - val_acc: 0.1064\n",
            "Epoch 302/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1829 - acc: 0.5452 - val_loss: 4.2489 - val_acc: 0.1968\n",
            "Epoch 303/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1853 - acc: 0.5454 - val_loss: 4.3152 - val_acc: 0.1752\n",
            "Epoch 304/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1811 - acc: 0.5440 - val_loss: 4.2796 - val_acc: 0.1968\n",
            "Epoch 305/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1818 - acc: 0.5456 - val_loss: 4.2297 - val_acc: 0.2012\n",
            "Epoch 306/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1856 - acc: 0.5452 - val_loss: 4.2173 - val_acc: 0.1004\n",
            "Epoch 307/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1839 - acc: 0.5450 - val_loss: 4.2553 - val_acc: 0.0988\n",
            "Epoch 308/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1849 - acc: 0.5427 - val_loss: 4.2037 - val_acc: 0.1776\n",
            "Epoch 309/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1823 - acc: 0.5455 - val_loss: 4.2285 - val_acc: 0.1796\n",
            "Epoch 310/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1818 - acc: 0.5447 - val_loss: 4.2561 - val_acc: 0.0924\n",
            "Epoch 311/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1794 - acc: 0.5442 - val_loss: 4.2496 - val_acc: 0.1780\n",
            "Epoch 312/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1824 - acc: 0.5421 - val_loss: 4.2317 - val_acc: 0.0916\n",
            "Epoch 313/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1831 - acc: 0.5464 - val_loss: 4.2246 - val_acc: 0.0976\n",
            "Epoch 314/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1811 - acc: 0.5447 - val_loss: 4.1749 - val_acc: 0.0968\n",
            "Epoch 315/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1770 - acc: 0.5466 - val_loss: 4.2055 - val_acc: 0.1036\n",
            "Epoch 316/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1767 - acc: 0.5459 - val_loss: 4.2630 - val_acc: 0.1680\n",
            "Epoch 317/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1839 - acc: 0.5427 - val_loss: 4.1978 - val_acc: 0.1052\n",
            "Epoch 318/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1792 - acc: 0.5462 - val_loss: 4.1967 - val_acc: 0.0992\n",
            "Epoch 319/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1817 - acc: 0.5459 - val_loss: 4.2002 - val_acc: 0.0980\n",
            "Epoch 320/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1782 - acc: 0.5442 - val_loss: 4.1328 - val_acc: 0.1108\n",
            "Epoch 321/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1787 - acc: 0.5468 - val_loss: 4.1862 - val_acc: 0.1940\n",
            "Epoch 322/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1783 - acc: 0.5463 - val_loss: 4.2994 - val_acc: 0.1720\n",
            "Epoch 323/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1806 - acc: 0.5439 - val_loss: 4.1429 - val_acc: 0.1916\n",
            "Epoch 324/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1836 - acc: 0.5436 - val_loss: 4.1479 - val_acc: 0.1064\n",
            "Epoch 325/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1767 - acc: 0.5470 - val_loss: 4.0978 - val_acc: 0.1228\n",
            "Epoch 326/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1821 - acc: 0.5468 - val_loss: 4.2712 - val_acc: 0.0824\n",
            "Epoch 327/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1752 - acc: 0.5498 - val_loss: 4.2139 - val_acc: 0.0996\n",
            "Epoch 328/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1825 - acc: 0.5437 - val_loss: 4.1454 - val_acc: 0.1056\n",
            "Epoch 329/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1789 - acc: 0.5427 - val_loss: 4.2350 - val_acc: 0.0928\n",
            "Epoch 330/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1810 - acc: 0.5457 - val_loss: 4.2549 - val_acc: 0.0876\n",
            "Epoch 331/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1786 - acc: 0.5476 - val_loss: 4.1831 - val_acc: 0.0916\n",
            "Epoch 332/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1767 - acc: 0.5478 - val_loss: 4.2853 - val_acc: 0.0836\n",
            "Epoch 333/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1780 - acc: 0.5448 - val_loss: 4.2724 - val_acc: 0.0844\n",
            "Epoch 334/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1771 - acc: 0.5444 - val_loss: 4.1553 - val_acc: 0.0988\n",
            "Epoch 335/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1804 - acc: 0.5456 - val_loss: 4.2856 - val_acc: 0.1708\n",
            "Epoch 336/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1763 - acc: 0.5484 - val_loss: 4.1562 - val_acc: 0.1052\n",
            "Epoch 337/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1771 - acc: 0.5482 - val_loss: 4.1801 - val_acc: 0.1912\n",
            "Epoch 338/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1766 - acc: 0.5463 - val_loss: 4.1281 - val_acc: 0.1092\n",
            "Epoch 339/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1810 - acc: 0.5421 - val_loss: 4.1825 - val_acc: 0.1024\n",
            "Epoch 340/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1777 - acc: 0.5472 - val_loss: 4.1953 - val_acc: 0.0980\n",
            "Epoch 341/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1738 - acc: 0.5456 - val_loss: 4.1609 - val_acc: 0.1132\n",
            "Epoch 342/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1746 - acc: 0.5490 - val_loss: 4.2419 - val_acc: 0.1828\n",
            "Epoch 343/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1784 - acc: 0.5476 - val_loss: 4.1893 - val_acc: 0.1872\n",
            "Epoch 344/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1749 - acc: 0.5449 - val_loss: 4.1841 - val_acc: 0.1920\n",
            "Epoch 345/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1746 - acc: 0.5459 - val_loss: 4.2026 - val_acc: 0.1124\n",
            "Epoch 346/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1810 - acc: 0.5444 - val_loss: 4.2019 - val_acc: 0.1020\n",
            "Epoch 347/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1781 - acc: 0.5441 - val_loss: 4.1913 - val_acc: 0.1884\n",
            "Epoch 348/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1778 - acc: 0.5453 - val_loss: 4.1694 - val_acc: 0.1208\n",
            "Epoch 349/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1803 - acc: 0.5438 - val_loss: 4.1496 - val_acc: 0.1916\n",
            "Epoch 350/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1758 - acc: 0.5499 - val_loss: 4.1227 - val_acc: 0.1164\n",
            "Epoch 351/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1801 - acc: 0.5456 - val_loss: 4.1752 - val_acc: 0.1940\n",
            "Epoch 352/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1731 - acc: 0.5456 - val_loss: 4.2246 - val_acc: 0.1824\n",
            "Epoch 353/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1750 - acc: 0.5453 - val_loss: 4.1177 - val_acc: 0.1096\n",
            "Epoch 354/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1817 - acc: 0.5434 - val_loss: 4.2076 - val_acc: 0.1856\n",
            "Epoch 355/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1781 - acc: 0.5466 - val_loss: 4.1474 - val_acc: 0.1020\n",
            "Epoch 356/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1763 - acc: 0.5458 - val_loss: 4.1988 - val_acc: 0.1976\n",
            "Epoch 357/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1754 - acc: 0.5454 - val_loss: 4.1403 - val_acc: 0.1032\n",
            "Epoch 358/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1770 - acc: 0.5479 - val_loss: 4.1291 - val_acc: 0.1124\n",
            "Epoch 359/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1731 - acc: 0.5458 - val_loss: 4.1326 - val_acc: 0.1040\n",
            "Epoch 360/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1747 - acc: 0.5456 - val_loss: 4.2801 - val_acc: 0.0924\n",
            "Epoch 361/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1742 - acc: 0.5478 - val_loss: 4.2730 - val_acc: 0.1864\n",
            "Epoch 362/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1771 - acc: 0.5468 - val_loss: 4.2062 - val_acc: 0.1932\n",
            "Epoch 363/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1798 - acc: 0.5440 - val_loss: 4.1288 - val_acc: 0.1220\n",
            "Epoch 364/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1758 - acc: 0.5467 - val_loss: 4.2176 - val_acc: 0.1832\n",
            "Epoch 365/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1734 - acc: 0.5443 - val_loss: 4.1724 - val_acc: 0.1156\n",
            "Epoch 366/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1753 - acc: 0.5464 - val_loss: 4.1535 - val_acc: 0.1080\n",
            "Epoch 367/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1724 - acc: 0.5503 - val_loss: 4.2010 - val_acc: 0.1100\n",
            "Epoch 368/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1722 - acc: 0.5473 - val_loss: 4.2378 - val_acc: 0.1048\n",
            "Epoch 369/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1750 - acc: 0.5460 - val_loss: 4.1707 - val_acc: 0.0976\n",
            "Epoch 370/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1777 - acc: 0.5465 - val_loss: 4.1274 - val_acc: 0.1052\n",
            "Epoch 371/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1746 - acc: 0.5457 - val_loss: 4.0861 - val_acc: 0.1092\n",
            "Epoch 372/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1769 - acc: 0.5445 - val_loss: 4.2437 - val_acc: 0.0916\n",
            "Epoch 373/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1758 - acc: 0.5490 - val_loss: 4.2886 - val_acc: 0.1800\n",
            "Epoch 374/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1711 - acc: 0.5458 - val_loss: 4.1991 - val_acc: 0.0904\n",
            "Epoch 375/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1763 - acc: 0.5464 - val_loss: 4.1544 - val_acc: 0.2032\n",
            "Epoch 376/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1761 - acc: 0.5435 - val_loss: 4.2430 - val_acc: 0.0996\n",
            "Epoch 377/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1758 - acc: 0.5480 - val_loss: 4.1919 - val_acc: 0.0996\n",
            "Epoch 378/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1708 - acc: 0.5464 - val_loss: 4.1416 - val_acc: 0.1128\n",
            "Epoch 379/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1737 - acc: 0.5473 - val_loss: 4.2087 - val_acc: 0.1872\n",
            "Epoch 380/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1758 - acc: 0.5467 - val_loss: 4.2426 - val_acc: 0.0976\n",
            "Epoch 381/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1781 - acc: 0.5441 - val_loss: 4.2442 - val_acc: 0.1032\n",
            "Epoch 382/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1687 - acc: 0.5450 - val_loss: 4.1316 - val_acc: 0.2036\n",
            "Epoch 383/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1767 - acc: 0.5429 - val_loss: 4.1640 - val_acc: 0.1904\n",
            "Epoch 384/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1738 - acc: 0.5478 - val_loss: 4.1320 - val_acc: 0.1996\n",
            "Epoch 385/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1751 - acc: 0.5468 - val_loss: 4.1110 - val_acc: 0.1064\n",
            "Epoch 386/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1722 - acc: 0.5484 - val_loss: 4.2158 - val_acc: 0.1908\n",
            "Epoch 387/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1722 - acc: 0.5476 - val_loss: 4.1681 - val_acc: 0.1008\n",
            "Epoch 388/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1742 - acc: 0.5486 - val_loss: 4.1986 - val_acc: 0.1896\n",
            "Epoch 389/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1737 - acc: 0.5459 - val_loss: 4.2391 - val_acc: 0.0908\n",
            "Epoch 390/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1756 - acc: 0.5486 - val_loss: 4.1775 - val_acc: 0.0984\n",
            "Epoch 391/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1759 - acc: 0.5439 - val_loss: 4.2315 - val_acc: 0.2008\n",
            "Epoch 392/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1697 - acc: 0.5463 - val_loss: 4.1936 - val_acc: 0.1060\n",
            "Epoch 393/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1749 - acc: 0.5479 - val_loss: 4.2548 - val_acc: 0.1052\n",
            "Epoch 394/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1754 - acc: 0.5464 - val_loss: 4.1459 - val_acc: 0.1068\n",
            "Epoch 395/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1771 - acc: 0.5468 - val_loss: 4.1925 - val_acc: 0.1108\n",
            "Epoch 396/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1733 - acc: 0.5457 - val_loss: 4.2630 - val_acc: 0.0996\n",
            "Epoch 397/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1701 - acc: 0.5483 - val_loss: 4.0801 - val_acc: 0.1260\n",
            "Epoch 398/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1701 - acc: 0.5476 - val_loss: 4.2536 - val_acc: 0.0960\n",
            "Epoch 399/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1731 - acc: 0.5450 - val_loss: 4.4173 - val_acc: 0.1624\n",
            "Epoch 400/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1755 - acc: 0.5435 - val_loss: 4.1913 - val_acc: 0.1072\n",
            "Epoch 401/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1718 - acc: 0.5470 - val_loss: 4.2676 - val_acc: 0.0844\n",
            "Epoch 402/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1733 - acc: 0.5510 - val_loss: 4.0857 - val_acc: 0.0984\n",
            "Epoch 403/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1712 - acc: 0.5472 - val_loss: 4.1714 - val_acc: 0.1008\n",
            "Epoch 404/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1692 - acc: 0.5471 - val_loss: 4.1659 - val_acc: 0.1196\n",
            "Epoch 405/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1687 - acc: 0.5467 - val_loss: 4.2175 - val_acc: 0.0980\n",
            "Epoch 406/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1734 - acc: 0.5473 - val_loss: 4.1759 - val_acc: 0.1080\n",
            "Epoch 407/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1714 - acc: 0.5492 - val_loss: 4.2256 - val_acc: 0.1864\n",
            "Epoch 408/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1705 - acc: 0.5494 - val_loss: 4.1959 - val_acc: 0.1104\n",
            "Epoch 409/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1692 - acc: 0.5449 - val_loss: 4.1953 - val_acc: 0.2000\n",
            "Epoch 410/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1672 - acc: 0.5485 - val_loss: 4.2391 - val_acc: 0.0944\n",
            "Epoch 411/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1691 - acc: 0.5483 - val_loss: 4.2208 - val_acc: 0.1940\n",
            "Epoch 412/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1713 - acc: 0.5483 - val_loss: 4.2008 - val_acc: 0.1048\n",
            "Epoch 413/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1724 - acc: 0.5501 - val_loss: 4.1982 - val_acc: 0.0992\n",
            "Epoch 414/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1743 - acc: 0.5416 - val_loss: 4.2585 - val_acc: 0.1852\n",
            "Epoch 415/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1727 - acc: 0.5473 - val_loss: 4.1784 - val_acc: 0.1112\n",
            "Epoch 416/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1700 - acc: 0.5470 - val_loss: 4.1912 - val_acc: 0.1008\n",
            "Epoch 417/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1697 - acc: 0.5472 - val_loss: 4.1692 - val_acc: 0.1064\n",
            "Epoch 418/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1718 - acc: 0.5467 - val_loss: 4.1321 - val_acc: 0.1916\n",
            "Epoch 419/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1714 - acc: 0.5469 - val_loss: 4.2083 - val_acc: 0.1896\n",
            "Epoch 420/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1733 - acc: 0.5484 - val_loss: 4.1552 - val_acc: 0.1184\n",
            "Epoch 421/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1739 - acc: 0.5462 - val_loss: 4.2117 - val_acc: 0.1040\n",
            "Epoch 422/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1699 - acc: 0.5486 - val_loss: 4.2052 - val_acc: 0.1064\n",
            "Epoch 423/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1665 - acc: 0.5481 - val_loss: 4.2222 - val_acc: 0.0888\n",
            "Epoch 424/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1760 - acc: 0.5459 - val_loss: 4.2872 - val_acc: 0.0856\n",
            "Epoch 425/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1694 - acc: 0.5482 - val_loss: 4.2555 - val_acc: 0.0956\n",
            "Epoch 426/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1746 - acc: 0.5478 - val_loss: 4.2474 - val_acc: 0.0928\n",
            "Epoch 427/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1695 - acc: 0.5484 - val_loss: 4.2297 - val_acc: 0.0932\n",
            "Epoch 428/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1695 - acc: 0.5480 - val_loss: 4.1507 - val_acc: 0.1116\n",
            "Epoch 429/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1712 - acc: 0.5435 - val_loss: 4.2527 - val_acc: 0.1800\n",
            "Epoch 430/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1741 - acc: 0.5480 - val_loss: 4.2467 - val_acc: 0.0936\n",
            "Epoch 431/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1641 - acc: 0.5490 - val_loss: 4.2003 - val_acc: 0.1060\n",
            "Epoch 432/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1718 - acc: 0.5497 - val_loss: 4.2850 - val_acc: 0.1924\n",
            "Epoch 433/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1688 - acc: 0.5495 - val_loss: 4.2475 - val_acc: 0.1824\n",
            "Epoch 434/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1732 - acc: 0.5471 - val_loss: 4.2691 - val_acc: 0.1820\n",
            "Epoch 435/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1666 - acc: 0.5515 - val_loss: 4.2743 - val_acc: 0.0948\n",
            "Epoch 436/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1671 - acc: 0.5484 - val_loss: 4.2659 - val_acc: 0.1788\n",
            "Epoch 437/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1652 - acc: 0.5509 - val_loss: 4.2548 - val_acc: 0.0960\n",
            "Epoch 438/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1699 - acc: 0.5476 - val_loss: 4.3236 - val_acc: 0.1016\n",
            "Epoch 439/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1702 - acc: 0.5487 - val_loss: 4.2003 - val_acc: 0.1916\n",
            "Epoch 440/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1738 - acc: 0.5465 - val_loss: 4.3202 - val_acc: 0.0828\n",
            "Epoch 441/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1681 - acc: 0.5498 - val_loss: 4.1605 - val_acc: 0.1132\n",
            "Epoch 442/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1714 - acc: 0.5453 - val_loss: 4.2531 - val_acc: 0.1752\n",
            "Epoch 443/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1682 - acc: 0.5472 - val_loss: 4.2011 - val_acc: 0.1116\n",
            "Epoch 444/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1639 - acc: 0.5484 - val_loss: 4.2948 - val_acc: 0.0780\n",
            "Epoch 445/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1680 - acc: 0.5480 - val_loss: 4.2506 - val_acc: 0.1868\n",
            "Epoch 446/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1708 - acc: 0.5472 - val_loss: 4.2903 - val_acc: 0.0892\n",
            "Epoch 447/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1673 - acc: 0.5474 - val_loss: 4.3719 - val_acc: 0.0832\n",
            "Epoch 448/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1672 - acc: 0.5483 - val_loss: 4.2734 - val_acc: 0.1028\n",
            "Epoch 449/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1728 - acc: 0.5450 - val_loss: 4.2782 - val_acc: 0.1156\n",
            "Epoch 450/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1723 - acc: 0.5503 - val_loss: 4.2597 - val_acc: 0.1860\n",
            "Epoch 451/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1656 - acc: 0.5464 - val_loss: 4.2459 - val_acc: 0.1856\n",
            "Epoch 452/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1698 - acc: 0.5501 - val_loss: 4.2748 - val_acc: 0.0980\n",
            "Epoch 453/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1712 - acc: 0.5461 - val_loss: 4.1803 - val_acc: 0.1052\n",
            "Epoch 454/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1657 - acc: 0.5463 - val_loss: 4.1450 - val_acc: 0.1136\n",
            "Epoch 455/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1736 - acc: 0.5448 - val_loss: 4.1593 - val_acc: 0.1088\n",
            "Epoch 456/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1673 - acc: 0.5460 - val_loss: 4.2823 - val_acc: 0.0852\n",
            "Epoch 457/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1670 - acc: 0.5467 - val_loss: 4.1613 - val_acc: 0.1128\n",
            "Epoch 458/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1690 - acc: 0.5471 - val_loss: 4.1940 - val_acc: 0.1024\n",
            "Epoch 459/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1729 - acc: 0.5470 - val_loss: 4.1679 - val_acc: 0.2016\n",
            "Epoch 460/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1630 - acc: 0.5503 - val_loss: 4.2459 - val_acc: 0.0968\n",
            "Epoch 461/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1663 - acc: 0.5475 - val_loss: 4.2556 - val_acc: 0.1020\n",
            "Epoch 462/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1647 - acc: 0.5510 - val_loss: 4.2607 - val_acc: 0.0952\n",
            "Epoch 463/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1704 - acc: 0.5484 - val_loss: 4.1490 - val_acc: 0.1152\n",
            "Epoch 464/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1680 - acc: 0.5496 - val_loss: 4.2238 - val_acc: 0.1024\n",
            "Epoch 465/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1647 - acc: 0.5494 - val_loss: 4.2174 - val_acc: 0.2008\n",
            "Epoch 466/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1691 - acc: 0.5471 - val_loss: 4.2383 - val_acc: 0.1048\n",
            "Epoch 467/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1690 - acc: 0.5467 - val_loss: 4.2228 - val_acc: 0.1176\n",
            "Epoch 468/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1674 - acc: 0.5475 - val_loss: 4.2634 - val_acc: 0.0984\n",
            "Epoch 469/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1644 - acc: 0.5489 - val_loss: 4.2241 - val_acc: 0.1092\n",
            "Epoch 470/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1648 - acc: 0.5474 - val_loss: 4.2927 - val_acc: 0.0940\n",
            "Epoch 471/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1688 - acc: 0.5497 - val_loss: 4.3641 - val_acc: 0.0960\n",
            "Epoch 472/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1647 - acc: 0.5477 - val_loss: 4.2790 - val_acc: 0.1932\n",
            "Epoch 473/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1688 - acc: 0.5469 - val_loss: 4.2773 - val_acc: 0.1008\n",
            "Epoch 474/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1651 - acc: 0.5502 - val_loss: 4.3295 - val_acc: 0.1836\n",
            "Epoch 475/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1632 - acc: 0.5501 - val_loss: 4.3085 - val_acc: 0.1068\n",
            "Epoch 476/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1651 - acc: 0.5483 - val_loss: 4.2792 - val_acc: 0.0856\n",
            "Epoch 477/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1638 - acc: 0.5483 - val_loss: 4.3363 - val_acc: 0.1760\n",
            "Epoch 478/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1656 - acc: 0.5496 - val_loss: 4.2731 - val_acc: 0.0896\n",
            "Epoch 479/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1623 - acc: 0.5507 - val_loss: 4.2853 - val_acc: 0.1892\n",
            "Epoch 480/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1643 - acc: 0.5470 - val_loss: 4.2944 - val_acc: 0.0876\n",
            "Epoch 481/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1666 - acc: 0.5489 - val_loss: 4.2645 - val_acc: 0.1004\n",
            "Epoch 482/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1657 - acc: 0.5515 - val_loss: 4.2874 - val_acc: 0.1000\n",
            "Epoch 483/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1649 - acc: 0.5462 - val_loss: 4.3044 - val_acc: 0.0984\n",
            "Epoch 484/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1675 - acc: 0.5445 - val_loss: 4.2549 - val_acc: 0.1052\n",
            "Epoch 485/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1700 - acc: 0.5489 - val_loss: 4.2776 - val_acc: 0.0892\n",
            "Epoch 486/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1681 - acc: 0.5483 - val_loss: 4.2950 - val_acc: 0.0896\n",
            "Epoch 487/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1655 - acc: 0.5493 - val_loss: 4.2872 - val_acc: 0.0924\n",
            "Epoch 488/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1651 - acc: 0.5500 - val_loss: 4.2919 - val_acc: 0.0856\n",
            "Epoch 489/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1674 - acc: 0.5477 - val_loss: 4.2470 - val_acc: 0.1232\n",
            "Epoch 490/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1614 - acc: 0.5488 - val_loss: 4.3397 - val_acc: 0.0916\n",
            "Epoch 491/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1679 - acc: 0.5457 - val_loss: 4.3032 - val_acc: 0.1044\n",
            "Epoch 492/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1633 - acc: 0.5504 - val_loss: 4.2350 - val_acc: 0.1028\n",
            "Epoch 493/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1638 - acc: 0.5468 - val_loss: 4.1724 - val_acc: 0.1956\n",
            "Epoch 494/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1649 - acc: 0.5483 - val_loss: 4.1876 - val_acc: 0.1064\n",
            "Epoch 495/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1616 - acc: 0.5492 - val_loss: 4.2537 - val_acc: 0.1060\n",
            "Epoch 496/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1642 - acc: 0.5502 - val_loss: 4.2424 - val_acc: 0.0996\n",
            "Epoch 497/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1637 - acc: 0.5473 - val_loss: 4.3071 - val_acc: 0.1908\n",
            "Epoch 498/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1658 - acc: 0.5460 - val_loss: 4.3293 - val_acc: 0.0944\n",
            "Epoch 499/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1671 - acc: 0.5483 - val_loss: 4.3078 - val_acc: 0.0880\n",
            "Epoch 500/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1660 - acc: 0.5492 - val_loss: 4.2642 - val_acc: 0.1856\n",
            "Epoch 501/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1661 - acc: 0.5493 - val_loss: 4.2716 - val_acc: 0.1028\n",
            "Epoch 502/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1614 - acc: 0.5495 - val_loss: 4.2130 - val_acc: 0.1084\n",
            "Epoch 503/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1678 - acc: 0.5506 - val_loss: 4.1823 - val_acc: 0.1216\n",
            "Epoch 504/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1684 - acc: 0.5461 - val_loss: 4.1621 - val_acc: 0.1116\n",
            "Epoch 505/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1619 - acc: 0.5472 - val_loss: 4.1883 - val_acc: 0.1012\n",
            "Epoch 506/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1646 - acc: 0.5496 - val_loss: 4.2781 - val_acc: 0.0984\n",
            "Epoch 507/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1654 - acc: 0.5487 - val_loss: 4.2386 - val_acc: 0.1020\n",
            "Epoch 508/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1638 - acc: 0.5517 - val_loss: 4.2726 - val_acc: 0.0956\n",
            "Epoch 509/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1680 - acc: 0.5471 - val_loss: 4.2392 - val_acc: 0.0956\n",
            "Epoch 510/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1589 - acc: 0.5520 - val_loss: 4.2526 - val_acc: 0.1132\n",
            "Epoch 511/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1653 - acc: 0.5463 - val_loss: 4.2860 - val_acc: 0.0952\n",
            "Epoch 512/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1691 - acc: 0.5465 - val_loss: 4.2257 - val_acc: 0.1084\n",
            "Epoch 513/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1650 - acc: 0.5506 - val_loss: 4.2228 - val_acc: 0.1128\n",
            "Epoch 514/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1649 - acc: 0.5468 - val_loss: 4.2979 - val_acc: 0.1084\n",
            "Epoch 515/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1649 - acc: 0.5478 - val_loss: 4.3988 - val_acc: 0.0904\n",
            "Epoch 516/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1644 - acc: 0.5501 - val_loss: 4.2414 - val_acc: 0.1960\n",
            "Epoch 517/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1599 - acc: 0.5498 - val_loss: 4.3210 - val_acc: 0.0900\n",
            "Epoch 518/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1666 - acc: 0.5485 - val_loss: 4.2886 - val_acc: 0.1076\n",
            "Epoch 519/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1623 - acc: 0.5495 - val_loss: 4.3318 - val_acc: 0.0896\n",
            "Epoch 520/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1583 - acc: 0.5487 - val_loss: 4.3085 - val_acc: 0.1164\n",
            "Epoch 521/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1638 - acc: 0.5484 - val_loss: 4.2833 - val_acc: 0.1808\n",
            "Epoch 522/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1641 - acc: 0.5481 - val_loss: 4.3149 - val_acc: 0.0980\n",
            "Epoch 523/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1670 - acc: 0.5492 - val_loss: 4.2477 - val_acc: 0.1220\n",
            "Epoch 524/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1656 - acc: 0.5482 - val_loss: 4.3275 - val_acc: 0.0852\n",
            "Epoch 525/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1638 - acc: 0.5517 - val_loss: 4.2809 - val_acc: 0.1116\n",
            "Epoch 526/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1608 - acc: 0.5511 - val_loss: 4.2155 - val_acc: 0.1192\n",
            "Epoch 527/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1588 - acc: 0.5517 - val_loss: 4.3781 - val_acc: 0.0936\n",
            "Epoch 528/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1633 - acc: 0.5490 - val_loss: 4.2021 - val_acc: 0.1192\n",
            "Epoch 529/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1660 - acc: 0.5491 - val_loss: 4.3067 - val_acc: 0.1952\n",
            "Epoch 530/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1618 - acc: 0.5478 - val_loss: 4.2430 - val_acc: 0.1964\n",
            "Epoch 531/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1611 - acc: 0.5499 - val_loss: 4.3406 - val_acc: 0.1028\n",
            "Epoch 532/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1694 - acc: 0.5445 - val_loss: 4.2627 - val_acc: 0.1952\n",
            "Epoch 533/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1594 - acc: 0.5504 - val_loss: 4.2805 - val_acc: 0.1952\n",
            "Epoch 534/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1636 - acc: 0.5489 - val_loss: 4.2728 - val_acc: 0.1120\n",
            "Epoch 535/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1591 - acc: 0.5508 - val_loss: 4.2976 - val_acc: 0.1012\n",
            "Epoch 536/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1657 - acc: 0.5482 - val_loss: 4.2799 - val_acc: 0.1088\n",
            "Epoch 537/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1598 - acc: 0.5519 - val_loss: 4.3455 - val_acc: 0.0956\n",
            "Epoch 538/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1670 - acc: 0.5472 - val_loss: 4.4078 - val_acc: 0.1044\n",
            "Epoch 539/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1596 - acc: 0.5535 - val_loss: 4.2855 - val_acc: 0.1028\n",
            "Epoch 540/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1648 - acc: 0.5475 - val_loss: 4.2884 - val_acc: 0.1044\n",
            "Epoch 541/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1616 - acc: 0.5501 - val_loss: 4.3087 - val_acc: 0.0988\n",
            "Epoch 542/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1620 - acc: 0.5466 - val_loss: 4.3335 - val_acc: 0.0968\n",
            "Epoch 543/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1636 - acc: 0.5512 - val_loss: 4.2686 - val_acc: 0.1988\n",
            "Epoch 544/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1627 - acc: 0.5473 - val_loss: 4.3549 - val_acc: 0.0860\n",
            "Epoch 545/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1609 - acc: 0.5494 - val_loss: 4.3314 - val_acc: 0.1800\n",
            "Epoch 546/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1693 - acc: 0.5475 - val_loss: 4.3001 - val_acc: 0.1052\n",
            "Epoch 547/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1580 - acc: 0.5479 - val_loss: 4.2937 - val_acc: 0.1752\n",
            "Epoch 548/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1657 - acc: 0.5507 - val_loss: 4.2692 - val_acc: 0.0992\n",
            "Epoch 549/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1639 - acc: 0.5490 - val_loss: 4.2384 - val_acc: 0.1096\n",
            "Epoch 550/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1604 - acc: 0.5500 - val_loss: 4.2390 - val_acc: 0.1980\n",
            "Epoch 551/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1665 - acc: 0.5479 - val_loss: 4.2608 - val_acc: 0.1112\n",
            "Epoch 552/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1641 - acc: 0.5496 - val_loss: 4.2761 - val_acc: 0.1852\n",
            "Epoch 553/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1601 - acc: 0.5505 - val_loss: 4.2479 - val_acc: 0.1044\n",
            "Epoch 554/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1628 - acc: 0.5489 - val_loss: 4.2884 - val_acc: 0.0992\n",
            "Epoch 555/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1602 - acc: 0.5515 - val_loss: 4.2813 - val_acc: 0.1128\n",
            "Epoch 556/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1615 - acc: 0.5474 - val_loss: 4.2404 - val_acc: 0.1084\n",
            "Epoch 557/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1633 - acc: 0.5484 - val_loss: 4.2891 - val_acc: 0.1812\n",
            "Epoch 558/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1624 - acc: 0.5494 - val_loss: 4.3249 - val_acc: 0.0972\n",
            "Epoch 559/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1569 - acc: 0.5503 - val_loss: 4.2547 - val_acc: 0.0960\n",
            "Epoch 560/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1585 - acc: 0.5488 - val_loss: 4.2794 - val_acc: 0.1976\n",
            "Epoch 561/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1625 - acc: 0.5493 - val_loss: 4.2162 - val_acc: 0.1228\n",
            "Epoch 562/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1637 - acc: 0.5504 - val_loss: 4.2625 - val_acc: 0.1008\n",
            "Epoch 563/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1645 - acc: 0.5476 - val_loss: 4.3051 - val_acc: 0.1004\n",
            "Epoch 564/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1586 - acc: 0.5521 - val_loss: 4.3049 - val_acc: 0.1756\n",
            "Epoch 565/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1611 - acc: 0.5498 - val_loss: 4.3607 - val_acc: 0.0872\n",
            "Epoch 566/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1594 - acc: 0.5520 - val_loss: 4.2723 - val_acc: 0.1836\n",
            "Epoch 567/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1636 - acc: 0.5473 - val_loss: 4.2886 - val_acc: 0.1040\n",
            "Epoch 568/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1567 - acc: 0.5527 - val_loss: 4.2805 - val_acc: 0.1964\n",
            "Epoch 569/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1627 - acc: 0.5496 - val_loss: 4.2244 - val_acc: 0.1052\n",
            "Epoch 570/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1587 - acc: 0.5522 - val_loss: 4.3200 - val_acc: 0.0944\n",
            "Epoch 571/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1647 - acc: 0.5495 - val_loss: 4.2779 - val_acc: 0.1024\n",
            "Epoch 572/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1642 - acc: 0.5476 - val_loss: 4.2625 - val_acc: 0.0960\n",
            "Epoch 573/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1687 - acc: 0.5487 - val_loss: 4.3235 - val_acc: 0.1900\n",
            "Epoch 574/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1599 - acc: 0.5508 - val_loss: 4.2696 - val_acc: 0.1020\n",
            "Epoch 575/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1632 - acc: 0.5497 - val_loss: 4.3460 - val_acc: 0.1700\n",
            "Epoch 576/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1617 - acc: 0.5473 - val_loss: 4.2553 - val_acc: 0.1960\n",
            "Epoch 577/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1611 - acc: 0.5471 - val_loss: 4.2972 - val_acc: 0.0952\n",
            "Epoch 578/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1569 - acc: 0.5495 - val_loss: 4.2526 - val_acc: 0.0928\n",
            "Epoch 579/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1592 - acc: 0.5493 - val_loss: 4.2461 - val_acc: 0.1104\n",
            "Epoch 580/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1591 - acc: 0.5522 - val_loss: 4.2714 - val_acc: 0.0968\n",
            "Epoch 581/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1607 - acc: 0.5528 - val_loss: 4.2884 - val_acc: 0.1024\n",
            "Epoch 582/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1610 - acc: 0.5541 - val_loss: 4.2761 - val_acc: 0.1072\n",
            "Epoch 583/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1640 - acc: 0.5490 - val_loss: 4.2303 - val_acc: 0.1928\n",
            "Epoch 584/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1585 - acc: 0.5501 - val_loss: 4.3353 - val_acc: 0.1064\n",
            "Epoch 585/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1567 - acc: 0.5516 - val_loss: 4.2915 - val_acc: 0.1868\n",
            "Epoch 586/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1590 - acc: 0.5492 - val_loss: 4.2412 - val_acc: 0.1156\n",
            "Epoch 587/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1601 - acc: 0.5516 - val_loss: 4.2716 - val_acc: 0.0988\n",
            "Epoch 588/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1613 - acc: 0.5497 - val_loss: 4.3003 - val_acc: 0.0932\n",
            "Epoch 589/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1630 - acc: 0.5493 - val_loss: 4.3464 - val_acc: 0.0908\n",
            "Epoch 590/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1562 - acc: 0.5520 - val_loss: 4.2756 - val_acc: 0.2000\n",
            "Epoch 591/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1594 - acc: 0.5552 - val_loss: 4.2378 - val_acc: 0.1068\n",
            "Epoch 592/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1576 - acc: 0.5493 - val_loss: 4.3119 - val_acc: 0.0944\n",
            "Epoch 593/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1559 - acc: 0.5542 - val_loss: 4.2647 - val_acc: 0.1060\n",
            "Epoch 594/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1568 - acc: 0.5491 - val_loss: 4.2918 - val_acc: 0.0884\n",
            "Epoch 595/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1620 - acc: 0.5484 - val_loss: 4.2184 - val_acc: 0.1140\n",
            "Epoch 596/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1564 - acc: 0.5496 - val_loss: 4.2180 - val_acc: 0.1012\n",
            "Epoch 597/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1580 - acc: 0.5488 - val_loss: 4.3513 - val_acc: 0.0932\n",
            "Epoch 598/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1548 - acc: 0.5523 - val_loss: 4.2625 - val_acc: 0.1072\n",
            "Epoch 599/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1627 - acc: 0.5488 - val_loss: 4.2485 - val_acc: 0.1060\n",
            "Epoch 600/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1590 - acc: 0.5476 - val_loss: 4.2962 - val_acc: 0.0920\n",
            "Epoch 601/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1611 - acc: 0.5494 - val_loss: 4.3131 - val_acc: 0.1012\n",
            "Epoch 602/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1629 - acc: 0.5469 - val_loss: 4.2890 - val_acc: 0.2060\n",
            "Epoch 603/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1579 - acc: 0.5487 - val_loss: 4.3183 - val_acc: 0.1956\n",
            "Epoch 604/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1583 - acc: 0.5488 - val_loss: 4.2148 - val_acc: 0.1208\n",
            "Epoch 605/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1611 - acc: 0.5548 - val_loss: 4.2160 - val_acc: 0.1968\n",
            "Epoch 606/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1568 - acc: 0.5504 - val_loss: 4.3242 - val_acc: 0.1020\n",
            "Epoch 607/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1657 - acc: 0.5475 - val_loss: 4.2707 - val_acc: 0.1056\n",
            "Epoch 608/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1569 - acc: 0.5501 - val_loss: 4.2644 - val_acc: 0.1028\n",
            "Epoch 609/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1581 - acc: 0.5508 - val_loss: 4.3118 - val_acc: 0.0932\n",
            "Epoch 610/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1578 - acc: 0.5532 - val_loss: 4.3938 - val_acc: 0.0924\n",
            "Epoch 611/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1520 - acc: 0.5529 - val_loss: 4.2963 - val_acc: 0.0968\n",
            "Epoch 612/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1568 - acc: 0.5505 - val_loss: 4.2560 - val_acc: 0.1044\n",
            "Epoch 613/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1582 - acc: 0.5540 - val_loss: 4.2617 - val_acc: 0.1032\n",
            "Epoch 614/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1616 - acc: 0.5453 - val_loss: 4.2852 - val_acc: 0.0908\n",
            "Epoch 615/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1599 - acc: 0.5535 - val_loss: 4.2146 - val_acc: 0.1056\n",
            "Epoch 616/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1556 - acc: 0.5499 - val_loss: 4.2335 - val_acc: 0.1880\n",
            "Epoch 617/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1599 - acc: 0.5507 - val_loss: 4.3948 - val_acc: 0.0800\n",
            "Epoch 618/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1560 - acc: 0.5533 - val_loss: 4.2275 - val_acc: 0.2012\n",
            "Epoch 619/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1576 - acc: 0.5520 - val_loss: 4.2998 - val_acc: 0.0932\n",
            "Epoch 620/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1568 - acc: 0.5508 - val_loss: 4.3092 - val_acc: 0.0944\n",
            "Epoch 621/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1594 - acc: 0.5487 - val_loss: 4.2946 - val_acc: 0.1140\n",
            "Epoch 622/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1582 - acc: 0.5524 - val_loss: 4.2271 - val_acc: 0.1256\n",
            "Epoch 623/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1599 - acc: 0.5492 - val_loss: 4.2878 - val_acc: 0.0920\n",
            "Epoch 624/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1558 - acc: 0.5511 - val_loss: 4.2855 - val_acc: 0.0996\n",
            "Epoch 625/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1557 - acc: 0.5542 - val_loss: 4.2619 - val_acc: 0.1220\n",
            "Epoch 626/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1576 - acc: 0.5508 - val_loss: 4.2649 - val_acc: 0.1112\n",
            "Epoch 627/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1598 - acc: 0.5528 - val_loss: 4.3087 - val_acc: 0.0912\n",
            "Epoch 628/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1585 - acc: 0.5509 - val_loss: 4.3452 - val_acc: 0.0812\n",
            "Epoch 629/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1558 - acc: 0.5484 - val_loss: 4.2360 - val_acc: 0.2012\n",
            "Epoch 630/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1583 - acc: 0.5486 - val_loss: 4.2659 - val_acc: 0.1940\n",
            "Epoch 631/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1554 - acc: 0.5538 - val_loss: 4.2289 - val_acc: 0.0956\n",
            "Epoch 632/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1519 - acc: 0.5550 - val_loss: 4.3246 - val_acc: 0.0868\n",
            "Epoch 633/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1583 - acc: 0.5510 - val_loss: 4.2914 - val_acc: 0.1108\n",
            "Epoch 634/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1599 - acc: 0.5472 - val_loss: 4.2881 - val_acc: 0.1848\n",
            "Epoch 635/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1587 - acc: 0.5478 - val_loss: 4.2494 - val_acc: 0.1080\n",
            "Epoch 636/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1598 - acc: 0.5516 - val_loss: 4.3223 - val_acc: 0.0996\n",
            "Epoch 637/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1567 - acc: 0.5496 - val_loss: 4.2255 - val_acc: 0.2048\n",
            "Epoch 638/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1613 - acc: 0.5499 - val_loss: 4.2313 - val_acc: 0.1104\n",
            "Epoch 639/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1517 - acc: 0.5533 - val_loss: 4.3557 - val_acc: 0.1884\n",
            "Epoch 640/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1555 - acc: 0.5504 - val_loss: 4.3173 - val_acc: 0.1044\n",
            "Epoch 641/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1592 - acc: 0.5505 - val_loss: 4.2521 - val_acc: 0.1956\n",
            "Epoch 642/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1564 - acc: 0.5507 - val_loss: 4.2595 - val_acc: 0.1812\n",
            "Epoch 643/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1598 - acc: 0.5493 - val_loss: 4.3374 - val_acc: 0.0980\n",
            "Epoch 644/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1561 - acc: 0.5514 - val_loss: 4.2580 - val_acc: 0.0984\n",
            "Epoch 645/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1580 - acc: 0.5512 - val_loss: 4.2677 - val_acc: 0.1884\n",
            "Epoch 646/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1564 - acc: 0.5510 - val_loss: 4.2475 - val_acc: 0.1188\n",
            "Epoch 647/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1618 - acc: 0.5513 - val_loss: 4.2269 - val_acc: 0.1168\n",
            "Epoch 648/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1581 - acc: 0.5490 - val_loss: 4.2060 - val_acc: 0.1140\n",
            "Epoch 649/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1538 - acc: 0.5534 - val_loss: 4.3481 - val_acc: 0.1752\n",
            "Epoch 650/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1543 - acc: 0.5521 - val_loss: 4.2723 - val_acc: 0.1116\n",
            "Epoch 651/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1492 - acc: 0.5528 - val_loss: 4.3537 - val_acc: 0.0808\n",
            "Epoch 652/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1533 - acc: 0.5511 - val_loss: 4.2788 - val_acc: 0.0960\n",
            "Epoch 653/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1605 - acc: 0.5453 - val_loss: 4.3073 - val_acc: 0.0872\n",
            "Epoch 654/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1622 - acc: 0.5504 - val_loss: 4.3227 - val_acc: 0.0928\n",
            "Epoch 655/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1605 - acc: 0.5504 - val_loss: 4.2994 - val_acc: 0.1064\n",
            "Epoch 656/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1518 - acc: 0.5527 - val_loss: 4.2652 - val_acc: 0.1068\n",
            "Epoch 657/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1557 - acc: 0.5517 - val_loss: 4.2677 - val_acc: 0.0924\n",
            "Epoch 658/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1554 - acc: 0.5516 - val_loss: 4.2011 - val_acc: 0.1172\n",
            "Epoch 659/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1532 - acc: 0.5536 - val_loss: 4.3185 - val_acc: 0.0864\n",
            "Epoch 660/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1571 - acc: 0.5480 - val_loss: 4.3721 - val_acc: 0.0784\n",
            "Epoch 661/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1561 - acc: 0.5508 - val_loss: 4.3005 - val_acc: 0.1004\n",
            "Epoch 662/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1522 - acc: 0.5509 - val_loss: 4.2754 - val_acc: 0.1000\n",
            "Epoch 663/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1587 - acc: 0.5532 - val_loss: 4.3149 - val_acc: 0.1004\n",
            "Epoch 664/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1542 - acc: 0.5537 - val_loss: 4.3477 - val_acc: 0.0996\n",
            "Epoch 665/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1539 - acc: 0.5514 - val_loss: 4.2305 - val_acc: 0.2004\n",
            "Epoch 666/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1543 - acc: 0.5504 - val_loss: 4.2927 - val_acc: 0.0956\n",
            "Epoch 667/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1579 - acc: 0.5496 - val_loss: 4.2844 - val_acc: 0.0992\n",
            "Epoch 668/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1524 - acc: 0.5511 - val_loss: 4.3081 - val_acc: 0.1024\n",
            "Epoch 669/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1591 - acc: 0.5506 - val_loss: 4.2458 - val_acc: 0.1104\n",
            "Epoch 670/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1553 - acc: 0.5508 - val_loss: 4.3177 - val_acc: 0.1036\n",
            "Epoch 671/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1587 - acc: 0.5475 - val_loss: 4.3907 - val_acc: 0.0928\n",
            "Epoch 672/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1587 - acc: 0.5472 - val_loss: 4.3417 - val_acc: 0.0864\n",
            "Epoch 673/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1568 - acc: 0.5517 - val_loss: 4.2894 - val_acc: 0.0944\n",
            "Epoch 674/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1600 - acc: 0.5508 - val_loss: 4.3360 - val_acc: 0.0940\n",
            "Epoch 675/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1578 - acc: 0.5500 - val_loss: 4.2533 - val_acc: 0.1032\n",
            "Epoch 676/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1523 - acc: 0.5526 - val_loss: 4.2355 - val_acc: 0.2020\n",
            "Epoch 677/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1527 - acc: 0.5544 - val_loss: 4.2973 - val_acc: 0.1128\n",
            "Epoch 678/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1535 - acc: 0.5517 - val_loss: 4.2689 - val_acc: 0.1836\n",
            "Epoch 679/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1572 - acc: 0.5515 - val_loss: 4.2636 - val_acc: 0.0988\n",
            "Epoch 680/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1513 - acc: 0.5500 - val_loss: 4.2990 - val_acc: 0.1864\n",
            "Epoch 681/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1534 - acc: 0.5509 - val_loss: 4.3059 - val_acc: 0.0996\n",
            "Epoch 682/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1546 - acc: 0.5524 - val_loss: 4.3270 - val_acc: 0.1864\n",
            "Epoch 683/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1558 - acc: 0.5528 - val_loss: 4.2909 - val_acc: 0.1884\n",
            "Epoch 684/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1546 - acc: 0.5501 - val_loss: 4.2228 - val_acc: 0.1156\n",
            "Epoch 685/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1559 - acc: 0.5525 - val_loss: 4.2744 - val_acc: 0.1000\n",
            "Epoch 686/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1558 - acc: 0.5525 - val_loss: 4.2949 - val_acc: 0.1048\n",
            "Epoch 687/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1578 - acc: 0.5503 - val_loss: 4.2905 - val_acc: 0.1004\n",
            "Epoch 688/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1532 - acc: 0.5541 - val_loss: 4.2377 - val_acc: 0.1012\n",
            "Epoch 689/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1548 - acc: 0.5536 - val_loss: 4.2659 - val_acc: 0.1056\n",
            "Epoch 690/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1509 - acc: 0.5522 - val_loss: 4.2815 - val_acc: 0.1016\n",
            "Epoch 691/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1550 - acc: 0.5513 - val_loss: 4.2340 - val_acc: 0.1216\n",
            "Epoch 692/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1568 - acc: 0.5517 - val_loss: 4.3691 - val_acc: 0.0896\n",
            "Epoch 693/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1566 - acc: 0.5503 - val_loss: 4.2576 - val_acc: 0.1048\n",
            "Epoch 694/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1557 - acc: 0.5512 - val_loss: 4.2264 - val_acc: 0.1104\n",
            "Epoch 695/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1548 - acc: 0.5487 - val_loss: 4.3189 - val_acc: 0.1012\n",
            "Epoch 696/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1585 - acc: 0.5525 - val_loss: 4.3103 - val_acc: 0.1048\n",
            "Epoch 697/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1567 - acc: 0.5483 - val_loss: 4.2930 - val_acc: 0.1920\n",
            "Epoch 698/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1557 - acc: 0.5507 - val_loss: 4.2685 - val_acc: 0.1028\n",
            "Epoch 699/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1506 - acc: 0.5500 - val_loss: 4.2665 - val_acc: 0.1060\n",
            "Epoch 700/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1542 - acc: 0.5519 - val_loss: 4.3006 - val_acc: 0.1120\n",
            "Epoch 701/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1554 - acc: 0.5528 - val_loss: 4.1932 - val_acc: 0.1244\n",
            "Epoch 702/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1543 - acc: 0.5513 - val_loss: 4.2965 - val_acc: 0.1836\n",
            "Epoch 703/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1521 - acc: 0.5501 - val_loss: 4.2891 - val_acc: 0.1080\n",
            "Epoch 704/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1598 - acc: 0.5487 - val_loss: 4.2659 - val_acc: 0.1052\n",
            "Epoch 705/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1597 - acc: 0.5523 - val_loss: 4.3033 - val_acc: 0.1048\n",
            "Epoch 706/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1525 - acc: 0.5523 - val_loss: 4.2518 - val_acc: 0.1288\n",
            "Epoch 707/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1546 - acc: 0.5545 - val_loss: 4.2414 - val_acc: 0.1940\n",
            "Epoch 708/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1542 - acc: 0.5519 - val_loss: 4.2363 - val_acc: 0.1144\n",
            "Epoch 709/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1547 - acc: 0.5510 - val_loss: 4.3486 - val_acc: 0.1856\n",
            "Epoch 710/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1594 - acc: 0.5475 - val_loss: 4.3766 - val_acc: 0.0824\n",
            "Epoch 711/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1538 - acc: 0.5540 - val_loss: 4.2341 - val_acc: 0.1084\n",
            "Epoch 712/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1579 - acc: 0.5536 - val_loss: 4.4283 - val_acc: 0.0844\n",
            "Epoch 713/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1570 - acc: 0.5507 - val_loss: 4.3004 - val_acc: 0.1092\n",
            "Epoch 714/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1567 - acc: 0.5512 - val_loss: 4.2916 - val_acc: 0.0976\n",
            "Epoch 715/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1523 - acc: 0.5518 - val_loss: 4.2319 - val_acc: 0.1008\n",
            "Epoch 716/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1536 - acc: 0.5516 - val_loss: 4.2461 - val_acc: 0.1016\n",
            "Epoch 717/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1548 - acc: 0.5532 - val_loss: 4.2592 - val_acc: 0.1180\n",
            "Epoch 718/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1591 - acc: 0.5505 - val_loss: 4.3297 - val_acc: 0.0968\n",
            "Epoch 719/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1546 - acc: 0.5529 - val_loss: 4.2644 - val_acc: 0.0924\n",
            "Epoch 720/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1561 - acc: 0.5505 - val_loss: 4.2496 - val_acc: 0.0984\n",
            "Epoch 721/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1514 - acc: 0.5512 - val_loss: 4.3060 - val_acc: 0.1052\n",
            "Epoch 722/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1541 - acc: 0.5515 - val_loss: 4.2906 - val_acc: 0.1064\n",
            "Epoch 723/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1500 - acc: 0.5547 - val_loss: 4.2489 - val_acc: 0.1080\n",
            "Epoch 724/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1548 - acc: 0.5519 - val_loss: 4.2592 - val_acc: 0.1884\n",
            "Epoch 725/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1533 - acc: 0.5513 - val_loss: 4.3317 - val_acc: 0.0904\n",
            "Epoch 726/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1559 - acc: 0.5519 - val_loss: 4.2996 - val_acc: 0.1092\n",
            "Epoch 727/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1509 - acc: 0.5494 - val_loss: 4.2724 - val_acc: 0.1108\n",
            "Epoch 728/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1504 - acc: 0.5552 - val_loss: 4.2509 - val_acc: 0.0996\n",
            "Epoch 729/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1499 - acc: 0.5553 - val_loss: 4.2752 - val_acc: 0.1060\n",
            "Epoch 730/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1548 - acc: 0.5536 - val_loss: 4.2333 - val_acc: 0.1108\n",
            "Epoch 731/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1524 - acc: 0.5546 - val_loss: 4.2764 - val_acc: 0.1948\n",
            "Epoch 732/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1535 - acc: 0.5532 - val_loss: 4.2002 - val_acc: 0.1148\n",
            "Epoch 733/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1543 - acc: 0.5499 - val_loss: 4.2146 - val_acc: 0.1076\n",
            "Epoch 734/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1529 - acc: 0.5527 - val_loss: 4.2158 - val_acc: 0.1116\n",
            "Epoch 735/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1511 - acc: 0.5559 - val_loss: 4.1896 - val_acc: 0.1272\n",
            "Epoch 736/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1525 - acc: 0.5555 - val_loss: 4.2930 - val_acc: 0.1012\n",
            "Epoch 737/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1520 - acc: 0.5536 - val_loss: 4.3007 - val_acc: 0.1096\n",
            "Epoch 738/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1557 - acc: 0.5492 - val_loss: 4.3350 - val_acc: 0.1824\n",
            "Epoch 739/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1526 - acc: 0.5541 - val_loss: 4.3029 - val_acc: 0.1008\n",
            "Epoch 740/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1515 - acc: 0.5536 - val_loss: 4.3906 - val_acc: 0.1804\n",
            "Epoch 741/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1483 - acc: 0.5527 - val_loss: 4.3617 - val_acc: 0.0972\n",
            "Epoch 742/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1519 - acc: 0.5510 - val_loss: 4.3391 - val_acc: 0.1056\n",
            "Epoch 743/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1561 - acc: 0.5512 - val_loss: 4.3185 - val_acc: 0.1056\n",
            "Epoch 744/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1573 - acc: 0.5482 - val_loss: 4.4160 - val_acc: 0.0916\n",
            "Epoch 745/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1551 - acc: 0.5536 - val_loss: 4.2849 - val_acc: 0.0960\n",
            "Epoch 746/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1544 - acc: 0.5509 - val_loss: 4.2802 - val_acc: 0.1032\n",
            "Epoch 747/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1513 - acc: 0.5542 - val_loss: 4.3101 - val_acc: 0.0976\n",
            "Epoch 748/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1525 - acc: 0.5512 - val_loss: 4.3204 - val_acc: 0.1916\n",
            "Epoch 749/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1570 - acc: 0.5520 - val_loss: 4.3283 - val_acc: 0.1988\n",
            "Epoch 750/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1548 - acc: 0.5519 - val_loss: 4.3788 - val_acc: 0.0944\n",
            "Epoch 751/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1552 - acc: 0.5526 - val_loss: 4.3294 - val_acc: 0.1064\n",
            "Epoch 752/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1567 - acc: 0.5516 - val_loss: 4.3268 - val_acc: 0.0908\n",
            "Epoch 753/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1573 - acc: 0.5509 - val_loss: 4.3324 - val_acc: 0.1028\n",
            "Epoch 754/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1544 - acc: 0.5531 - val_loss: 4.3040 - val_acc: 0.1808\n",
            "Epoch 755/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1496 - acc: 0.5545 - val_loss: 4.4024 - val_acc: 0.1764\n",
            "Epoch 756/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1496 - acc: 0.5511 - val_loss: 4.3030 - val_acc: 0.1956\n",
            "Epoch 757/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1514 - acc: 0.5526 - val_loss: 4.2790 - val_acc: 0.1024\n",
            "Epoch 758/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1483 - acc: 0.5560 - val_loss: 4.3260 - val_acc: 0.1868\n",
            "Epoch 759/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1526 - acc: 0.5516 - val_loss: 4.3085 - val_acc: 0.0940\n",
            "Epoch 760/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1533 - acc: 0.5556 - val_loss: 4.3484 - val_acc: 0.1064\n",
            "Epoch 761/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1523 - acc: 0.5517 - val_loss: 4.3594 - val_acc: 0.0980\n",
            "Epoch 762/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1499 - acc: 0.5513 - val_loss: 4.3004 - val_acc: 0.1104\n",
            "Epoch 763/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1508 - acc: 0.5558 - val_loss: 4.2564 - val_acc: 0.1056\n",
            "Epoch 764/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1516 - acc: 0.5522 - val_loss: 4.2920 - val_acc: 0.1156\n",
            "Epoch 765/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1519 - acc: 0.5507 - val_loss: 4.3548 - val_acc: 0.0908\n",
            "Epoch 766/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1534 - acc: 0.5505 - val_loss: 4.3307 - val_acc: 0.0972\n",
            "Epoch 767/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1494 - acc: 0.5520 - val_loss: 4.2088 - val_acc: 0.2164\n",
            "Epoch 768/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1503 - acc: 0.5528 - val_loss: 4.3349 - val_acc: 0.1020\n",
            "Epoch 769/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1480 - acc: 0.5541 - val_loss: 4.2587 - val_acc: 0.1124\n",
            "Epoch 770/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1523 - acc: 0.5523 - val_loss: 4.3114 - val_acc: 0.0964\n",
            "Epoch 771/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1547 - acc: 0.5515 - val_loss: 4.2716 - val_acc: 0.1044\n",
            "Epoch 772/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1546 - acc: 0.5528 - val_loss: 4.2488 - val_acc: 0.2040\n",
            "Epoch 773/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1458 - acc: 0.5533 - val_loss: 4.3087 - val_acc: 0.1112\n",
            "Epoch 774/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1538 - acc: 0.5514 - val_loss: 4.3253 - val_acc: 0.0968\n",
            "Epoch 775/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1504 - acc: 0.5512 - val_loss: 4.3269 - val_acc: 0.1944\n",
            "Epoch 776/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1531 - acc: 0.5505 - val_loss: 4.2558 - val_acc: 0.1112\n",
            "Epoch 777/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1533 - acc: 0.5530 - val_loss: 4.2863 - val_acc: 0.1140\n",
            "Epoch 778/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1546 - acc: 0.5534 - val_loss: 4.3839 - val_acc: 0.1904\n",
            "Epoch 779/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1549 - acc: 0.5493 - val_loss: 4.3735 - val_acc: 0.0864\n",
            "Epoch 780/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1531 - acc: 0.5534 - val_loss: 4.3589 - val_acc: 0.0900\n",
            "Epoch 781/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1481 - acc: 0.5540 - val_loss: 4.3110 - val_acc: 0.1028\n",
            "Epoch 782/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1479 - acc: 0.5537 - val_loss: 4.4925 - val_acc: 0.1740\n",
            "Epoch 783/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1517 - acc: 0.5520 - val_loss: 4.2894 - val_acc: 0.1072\n",
            "Epoch 784/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1557 - acc: 0.5486 - val_loss: 4.3245 - val_acc: 0.0904\n",
            "Epoch 785/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1520 - acc: 0.5523 - val_loss: 4.2790 - val_acc: 0.1184\n",
            "Epoch 786/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1529 - acc: 0.5508 - val_loss: 4.4021 - val_acc: 0.0816\n",
            "Epoch 787/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1542 - acc: 0.5491 - val_loss: 4.3111 - val_acc: 0.1140\n",
            "Epoch 788/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1489 - acc: 0.5535 - val_loss: 4.2710 - val_acc: 0.2064\n",
            "Epoch 789/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1496 - acc: 0.5518 - val_loss: 4.2844 - val_acc: 0.1120\n",
            "Epoch 790/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1527 - acc: 0.5507 - val_loss: 4.4002 - val_acc: 0.0896\n",
            "Epoch 791/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1513 - acc: 0.5527 - val_loss: 4.2705 - val_acc: 0.0996\n",
            "Epoch 792/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1505 - acc: 0.5535 - val_loss: 4.3778 - val_acc: 0.0964\n",
            "Epoch 793/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1528 - acc: 0.5514 - val_loss: 4.2257 - val_acc: 0.2016\n",
            "Epoch 794/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1495 - acc: 0.5514 - val_loss: 4.2709 - val_acc: 0.1856\n",
            "Epoch 795/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1503 - acc: 0.5517 - val_loss: 4.2992 - val_acc: 0.1896\n",
            "Epoch 796/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1529 - acc: 0.5472 - val_loss: 4.4368 - val_acc: 0.1640\n",
            "Epoch 797/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1522 - acc: 0.5527 - val_loss: 4.3392 - val_acc: 0.0964\n",
            "Epoch 798/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1547 - acc: 0.5512 - val_loss: 4.3173 - val_acc: 0.1012\n",
            "Epoch 799/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1569 - acc: 0.5493 - val_loss: 4.3888 - val_acc: 0.0976\n",
            "Epoch 800/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1528 - acc: 0.5524 - val_loss: 4.3527 - val_acc: 0.0956\n",
            "Epoch 801/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1477 - acc: 0.5537 - val_loss: 4.3412 - val_acc: 0.0960\n",
            "Epoch 802/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1550 - acc: 0.5516 - val_loss: 4.2907 - val_acc: 0.1012\n",
            "Epoch 803/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1475 - acc: 0.5521 - val_loss: 4.3890 - val_acc: 0.0936\n",
            "Epoch 804/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1520 - acc: 0.5523 - val_loss: 4.4077 - val_acc: 0.0832\n",
            "Epoch 805/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1486 - acc: 0.5524 - val_loss: 4.3711 - val_acc: 0.1940\n",
            "Epoch 806/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1541 - acc: 0.5496 - val_loss: 4.3539 - val_acc: 0.0880\n",
            "Epoch 807/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1479 - acc: 0.5537 - val_loss: 4.3461 - val_acc: 0.0936\n",
            "Epoch 808/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1503 - acc: 0.5512 - val_loss: 4.2560 - val_acc: 0.1108\n",
            "Epoch 809/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1467 - acc: 0.5549 - val_loss: 4.3211 - val_acc: 0.0940\n",
            "Epoch 810/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1528 - acc: 0.5517 - val_loss: 4.2094 - val_acc: 0.1264\n",
            "Epoch 811/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1485 - acc: 0.5521 - val_loss: 4.2908 - val_acc: 0.1064\n",
            "Epoch 812/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1546 - acc: 0.5491 - val_loss: 4.3061 - val_acc: 0.0988\n",
            "Epoch 813/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1524 - acc: 0.5528 - val_loss: 4.3900 - val_acc: 0.0972\n",
            "Epoch 814/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1524 - acc: 0.5521 - val_loss: 4.3827 - val_acc: 0.1004\n",
            "Epoch 815/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1499 - acc: 0.5526 - val_loss: 4.3418 - val_acc: 0.1028\n",
            "Epoch 816/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1462 - acc: 0.5552 - val_loss: 4.3171 - val_acc: 0.1088\n",
            "Epoch 817/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1456 - acc: 0.5538 - val_loss: 4.3684 - val_acc: 0.1028\n",
            "Epoch 818/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1530 - acc: 0.5491 - val_loss: 4.3406 - val_acc: 0.1164\n",
            "Epoch 819/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1497 - acc: 0.5539 - val_loss: 4.4274 - val_acc: 0.0932\n",
            "Epoch 820/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1495 - acc: 0.5542 - val_loss: 4.2862 - val_acc: 0.2148\n",
            "Epoch 821/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1475 - acc: 0.5550 - val_loss: 4.4468 - val_acc: 0.1852\n",
            "Epoch 822/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1482 - acc: 0.5534 - val_loss: 4.3268 - val_acc: 0.1016\n",
            "Epoch 823/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1507 - acc: 0.5530 - val_loss: 4.3668 - val_acc: 0.1004\n",
            "Epoch 824/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1537 - acc: 0.5499 - val_loss: 4.3324 - val_acc: 0.1100\n",
            "Epoch 825/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1456 - acc: 0.5540 - val_loss: 4.3629 - val_acc: 0.0800\n",
            "Epoch 826/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1467 - acc: 0.5517 - val_loss: 4.3450 - val_acc: 0.1052\n",
            "Epoch 827/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1492 - acc: 0.5504 - val_loss: 4.5106 - val_acc: 0.0716\n",
            "Epoch 828/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1538 - acc: 0.5508 - val_loss: 4.3239 - val_acc: 0.1012\n",
            "Epoch 829/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1473 - acc: 0.5516 - val_loss: 4.3761 - val_acc: 0.1776\n",
            "Epoch 830/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1525 - acc: 0.5517 - val_loss: 4.3233 - val_acc: 0.1108\n",
            "Epoch 831/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1498 - acc: 0.5517 - val_loss: 4.3561 - val_acc: 0.1840\n",
            "Epoch 832/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1509 - acc: 0.5537 - val_loss: 4.3689 - val_acc: 0.0976\n",
            "Epoch 833/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1435 - acc: 0.5542 - val_loss: 4.4240 - val_acc: 0.0912\n",
            "Epoch 834/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1535 - acc: 0.5540 - val_loss: 4.4284 - val_acc: 0.0836\n",
            "Epoch 835/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1540 - acc: 0.5511 - val_loss: 4.4317 - val_acc: 0.0836\n",
            "Epoch 836/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1545 - acc: 0.5532 - val_loss: 4.3756 - val_acc: 0.0912\n",
            "Epoch 837/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1513 - acc: 0.5540 - val_loss: 4.3341 - val_acc: 0.1004\n",
            "Epoch 838/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1481 - acc: 0.5535 - val_loss: 4.3875 - val_acc: 0.0988\n",
            "Epoch 839/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1493 - acc: 0.5521 - val_loss: 4.3349 - val_acc: 0.1080\n",
            "Epoch 840/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1523 - acc: 0.5504 - val_loss: 4.3246 - val_acc: 0.1032\n",
            "Epoch 841/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1520 - acc: 0.5519 - val_loss: 4.4289 - val_acc: 0.0960\n",
            "Epoch 842/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1537 - acc: 0.5518 - val_loss: 4.3757 - val_acc: 0.0916\n",
            "Epoch 843/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1479 - acc: 0.5544 - val_loss: 4.4665 - val_acc: 0.0836\n",
            "Epoch 844/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1527 - acc: 0.5483 - val_loss: 4.3903 - val_acc: 0.0848\n",
            "Epoch 845/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1480 - acc: 0.5529 - val_loss: 4.3562 - val_acc: 0.1024\n",
            "Epoch 846/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1501 - acc: 0.5516 - val_loss: 4.3295 - val_acc: 0.1008\n",
            "Epoch 847/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1507 - acc: 0.5525 - val_loss: 4.3490 - val_acc: 0.1864\n",
            "Epoch 848/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1527 - acc: 0.5510 - val_loss: 4.2354 - val_acc: 0.2108\n",
            "Epoch 849/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1450 - acc: 0.5523 - val_loss: 4.4034 - val_acc: 0.1000\n",
            "Epoch 850/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1488 - acc: 0.5549 - val_loss: 4.4040 - val_acc: 0.0932\n",
            "Epoch 851/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1558 - acc: 0.5498 - val_loss: 4.3185 - val_acc: 0.1028\n",
            "Epoch 852/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1470 - acc: 0.5555 - val_loss: 4.3088 - val_acc: 0.1028\n",
            "Epoch 853/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1516 - acc: 0.5508 - val_loss: 4.2502 - val_acc: 0.2032\n",
            "Epoch 854/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1458 - acc: 0.5530 - val_loss: 4.3827 - val_acc: 0.1748\n",
            "Epoch 855/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1543 - acc: 0.5507 - val_loss: 4.3566 - val_acc: 0.0896\n",
            "Epoch 856/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1505 - acc: 0.5548 - val_loss: 4.2770 - val_acc: 0.1936\n",
            "Epoch 857/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1516 - acc: 0.5510 - val_loss: 4.4010 - val_acc: 0.0992\n",
            "Epoch 858/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1482 - acc: 0.5543 - val_loss: 4.3559 - val_acc: 0.1040\n",
            "Epoch 859/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1469 - acc: 0.5520 - val_loss: 4.3855 - val_acc: 0.0864\n",
            "Epoch 860/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1469 - acc: 0.5549 - val_loss: 4.2657 - val_acc: 0.1084\n",
            "Epoch 861/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1468 - acc: 0.5508 - val_loss: 4.4169 - val_acc: 0.0976\n",
            "Epoch 862/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1477 - acc: 0.5552 - val_loss: 4.3100 - val_acc: 0.1068\n",
            "Epoch 863/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1507 - acc: 0.5538 - val_loss: 4.3976 - val_acc: 0.1856\n",
            "Epoch 864/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1492 - acc: 0.5493 - val_loss: 4.3479 - val_acc: 0.0968\n",
            "Epoch 865/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1496 - acc: 0.5513 - val_loss: 4.3424 - val_acc: 0.0924\n",
            "Epoch 866/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1507 - acc: 0.5540 - val_loss: 4.3751 - val_acc: 0.1020\n",
            "Epoch 867/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1490 - acc: 0.5502 - val_loss: 4.3432 - val_acc: 0.0952\n",
            "Epoch 868/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1483 - acc: 0.5548 - val_loss: 4.3451 - val_acc: 0.0812\n",
            "Epoch 869/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1474 - acc: 0.5538 - val_loss: 4.3613 - val_acc: 0.1088\n",
            "Epoch 870/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1501 - acc: 0.5547 - val_loss: 4.3824 - val_acc: 0.0992\n",
            "Epoch 871/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1523 - acc: 0.5502 - val_loss: 4.4258 - val_acc: 0.0920\n",
            "Epoch 872/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1485 - acc: 0.5528 - val_loss: 4.3388 - val_acc: 0.0928\n",
            "Epoch 873/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1474 - acc: 0.5547 - val_loss: 4.3171 - val_acc: 0.0912\n",
            "Epoch 874/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1483 - acc: 0.5513 - val_loss: 4.3046 - val_acc: 0.1012\n",
            "Epoch 875/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1485 - acc: 0.5531 - val_loss: 4.3270 - val_acc: 0.1056\n",
            "Epoch 876/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1502 - acc: 0.5543 - val_loss: 4.3348 - val_acc: 0.2012\n",
            "Epoch 877/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1469 - acc: 0.5553 - val_loss: 4.3137 - val_acc: 0.1940\n",
            "Epoch 878/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1508 - acc: 0.5524 - val_loss: 4.3761 - val_acc: 0.0972\n",
            "Epoch 879/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1509 - acc: 0.5516 - val_loss: 4.3592 - val_acc: 0.1908\n",
            "Epoch 880/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1528 - acc: 0.5516 - val_loss: 4.3199 - val_acc: 0.0960\n",
            "Epoch 881/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1446 - acc: 0.5528 - val_loss: 4.2506 - val_acc: 0.1164\n",
            "Epoch 882/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1469 - acc: 0.5526 - val_loss: 4.3144 - val_acc: 0.1084\n",
            "Epoch 883/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1480 - acc: 0.5540 - val_loss: 4.4137 - val_acc: 0.1812\n",
            "Epoch 884/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1480 - acc: 0.5539 - val_loss: 4.4418 - val_acc: 0.0860\n",
            "Epoch 885/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1500 - acc: 0.5521 - val_loss: 4.2644 - val_acc: 0.2128\n",
            "Epoch 886/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1485 - acc: 0.5533 - val_loss: 4.3443 - val_acc: 0.0980\n",
            "Epoch 887/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1460 - acc: 0.5522 - val_loss: 4.3621 - val_acc: 0.1020\n",
            "Epoch 888/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1447 - acc: 0.5557 - val_loss: 4.4012 - val_acc: 0.0944\n",
            "Epoch 889/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1503 - acc: 0.5543 - val_loss: 4.3197 - val_acc: 0.1004\n",
            "Epoch 890/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1484 - acc: 0.5546 - val_loss: 4.3976 - val_acc: 0.0984\n",
            "Epoch 891/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1549 - acc: 0.5502 - val_loss: 4.3790 - val_acc: 0.0976\n",
            "Epoch 892/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1501 - acc: 0.5500 - val_loss: 4.3479 - val_acc: 0.0944\n",
            "Epoch 893/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1515 - acc: 0.5530 - val_loss: 4.3855 - val_acc: 0.1788\n",
            "Epoch 894/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1466 - acc: 0.5546 - val_loss: 4.4353 - val_acc: 0.1768\n",
            "Epoch 895/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1494 - acc: 0.5516 - val_loss: 4.3047 - val_acc: 0.1940\n",
            "Epoch 896/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1526 - acc: 0.5513 - val_loss: 4.3839 - val_acc: 0.1840\n",
            "Epoch 897/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1521 - acc: 0.5533 - val_loss: 4.3822 - val_acc: 0.0988\n",
            "Epoch 898/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1496 - acc: 0.5490 - val_loss: 4.3650 - val_acc: 0.1048\n",
            "Epoch 899/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1472 - acc: 0.5550 - val_loss: 4.4775 - val_acc: 0.0848\n",
            "Epoch 900/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1515 - acc: 0.5536 - val_loss: 4.2930 - val_acc: 0.0964\n",
            "Epoch 901/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1471 - acc: 0.5516 - val_loss: 4.3223 - val_acc: 0.1024\n",
            "Epoch 902/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1502 - acc: 0.5489 - val_loss: 4.4426 - val_acc: 0.0804\n",
            "Epoch 903/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1483 - acc: 0.5528 - val_loss: 4.3012 - val_acc: 0.0992\n",
            "Epoch 904/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1500 - acc: 0.5541 - val_loss: 4.4165 - val_acc: 0.1792\n",
            "Epoch 905/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1489 - acc: 0.5517 - val_loss: 4.2937 - val_acc: 0.1204\n",
            "Epoch 906/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1501 - acc: 0.5509 - val_loss: 4.3364 - val_acc: 0.1120\n",
            "Epoch 907/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1468 - acc: 0.5510 - val_loss: 4.3384 - val_acc: 0.0976\n",
            "Epoch 908/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1501 - acc: 0.5516 - val_loss: 4.3572 - val_acc: 0.0944\n",
            "Epoch 909/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1455 - acc: 0.5543 - val_loss: 4.3309 - val_acc: 0.0980\n",
            "Epoch 910/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1457 - acc: 0.5545 - val_loss: 4.4337 - val_acc: 0.0888\n",
            "Epoch 911/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1479 - acc: 0.5557 - val_loss: 4.4698 - val_acc: 0.0856\n",
            "Epoch 912/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1517 - acc: 0.5509 - val_loss: 4.3028 - val_acc: 0.1036\n",
            "Epoch 913/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1465 - acc: 0.5552 - val_loss: 4.3516 - val_acc: 0.0948\n",
            "Epoch 914/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1472 - acc: 0.5564 - val_loss: 4.3459 - val_acc: 0.0932\n",
            "Epoch 915/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1495 - acc: 0.5517 - val_loss: 4.3703 - val_acc: 0.1852\n",
            "Epoch 916/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1463 - acc: 0.5539 - val_loss: 4.2995 - val_acc: 0.1096\n",
            "Epoch 917/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1482 - acc: 0.5518 - val_loss: 4.3028 - val_acc: 0.2016\n",
            "Epoch 918/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1513 - acc: 0.5530 - val_loss: 4.2792 - val_acc: 0.1200\n",
            "Epoch 919/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1469 - acc: 0.5526 - val_loss: 4.2721 - val_acc: 0.1008\n",
            "Epoch 920/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1515 - acc: 0.5511 - val_loss: 4.3438 - val_acc: 0.1792\n",
            "Epoch 921/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1495 - acc: 0.5546 - val_loss: 4.3328 - val_acc: 0.0972\n",
            "Epoch 922/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1487 - acc: 0.5523 - val_loss: 4.3576 - val_acc: 0.0940\n",
            "Epoch 923/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1486 - acc: 0.5538 - val_loss: 4.3046 - val_acc: 0.1108\n",
            "Epoch 924/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1486 - acc: 0.5514 - val_loss: 4.3899 - val_acc: 0.2004\n",
            "Epoch 925/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1463 - acc: 0.5555 - val_loss: 4.3734 - val_acc: 0.1012\n",
            "Epoch 926/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1516 - acc: 0.5531 - val_loss: 4.3553 - val_acc: 0.0916\n",
            "Epoch 927/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1475 - acc: 0.5552 - val_loss: 4.3969 - val_acc: 0.0924\n",
            "Epoch 928/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1466 - acc: 0.5544 - val_loss: 4.3676 - val_acc: 0.0976\n",
            "Epoch 929/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1448 - acc: 0.5517 - val_loss: 4.3322 - val_acc: 0.1024\n",
            "Epoch 930/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1460 - acc: 0.5537 - val_loss: 4.2681 - val_acc: 0.1208\n",
            "Epoch 931/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1485 - acc: 0.5490 - val_loss: 4.4076 - val_acc: 0.0956\n",
            "Epoch 932/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1498 - acc: 0.5543 - val_loss: 4.3606 - val_acc: 0.0940\n",
            "Epoch 933/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1516 - acc: 0.5525 - val_loss: 4.3478 - val_acc: 0.0964\n",
            "Epoch 934/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1457 - acc: 0.5525 - val_loss: 4.3145 - val_acc: 0.1136\n",
            "Epoch 935/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1495 - acc: 0.5526 - val_loss: 4.3918 - val_acc: 0.0868\n",
            "Epoch 936/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1418 - acc: 0.5536 - val_loss: 4.3847 - val_acc: 0.0972\n",
            "Epoch 937/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1428 - acc: 0.5547 - val_loss: 4.3184 - val_acc: 0.2080\n",
            "Epoch 938/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1491 - acc: 0.5541 - val_loss: 4.3320 - val_acc: 0.1136\n",
            "Epoch 939/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1449 - acc: 0.5530 - val_loss: 4.3898 - val_acc: 0.0968\n",
            "Epoch 940/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1451 - acc: 0.5532 - val_loss: 4.3185 - val_acc: 0.1076\n",
            "Epoch 941/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1460 - acc: 0.5549 - val_loss: 4.3135 - val_acc: 0.1964\n",
            "Epoch 942/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1465 - acc: 0.5503 - val_loss: 4.3300 - val_acc: 0.0992\n",
            "Epoch 943/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1414 - acc: 0.5561 - val_loss: 4.3230 - val_acc: 0.1960\n",
            "Epoch 944/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1484 - acc: 0.5546 - val_loss: 4.3551 - val_acc: 0.1020\n",
            "Epoch 945/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1430 - acc: 0.5546 - val_loss: 4.4276 - val_acc: 0.0904\n",
            "Epoch 946/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1512 - acc: 0.5499 - val_loss: 4.3556 - val_acc: 0.1872\n",
            "Epoch 947/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1458 - acc: 0.5533 - val_loss: 4.4380 - val_acc: 0.0892\n",
            "Epoch 948/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1470 - acc: 0.5532 - val_loss: 4.2914 - val_acc: 0.1144\n",
            "Epoch 949/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1485 - acc: 0.5515 - val_loss: 4.3632 - val_acc: 0.1056\n",
            "Epoch 950/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1480 - acc: 0.5519 - val_loss: 4.2593 - val_acc: 0.2064\n",
            "Epoch 951/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1473 - acc: 0.5520 - val_loss: 4.3452 - val_acc: 0.0984\n",
            "Epoch 952/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1457 - acc: 0.5559 - val_loss: 4.3318 - val_acc: 0.0944\n",
            "Epoch 953/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1495 - acc: 0.5523 - val_loss: 4.3388 - val_acc: 0.0976\n",
            "Epoch 954/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1477 - acc: 0.5576 - val_loss: 4.3298 - val_acc: 0.0984\n",
            "Epoch 955/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1473 - acc: 0.5528 - val_loss: 4.2927 - val_acc: 0.1092\n",
            "Epoch 956/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1498 - acc: 0.5535 - val_loss: 4.4138 - val_acc: 0.0940\n",
            "Epoch 957/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1470 - acc: 0.5503 - val_loss: 4.2719 - val_acc: 0.1096\n",
            "Epoch 958/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1464 - acc: 0.5500 - val_loss: 4.3897 - val_acc: 0.0884\n",
            "Epoch 959/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1486 - acc: 0.5529 - val_loss: 4.3360 - val_acc: 0.1072\n",
            "Epoch 960/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1415 - acc: 0.5546 - val_loss: 4.3023 - val_acc: 0.1860\n",
            "Epoch 961/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1438 - acc: 0.5535 - val_loss: 4.3503 - val_acc: 0.1820\n",
            "Epoch 962/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1428 - acc: 0.5547 - val_loss: 4.4458 - val_acc: 0.1800\n",
            "Epoch 963/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1454 - acc: 0.5526 - val_loss: 4.3136 - val_acc: 0.1964\n",
            "Epoch 964/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1445 - acc: 0.5533 - val_loss: 4.3266 - val_acc: 0.1916\n",
            "Epoch 965/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1491 - acc: 0.5521 - val_loss: 4.3114 - val_acc: 0.1100\n",
            "Epoch 966/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1484 - acc: 0.5507 - val_loss: 4.3760 - val_acc: 0.0960\n",
            "Epoch 967/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1485 - acc: 0.5525 - val_loss: 4.2841 - val_acc: 0.2108\n",
            "Epoch 968/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1462 - acc: 0.5548 - val_loss: 4.3275 - val_acc: 0.1028\n",
            "Epoch 969/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1458 - acc: 0.5540 - val_loss: 4.3318 - val_acc: 0.1052\n",
            "Epoch 970/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1461 - acc: 0.5522 - val_loss: 4.3453 - val_acc: 0.1904\n",
            "Epoch 971/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1439 - acc: 0.5553 - val_loss: 4.3822 - val_acc: 0.0952\n",
            "Epoch 972/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1471 - acc: 0.5539 - val_loss: 4.2962 - val_acc: 0.1012\n",
            "Epoch 973/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1454 - acc: 0.5541 - val_loss: 4.3159 - val_acc: 0.1044\n",
            "Epoch 974/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1409 - acc: 0.5527 - val_loss: 4.3096 - val_acc: 0.0964\n",
            "Epoch 975/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1474 - acc: 0.5523 - val_loss: 4.3094 - val_acc: 0.1016\n",
            "Epoch 976/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1483 - acc: 0.5532 - val_loss: 4.3327 - val_acc: 0.1952\n",
            "Epoch 977/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1463 - acc: 0.5549 - val_loss: 4.3150 - val_acc: 0.1020\n",
            "Epoch 978/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1458 - acc: 0.5521 - val_loss: 4.2737 - val_acc: 0.1084\n",
            "Epoch 979/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1446 - acc: 0.5559 - val_loss: 4.3220 - val_acc: 0.0992\n",
            "Epoch 980/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1509 - acc: 0.5500 - val_loss: 4.3197 - val_acc: 0.1968\n",
            "Epoch 981/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1460 - acc: 0.5520 - val_loss: 4.2177 - val_acc: 0.1092\n",
            "Epoch 982/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.1491 - acc: 0.5495 - val_loss: 4.3697 - val_acc: 0.0840\n",
            "Epoch 983/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1460 - acc: 0.5521 - val_loss: 4.2815 - val_acc: 0.1176\n",
            "Epoch 984/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1463 - acc: 0.5524 - val_loss: 4.2276 - val_acc: 0.1176\n",
            "Epoch 985/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1453 - acc: 0.5547 - val_loss: 4.3142 - val_acc: 0.1012\n",
            "Epoch 986/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1513 - acc: 0.5500 - val_loss: 4.2755 - val_acc: 0.2012\n",
            "Epoch 987/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1470 - acc: 0.5525 - val_loss: 4.4067 - val_acc: 0.0868\n",
            "Epoch 988/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1466 - acc: 0.5541 - val_loss: 4.3532 - val_acc: 0.1092\n",
            "Epoch 989/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1481 - acc: 0.5537 - val_loss: 4.3141 - val_acc: 0.1132\n",
            "Epoch 990/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1494 - acc: 0.5514 - val_loss: 4.2653 - val_acc: 0.1068\n",
            "Epoch 991/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1440 - acc: 0.5520 - val_loss: 4.3655 - val_acc: 0.0888\n",
            "Epoch 992/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.1508 - acc: 0.5511 - val_loss: 4.2754 - val_acc: 0.1156\n",
            "Epoch 993/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1513 - acc: 0.5534 - val_loss: 4.3057 - val_acc: 0.1972\n",
            "Epoch 994/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1432 - acc: 0.5544 - val_loss: 4.3487 - val_acc: 0.1780\n",
            "Epoch 995/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1441 - acc: 0.5523 - val_loss: 4.2832 - val_acc: 0.1928\n",
            "Epoch 996/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1489 - acc: 0.5536 - val_loss: 4.2723 - val_acc: 0.1992\n",
            "Epoch 997/1000\n",
            "22500/22500 [==============================] - 2s 92us/step - loss: 1.1470 - acc: 0.5531 - val_loss: 4.3649 - val_acc: 0.1144\n",
            "Epoch 998/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1419 - acc: 0.5510 - val_loss: 4.3159 - val_acc: 0.1944\n",
            "Epoch 999/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 1.1435 - acc: 0.5543 - val_loss: 4.3735 - val_acc: 0.1000\n",
            "Epoch 1000/1000\n",
            "22500/22500 [==============================] - 2s 94us/step - loss: 1.1407 - acc: 0.5533 - val_loss: 4.4564 - val_acc: 0.0824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DtC6lLmljdMp",
        "colab_type": "code",
        "outputId": "59558397-f36b-4167-c12d-25038d95e3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                       batch_size=100, verbose=1)\n",
        "print('Test accuracy:', score[1]) # низкая accuracy на test и validation, переобучилась :("
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 22us/step\n",
            "Test accuracy: 0.16132000013440848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tjggAhwhLlEc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training neural network with GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "5gXmb0Ogcv92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"embeddings (1).zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-isLJ2-ptw32",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loading the whole embedding in a memory as a dict\n",
        "\n",
        "embeddings_index = dict()\n",
        "with open('glove.6B.50d.txt') as file:\n",
        "  for line in file:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "#creating a matrix for words from our reviews\n",
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word, i in vocab.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5gwsUudcLkOR",
        "colab_type": "code",
        "outputId": "716f63de-026b-4799-cc69-2e2e57abe43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34493
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(L.Embedding(vocab_size, 50, weights=[embedding_matrix], input_length=100, trainable=False))\n",
        "model.add(L.Flatten())\n",
        "model.add(L.Dense(512))\n",
        "model.add(L.Activation('sigmoid'))\n",
        "model.add(L.Dropout(0.2))\n",
        "model.add(L.Dense(256))\n",
        "model.add(L.Activation('relu'))\n",
        "model.add(L.Dropout(0.5))\n",
        "model.add(L.Dense(8))\n",
        "model.add(L.Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=100,\n",
        "                    epochs=1000,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 50)           6149300   \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 512)               2560512   \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 8)                 2056      \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8)                 0         \n",
            "=================================================================\n",
            "Total params: 8,843,196\n",
            "Trainable params: 2,693,896\n",
            "Non-trainable params: 6,149,300\n",
            "_________________________________________________________________\n",
            "Train on 22500 samples, validate on 2500 samples\n",
            "Epoch 1/1000\n",
            "22500/22500 [==============================] - 3s 138us/step - loss: 2.0279 - acc: 0.2194 - val_loss: 2.0960 - val_acc: 0.2464\n",
            "Epoch 2/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 1.9111 - acc: 0.2800 - val_loss: 1.9439 - val_acc: 0.3196\n",
            "Epoch 3/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.8228 - acc: 0.3165 - val_loss: 1.8174 - val_acc: 0.3464\n",
            "Epoch 4/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.7520 - acc: 0.3406 - val_loss: 2.0772 - val_acc: 0.2580\n",
            "Epoch 5/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.6712 - acc: 0.3743 - val_loss: 1.9439 - val_acc: 0.2980\n",
            "Epoch 6/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.5561 - acc: 0.4183 - val_loss: 2.1376 - val_acc: 0.2464\n",
            "Epoch 7/1000\n",
            "22500/22500 [==============================] - 2s 93us/step - loss: 1.3897 - acc: 0.4804 - val_loss: 2.2743 - val_acc: 0.2464\n",
            "Epoch 8/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 1.1767 - acc: 0.5688 - val_loss: 2.4696 - val_acc: 0.2464\n",
            "Epoch 9/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 0.9275 - acc: 0.6652 - val_loss: 2.9965 - val_acc: 0.2168\n",
            "Epoch 10/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.6801 - acc: 0.7608 - val_loss: 3.0700 - val_acc: 0.2212\n",
            "Epoch 11/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.4908 - acc: 0.8334 - val_loss: 3.5871 - val_acc: 0.2132\n",
            "Epoch 12/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.3592 - acc: 0.8785 - val_loss: 3.6820 - val_acc: 0.2244\n",
            "Epoch 13/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.2845 - acc: 0.9069 - val_loss: 3.7173 - val_acc: 0.2340\n",
            "Epoch 14/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.2182 - acc: 0.9274 - val_loss: 3.7873 - val_acc: 0.2500\n",
            "Epoch 15/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.1847 - acc: 0.9404 - val_loss: 4.4246 - val_acc: 0.2508\n",
            "Epoch 16/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.1572 - acc: 0.9492 - val_loss: 4.8046 - val_acc: 0.2044\n",
            "Epoch 17/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.1445 - acc: 0.9537 - val_loss: 4.2917 - val_acc: 0.2448\n",
            "Epoch 18/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.1334 - acc: 0.9572 - val_loss: 4.5061 - val_acc: 0.2356\n",
            "Epoch 19/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.1270 - acc: 0.9578 - val_loss: 4.6480 - val_acc: 0.2256\n",
            "Epoch 20/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.1124 - acc: 0.9621 - val_loss: 5.0051 - val_acc: 0.2124\n",
            "Epoch 21/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.1027 - acc: 0.9674 - val_loss: 4.8943 - val_acc: 0.2268\n",
            "Epoch 22/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.1065 - acc: 0.9649 - val_loss: 5.2853 - val_acc: 0.2068\n",
            "Epoch 23/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.1043 - acc: 0.9652 - val_loss: 4.8908 - val_acc: 0.2228\n",
            "Epoch 24/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.1082 - acc: 0.9643 - val_loss: 4.5192 - val_acc: 0.2664\n",
            "Epoch 25/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0936 - acc: 0.9700 - val_loss: 5.5464 - val_acc: 0.2132\n",
            "Epoch 26/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.1012 - acc: 0.9675 - val_loss: 5.2207 - val_acc: 0.2268\n",
            "Epoch 27/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0965 - acc: 0.9677 - val_loss: 5.3753 - val_acc: 0.2096\n",
            "Epoch 28/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0977 - acc: 0.9686 - val_loss: 5.2299 - val_acc: 0.2428\n",
            "Epoch 29/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0800 - acc: 0.9739 - val_loss: 5.2879 - val_acc: 0.2044\n",
            "Epoch 30/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0795 - acc: 0.9730 - val_loss: 5.6362 - val_acc: 0.2244\n",
            "Epoch 31/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0859 - acc: 0.9728 - val_loss: 5.2777 - val_acc: 0.2244\n",
            "Epoch 32/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0765 - acc: 0.9748 - val_loss: 5.5059 - val_acc: 0.2112\n",
            "Epoch 33/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0721 - acc: 0.9762 - val_loss: 5.5645 - val_acc: 0.2204\n",
            "Epoch 34/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0726 - acc: 0.9760 - val_loss: 5.4206 - val_acc: 0.2116\n",
            "Epoch 35/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0763 - acc: 0.9734 - val_loss: 5.9160 - val_acc: 0.2032\n",
            "Epoch 36/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0785 - acc: 0.9738 - val_loss: 5.3956 - val_acc: 0.2136\n",
            "Epoch 37/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0779 - acc: 0.9746 - val_loss: 5.4069 - val_acc: 0.2196\n",
            "Epoch 38/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 0.0752 - acc: 0.9746 - val_loss: 5.1153 - val_acc: 0.2400\n",
            "Epoch 39/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0774 - acc: 0.9752 - val_loss: 5.0533 - val_acc: 0.2588\n",
            "Epoch 40/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0652 - acc: 0.9789 - val_loss: 5.8817 - val_acc: 0.2036\n",
            "Epoch 41/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0669 - acc: 0.9778 - val_loss: 5.5238 - val_acc: 0.2152\n",
            "Epoch 42/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0682 - acc: 0.9777 - val_loss: 5.4753 - val_acc: 0.2280\n",
            "Epoch 43/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0748 - acc: 0.9758 - val_loss: 5.2877 - val_acc: 0.2320\n",
            "Epoch 44/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0653 - acc: 0.9787 - val_loss: 5.3624 - val_acc: 0.2296\n",
            "Epoch 45/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0725 - acc: 0.9756 - val_loss: 5.3942 - val_acc: 0.2448\n",
            "Epoch 46/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0735 - acc: 0.9765 - val_loss: 5.3765 - val_acc: 0.2504\n",
            "Epoch 47/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0733 - acc: 0.9772 - val_loss: 5.5095 - val_acc: 0.2076\n",
            "Epoch 48/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0584 - acc: 0.9810 - val_loss: 5.6038 - val_acc: 0.2364\n",
            "Epoch 49/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0705 - acc: 0.9776 - val_loss: 5.6091 - val_acc: 0.2196\n",
            "Epoch 50/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0611 - acc: 0.9807 - val_loss: 6.3233 - val_acc: 0.2044\n",
            "Epoch 51/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0559 - acc: 0.9810 - val_loss: 5.8026 - val_acc: 0.2308\n",
            "Epoch 52/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0682 - acc: 0.9778 - val_loss: 5.7456 - val_acc: 0.2100\n",
            "Epoch 53/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0580 - acc: 0.9816 - val_loss: 5.7558 - val_acc: 0.2352\n",
            "Epoch 54/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0577 - acc: 0.9812 - val_loss: 5.8297 - val_acc: 0.2176\n",
            "Epoch 55/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0552 - acc: 0.9823 - val_loss: 5.7918 - val_acc: 0.2164\n",
            "Epoch 56/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0618 - acc: 0.9802 - val_loss: 5.8819 - val_acc: 0.2220\n",
            "Epoch 57/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0663 - acc: 0.9792 - val_loss: 5.5086 - val_acc: 0.2560\n",
            "Epoch 58/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0602 - acc: 0.9808 - val_loss: 5.9318 - val_acc: 0.2248\n",
            "Epoch 59/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0622 - acc: 0.9796 - val_loss: 5.6343 - val_acc: 0.2380\n",
            "Epoch 60/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0605 - acc: 0.9799 - val_loss: 6.0237 - val_acc: 0.2212\n",
            "Epoch 61/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0512 - acc: 0.9832 - val_loss: 5.7655 - val_acc: 0.2600\n",
            "Epoch 62/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0516 - acc: 0.9838 - val_loss: 6.1198 - val_acc: 0.2156\n",
            "Epoch 63/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0501 - acc: 0.9848 - val_loss: 5.9483 - val_acc: 0.2268\n",
            "Epoch 64/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0600 - acc: 0.9805 - val_loss: 5.9475 - val_acc: 0.2376\n",
            "Epoch 65/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0590 - acc: 0.9816 - val_loss: 6.1745 - val_acc: 0.1900\n",
            "Epoch 66/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0581 - acc: 0.9816 - val_loss: 5.5118 - val_acc: 0.2356\n",
            "Epoch 67/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0546 - acc: 0.9816 - val_loss: 5.6860 - val_acc: 0.2244\n",
            "Epoch 68/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0567 - acc: 0.9815 - val_loss: 5.7101 - val_acc: 0.2292\n",
            "Epoch 69/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0555 - acc: 0.9820 - val_loss: 5.7023 - val_acc: 0.2320\n",
            "Epoch 70/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0578 - acc: 0.9822 - val_loss: 6.3233 - val_acc: 0.2016\n",
            "Epoch 71/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0522 - acc: 0.9837 - val_loss: 6.0385 - val_acc: 0.2224\n",
            "Epoch 72/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0534 - acc: 0.9825 - val_loss: 5.7987 - val_acc: 0.2124\n",
            "Epoch 73/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0484 - acc: 0.9849 - val_loss: 6.5940 - val_acc: 0.1888\n",
            "Epoch 74/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0524 - acc: 0.9827 - val_loss: 6.3139 - val_acc: 0.2072\n",
            "Epoch 75/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0487 - acc: 0.9843 - val_loss: 5.9685 - val_acc: 0.2140\n",
            "Epoch 76/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0455 - acc: 0.9854 - val_loss: 6.3085 - val_acc: 0.2044\n",
            "Epoch 77/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0513 - acc: 0.9835 - val_loss: 6.2102 - val_acc: 0.2328\n",
            "Epoch 78/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0454 - acc: 0.9852 - val_loss: 6.0851 - val_acc: 0.2240\n",
            "Epoch 79/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0505 - acc: 0.9830 - val_loss: 6.0735 - val_acc: 0.2148\n",
            "Epoch 80/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0543 - acc: 0.9819 - val_loss: 5.9646 - val_acc: 0.2184\n",
            "Epoch 81/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0517 - acc: 0.9833 - val_loss: 6.3581 - val_acc: 0.2156\n",
            "Epoch 82/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0475 - acc: 0.9841 - val_loss: 6.0630 - val_acc: 0.2152\n",
            "Epoch 83/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0519 - acc: 0.9836 - val_loss: 5.8147 - val_acc: 0.2332\n",
            "Epoch 84/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0472 - acc: 0.9851 - val_loss: 6.1679 - val_acc: 0.2160\n",
            "Epoch 85/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0456 - acc: 0.9841 - val_loss: 6.0292 - val_acc: 0.2188\n",
            "Epoch 86/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0469 - acc: 0.9862 - val_loss: 6.0889 - val_acc: 0.2364\n",
            "Epoch 87/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0502 - acc: 0.9836 - val_loss: 5.8621 - val_acc: 0.2216\n",
            "Epoch 88/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0445 - acc: 0.9866 - val_loss: 5.5485 - val_acc: 0.2464\n",
            "Epoch 89/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0398 - acc: 0.9870 - val_loss: 6.4963 - val_acc: 0.2276\n",
            "Epoch 90/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0458 - acc: 0.9847 - val_loss: 6.0372 - val_acc: 0.2472\n",
            "Epoch 91/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0477 - acc: 0.9845 - val_loss: 6.5104 - val_acc: 0.2148\n",
            "Epoch 92/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0409 - acc: 0.9858 - val_loss: 6.0795 - val_acc: 0.2248\n",
            "Epoch 93/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0466 - acc: 0.9844 - val_loss: 6.4678 - val_acc: 0.2024\n",
            "Epoch 94/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0505 - acc: 0.9840 - val_loss: 6.2436 - val_acc: 0.2096\n",
            "Epoch 95/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0449 - acc: 0.9855 - val_loss: 5.6540 - val_acc: 0.2488\n",
            "Epoch 96/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0371 - acc: 0.9878 - val_loss: 6.5408 - val_acc: 0.2068\n",
            "Epoch 97/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0421 - acc: 0.9862 - val_loss: 6.3444 - val_acc: 0.2260\n",
            "Epoch 98/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0480 - acc: 0.9849 - val_loss: 5.8435 - val_acc: 0.2524\n",
            "Epoch 99/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0498 - acc: 0.9836 - val_loss: 5.8922 - val_acc: 0.2412\n",
            "Epoch 100/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0455 - acc: 0.9852 - val_loss: 6.3171 - val_acc: 0.2244\n",
            "Epoch 101/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0479 - acc: 0.9844 - val_loss: 5.8070 - val_acc: 0.2252\n",
            "Epoch 102/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0432 - acc: 0.9864 - val_loss: 6.0708 - val_acc: 0.2356\n",
            "Epoch 103/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0444 - acc: 0.9859 - val_loss: 6.3987 - val_acc: 0.2160\n",
            "Epoch 104/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0453 - acc: 0.9862 - val_loss: 6.1272 - val_acc: 0.2212\n",
            "Epoch 105/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0418 - acc: 0.9859 - val_loss: 5.8960 - val_acc: 0.2348\n",
            "Epoch 106/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0364 - acc: 0.9877 - val_loss: 6.2903 - val_acc: 0.2056\n",
            "Epoch 107/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0417 - acc: 0.9862 - val_loss: 6.7211 - val_acc: 0.2296\n",
            "Epoch 108/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0463 - acc: 0.9844 - val_loss: 6.0335 - val_acc: 0.2348\n",
            "Epoch 109/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0481 - acc: 0.9848 - val_loss: 6.2494 - val_acc: 0.1964\n",
            "Epoch 110/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0461 - acc: 0.9854 - val_loss: 6.5983 - val_acc: 0.1848\n",
            "Epoch 111/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0398 - acc: 0.9880 - val_loss: 6.4538 - val_acc: 0.2152\n",
            "Epoch 112/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0355 - acc: 0.9876 - val_loss: 6.5676 - val_acc: 0.2312\n",
            "Epoch 113/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0462 - acc: 0.9848 - val_loss: 6.1856 - val_acc: 0.2372\n",
            "Epoch 114/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0399 - acc: 0.9879 - val_loss: 5.9923 - val_acc: 0.2452\n",
            "Epoch 115/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0474 - acc: 0.9849 - val_loss: 6.0815 - val_acc: 0.2048\n",
            "Epoch 116/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0387 - acc: 0.9874 - val_loss: 6.3631 - val_acc: 0.2192\n",
            "Epoch 117/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0325 - acc: 0.9895 - val_loss: 6.5380 - val_acc: 0.2244\n",
            "Epoch 118/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0445 - acc: 0.9861 - val_loss: 6.0095 - val_acc: 0.2420\n",
            "Epoch 119/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0452 - acc: 0.9859 - val_loss: 5.6731 - val_acc: 0.2320\n",
            "Epoch 120/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0408 - acc: 0.9867 - val_loss: 6.0656 - val_acc: 0.2428\n",
            "Epoch 121/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0399 - acc: 0.9875 - val_loss: 6.4864 - val_acc: 0.2180\n",
            "Epoch 122/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0351 - acc: 0.9894 - val_loss: 6.0367 - val_acc: 0.2372\n",
            "Epoch 123/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0388 - acc: 0.9874 - val_loss: 6.3485 - val_acc: 0.2176\n",
            "Epoch 124/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0384 - acc: 0.9875 - val_loss: 6.5010 - val_acc: 0.1980\n",
            "Epoch 125/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0442 - acc: 0.9854 - val_loss: 6.0960 - val_acc: 0.2224\n",
            "Epoch 126/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0382 - acc: 0.9870 - val_loss: 6.1051 - val_acc: 0.2228\n",
            "Epoch 127/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0412 - acc: 0.9867 - val_loss: 6.1614 - val_acc: 0.2132\n",
            "Epoch 128/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0406 - acc: 0.9871 - val_loss: 6.6653 - val_acc: 0.2076\n",
            "Epoch 129/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0421 - acc: 0.9869 - val_loss: 6.2330 - val_acc: 0.2180\n",
            "Epoch 130/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0369 - acc: 0.9876 - val_loss: 6.6092 - val_acc: 0.2236\n",
            "Epoch 131/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0412 - acc: 0.9866 - val_loss: 6.4784 - val_acc: 0.2160\n",
            "Epoch 132/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0361 - acc: 0.9888 - val_loss: 6.5067 - val_acc: 0.2108\n",
            "Epoch 133/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0401 - acc: 0.9872 - val_loss: 6.1914 - val_acc: 0.2180\n",
            "Epoch 134/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0259 - acc: 0.9910 - val_loss: 6.6910 - val_acc: 0.2124\n",
            "Epoch 135/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0378 - acc: 0.9871 - val_loss: 6.3087 - val_acc: 0.2244\n",
            "Epoch 136/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0355 - acc: 0.9885 - val_loss: 6.6573 - val_acc: 0.2052\n",
            "Epoch 137/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0479 - acc: 0.9846 - val_loss: 6.1182 - val_acc: 0.2184\n",
            "Epoch 138/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0378 - acc: 0.9873 - val_loss: 6.2894 - val_acc: 0.2148\n",
            "Epoch 139/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0388 - acc: 0.9880 - val_loss: 6.1907 - val_acc: 0.2136\n",
            "Epoch 140/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0388 - acc: 0.9876 - val_loss: 6.2240 - val_acc: 0.2284\n",
            "Epoch 141/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0367 - acc: 0.9883 - val_loss: 6.1831 - val_acc: 0.2188\n",
            "Epoch 142/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0385 - acc: 0.9877 - val_loss: 6.4352 - val_acc: 0.2048\n",
            "Epoch 143/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0321 - acc: 0.9898 - val_loss: 6.0361 - val_acc: 0.2312\n",
            "Epoch 144/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0362 - acc: 0.9881 - val_loss: 6.2362 - val_acc: 0.2076\n",
            "Epoch 145/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0342 - acc: 0.9891 - val_loss: 6.4246 - val_acc: 0.1964\n",
            "Epoch 146/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0369 - acc: 0.9879 - val_loss: 6.1580 - val_acc: 0.2168\n",
            "Epoch 147/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0375 - acc: 0.9876 - val_loss: 6.3930 - val_acc: 0.2120\n",
            "Epoch 148/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0304 - acc: 0.9904 - val_loss: 6.4870 - val_acc: 0.2124\n",
            "Epoch 149/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0363 - acc: 0.9888 - val_loss: 6.2309 - val_acc: 0.2124\n",
            "Epoch 150/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0358 - acc: 0.9892 - val_loss: 6.1994 - val_acc: 0.2184\n",
            "Epoch 151/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0365 - acc: 0.9886 - val_loss: 6.2954 - val_acc: 0.2204\n",
            "Epoch 152/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0344 - acc: 0.9885 - val_loss: 6.3818 - val_acc: 0.2012\n",
            "Epoch 153/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0349 - acc: 0.9889 - val_loss: 6.7843 - val_acc: 0.1984\n",
            "Epoch 154/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0381 - acc: 0.9879 - val_loss: 6.1971 - val_acc: 0.2084\n",
            "Epoch 155/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0395 - acc: 0.9874 - val_loss: 6.1928 - val_acc: 0.2200\n",
            "Epoch 156/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0373 - acc: 0.9877 - val_loss: 6.5419 - val_acc: 0.1936\n",
            "Epoch 157/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0359 - acc: 0.9879 - val_loss: 5.9513 - val_acc: 0.2340\n",
            "Epoch 158/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0311 - acc: 0.9899 - val_loss: 6.5899 - val_acc: 0.1968\n",
            "Epoch 159/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0368 - acc: 0.9877 - val_loss: 6.8567 - val_acc: 0.2152\n",
            "Epoch 160/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0381 - acc: 0.9877 - val_loss: 6.6230 - val_acc: 0.1996\n",
            "Epoch 161/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0368 - acc: 0.9892 - val_loss: 6.4392 - val_acc: 0.1984\n",
            "Epoch 162/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0308 - acc: 0.9899 - val_loss: 6.5709 - val_acc: 0.2044\n",
            "Epoch 163/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0359 - acc: 0.9883 - val_loss: 6.6019 - val_acc: 0.2052\n",
            "Epoch 164/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0341 - acc: 0.9899 - val_loss: 6.7055 - val_acc: 0.1964\n",
            "Epoch 165/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0290 - acc: 0.9909 - val_loss: 6.4477 - val_acc: 0.2384\n",
            "Epoch 166/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0373 - acc: 0.9883 - val_loss: 6.1511 - val_acc: 0.2108\n",
            "Epoch 167/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0359 - acc: 0.9881 - val_loss: 6.2466 - val_acc: 0.2028\n",
            "Epoch 168/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0302 - acc: 0.9901 - val_loss: 6.1855 - val_acc: 0.2220\n",
            "Epoch 169/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0324 - acc: 0.9897 - val_loss: 6.4695 - val_acc: 0.2040\n",
            "Epoch 170/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0418 - acc: 0.9871 - val_loss: 6.2759 - val_acc: 0.1964\n",
            "Epoch 171/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0357 - acc: 0.9889 - val_loss: 6.0235 - val_acc: 0.2308\n",
            "Epoch 172/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0344 - acc: 0.9904 - val_loss: 6.9226 - val_acc: 0.1824\n",
            "Epoch 173/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0303 - acc: 0.9898 - val_loss: 6.4720 - val_acc: 0.2136\n",
            "Epoch 174/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0314 - acc: 0.9902 - val_loss: 6.5378 - val_acc: 0.1932\n",
            "Epoch 175/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0363 - acc: 0.9882 - val_loss: 6.4027 - val_acc: 0.2012\n",
            "Epoch 176/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0312 - acc: 0.9904 - val_loss: 6.2906 - val_acc: 0.2396\n",
            "Epoch 177/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0387 - acc: 0.9880 - val_loss: 6.2037 - val_acc: 0.2272\n",
            "Epoch 178/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0332 - acc: 0.9892 - val_loss: 6.4304 - val_acc: 0.2016\n",
            "Epoch 179/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0327 - acc: 0.9886 - val_loss: 6.3618 - val_acc: 0.2144\n",
            "Epoch 180/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 6.4657 - val_acc: 0.2284\n",
            "Epoch 181/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0252 - acc: 0.9918 - val_loss: 6.4552 - val_acc: 0.2256\n",
            "Epoch 182/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0295 - acc: 0.9906 - val_loss: 6.3455 - val_acc: 0.2040\n",
            "Epoch 183/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0316 - acc: 0.9902 - val_loss: 6.1945 - val_acc: 0.2228\n",
            "Epoch 184/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0297 - acc: 0.9912 - val_loss: 6.3626 - val_acc: 0.2240\n",
            "Epoch 185/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0263 - acc: 0.9915 - val_loss: 7.0804 - val_acc: 0.1820\n",
            "Epoch 186/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0303 - acc: 0.9907 - val_loss: 6.3869 - val_acc: 0.2172\n",
            "Epoch 187/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0353 - acc: 0.9887 - val_loss: 6.2405 - val_acc: 0.2244\n",
            "Epoch 188/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0291 - acc: 0.9909 - val_loss: 6.4200 - val_acc: 0.2172\n",
            "Epoch 189/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0325 - acc: 0.9902 - val_loss: 6.3101 - val_acc: 0.2100\n",
            "Epoch 190/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0337 - acc: 0.9882 - val_loss: 6.2755 - val_acc: 0.2176\n",
            "Epoch 191/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0275 - acc: 0.9916 - val_loss: 6.2813 - val_acc: 0.2260\n",
            "Epoch 192/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 6.3497 - val_acc: 0.2520\n",
            "Epoch 193/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0344 - acc: 0.9896 - val_loss: 6.2060 - val_acc: 0.2240\n",
            "Epoch 194/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 0.0377 - acc: 0.9875 - val_loss: 6.4950 - val_acc: 0.2100\n",
            "Epoch 195/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0364 - acc: 0.9883 - val_loss: 6.3070 - val_acc: 0.2076\n",
            "Epoch 196/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0307 - acc: 0.9903 - val_loss: 6.4749 - val_acc: 0.2004\n",
            "Epoch 197/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 6.8308 - val_acc: 0.2060\n",
            "Epoch 198/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0290 - acc: 0.9916 - val_loss: 6.3296 - val_acc: 0.2352\n",
            "Epoch 199/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0294 - acc: 0.9900 - val_loss: 6.6543 - val_acc: 0.2200\n",
            "Epoch 200/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0348 - acc: 0.9890 - val_loss: 6.1779 - val_acc: 0.2320\n",
            "Epoch 201/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0334 - acc: 0.9904 - val_loss: 6.2466 - val_acc: 0.2152\n",
            "Epoch 202/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0283 - acc: 0.9902 - val_loss: 6.1469 - val_acc: 0.2368\n",
            "Epoch 203/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0351 - acc: 0.9890 - val_loss: 6.1999 - val_acc: 0.2256\n",
            "Epoch 204/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0327 - acc: 0.9898 - val_loss: 6.2569 - val_acc: 0.2216\n",
            "Epoch 205/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0234 - acc: 0.9922 - val_loss: 6.4789 - val_acc: 0.2152\n",
            "Epoch 206/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0242 - acc: 0.9924 - val_loss: 6.2771 - val_acc: 0.2332\n",
            "Epoch 207/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0290 - acc: 0.9915 - val_loss: 6.1659 - val_acc: 0.2324\n",
            "Epoch 208/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0267 - acc: 0.9916 - val_loss: 6.1983 - val_acc: 0.2504\n",
            "Epoch 209/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0318 - acc: 0.9903 - val_loss: 6.1079 - val_acc: 0.2316\n",
            "Epoch 210/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0326 - acc: 0.9896 - val_loss: 5.8441 - val_acc: 0.2396\n",
            "Epoch 211/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0330 - acc: 0.9899 - val_loss: 6.3281 - val_acc: 0.2260\n",
            "Epoch 212/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0298 - acc: 0.9897 - val_loss: 6.2796 - val_acc: 0.2304\n",
            "Epoch 213/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0237 - acc: 0.9930 - val_loss: 6.1933 - val_acc: 0.2232\n",
            "Epoch 214/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0245 - acc: 0.9919 - val_loss: 7.0294 - val_acc: 0.2060\n",
            "Epoch 215/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0321 - acc: 0.9900 - val_loss: 6.4728 - val_acc: 0.2116\n",
            "Epoch 216/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0281 - acc: 0.9911 - val_loss: 6.5536 - val_acc: 0.2292\n",
            "Epoch 217/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0281 - acc: 0.9920 - val_loss: 6.7959 - val_acc: 0.2180\n",
            "Epoch 218/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0302 - acc: 0.9906 - val_loss: 6.1582 - val_acc: 0.2260\n",
            "Epoch 219/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0298 - acc: 0.9904 - val_loss: 6.0393 - val_acc: 0.2240\n",
            "Epoch 220/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0275 - acc: 0.9917 - val_loss: 6.5538 - val_acc: 0.2024\n",
            "Epoch 221/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0283 - acc: 0.9916 - val_loss: 6.3760 - val_acc: 0.2224\n",
            "Epoch 222/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0305 - acc: 0.9908 - val_loss: 6.1914 - val_acc: 0.2172\n",
            "Epoch 223/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0356 - acc: 0.9895 - val_loss: 5.9993 - val_acc: 0.2244\n",
            "Epoch 224/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0318 - acc: 0.9908 - val_loss: 6.1844 - val_acc: 0.1952\n",
            "Epoch 225/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 5.7564 - val_acc: 0.2436\n",
            "Epoch 226/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0281 - acc: 0.9912 - val_loss: 6.3144 - val_acc: 0.2256\n",
            "Epoch 227/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0260 - acc: 0.9921 - val_loss: 6.0987 - val_acc: 0.2380\n",
            "Epoch 228/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0317 - acc: 0.9898 - val_loss: 6.2215 - val_acc: 0.2156\n",
            "Epoch 229/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0234 - acc: 0.9932 - val_loss: 6.2479 - val_acc: 0.2144\n",
            "Epoch 230/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0285 - acc: 0.9918 - val_loss: 6.2771 - val_acc: 0.2216\n",
            "Epoch 231/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0252 - acc: 0.9929 - val_loss: 6.3121 - val_acc: 0.2272\n",
            "Epoch 232/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0265 - acc: 0.9913 - val_loss: 6.3216 - val_acc: 0.2304\n",
            "Epoch 233/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0326 - acc: 0.9905 - val_loss: 6.5667 - val_acc: 0.2056\n",
            "Epoch 234/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0272 - acc: 0.9911 - val_loss: 6.1662 - val_acc: 0.2372\n",
            "Epoch 235/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 6.1537 - val_acc: 0.2404\n",
            "Epoch 236/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0270 - acc: 0.9912 - val_loss: 6.7574 - val_acc: 0.2120\n",
            "Epoch 237/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0264 - acc: 0.9914 - val_loss: 6.2857 - val_acc: 0.2388\n",
            "Epoch 238/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 6.6111 - val_acc: 0.2220\n",
            "Epoch 239/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0328 - acc: 0.9901 - val_loss: 6.1500 - val_acc: 0.2312\n",
            "Epoch 240/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0303 - acc: 0.9908 - val_loss: 6.5068 - val_acc: 0.2044\n",
            "Epoch 241/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0229 - acc: 0.9934 - val_loss: 6.2451 - val_acc: 0.2368\n",
            "Epoch 242/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0330 - acc: 0.9900 - val_loss: 6.1093 - val_acc: 0.2252\n",
            "Epoch 243/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0285 - acc: 0.9916 - val_loss: 6.3268 - val_acc: 0.2304\n",
            "Epoch 244/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0259 - acc: 0.9912 - val_loss: 6.2442 - val_acc: 0.2144\n",
            "Epoch 245/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 6.5853 - val_acc: 0.2296\n",
            "Epoch 246/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0288 - acc: 0.9912 - val_loss: 6.5458 - val_acc: 0.2048\n",
            "Epoch 247/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0292 - acc: 0.9911 - val_loss: 6.5700 - val_acc: 0.2068\n",
            "Epoch 248/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0259 - acc: 0.9922 - val_loss: 6.4909 - val_acc: 0.2076\n",
            "Epoch 249/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0355 - acc: 0.9897 - val_loss: 6.0500 - val_acc: 0.2256\n",
            "Epoch 250/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0298 - acc: 0.9905 - val_loss: 6.1874 - val_acc: 0.2140\n",
            "Epoch 251/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0242 - acc: 0.9925 - val_loss: 6.0591 - val_acc: 0.2284\n",
            "Epoch 252/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 6.2081 - val_acc: 0.2280\n",
            "Epoch 253/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0301 - acc: 0.9909 - val_loss: 6.4511 - val_acc: 0.2032\n",
            "Epoch 254/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0223 - acc: 0.9925 - val_loss: 6.3117 - val_acc: 0.2156\n",
            "Epoch 255/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0269 - acc: 0.9919 - val_loss: 5.9675 - val_acc: 0.2260\n",
            "Epoch 256/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0262 - acc: 0.9916 - val_loss: 6.0636 - val_acc: 0.2240\n",
            "Epoch 257/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0335 - acc: 0.9896 - val_loss: 6.3106 - val_acc: 0.2376\n",
            "Epoch 258/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0201 - acc: 0.9931 - val_loss: 6.2452 - val_acc: 0.2164\n",
            "Epoch 259/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0237 - acc: 0.9924 - val_loss: 6.4092 - val_acc: 0.2228\n",
            "Epoch 260/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0247 - acc: 0.9920 - val_loss: 6.4982 - val_acc: 0.2172\n",
            "Epoch 261/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0263 - acc: 0.9916 - val_loss: 6.5251 - val_acc: 0.2216\n",
            "Epoch 262/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0265 - acc: 0.9912 - val_loss: 6.1632 - val_acc: 0.2408\n",
            "Epoch 263/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 6.4826 - val_acc: 0.2040\n",
            "Epoch 264/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0298 - acc: 0.9906 - val_loss: 6.5468 - val_acc: 0.2048\n",
            "Epoch 265/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0310 - acc: 0.9910 - val_loss: 6.2403 - val_acc: 0.2008\n",
            "Epoch 266/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0238 - acc: 0.9924 - val_loss: 6.7142 - val_acc: 0.2012\n",
            "Epoch 267/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0243 - acc: 0.9923 - val_loss: 6.6701 - val_acc: 0.2120\n",
            "Epoch 268/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0234 - acc: 0.9930 - val_loss: 6.2303 - val_acc: 0.2472\n",
            "Epoch 269/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 6.6847 - val_acc: 0.2136\n",
            "Epoch 270/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0295 - acc: 0.9907 - val_loss: 6.4039 - val_acc: 0.2252\n",
            "Epoch 271/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0299 - acc: 0.9905 - val_loss: 6.4914 - val_acc: 0.2308\n",
            "Epoch 272/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0299 - acc: 0.9907 - val_loss: 6.1362 - val_acc: 0.2360\n",
            "Epoch 273/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0276 - acc: 0.9920 - val_loss: 6.0215 - val_acc: 0.2304\n",
            "Epoch 274/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0209 - acc: 0.9928 - val_loss: 5.9404 - val_acc: 0.2444\n",
            "Epoch 275/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0241 - acc: 0.9920 - val_loss: 6.4967 - val_acc: 0.2132\n",
            "Epoch 276/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0263 - acc: 0.9921 - val_loss: 6.4399 - val_acc: 0.2260\n",
            "Epoch 277/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0221 - acc: 0.9930 - val_loss: 6.3019 - val_acc: 0.2200\n",
            "Epoch 278/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0236 - acc: 0.9932 - val_loss: 6.4769 - val_acc: 0.2444\n",
            "Epoch 279/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0302 - acc: 0.9913 - val_loss: 6.6062 - val_acc: 0.2012\n",
            "Epoch 280/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0231 - acc: 0.9925 - val_loss: 6.4118 - val_acc: 0.2224\n",
            "Epoch 281/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0245 - acc: 0.9927 - val_loss: 6.6045 - val_acc: 0.2024\n",
            "Epoch 282/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0247 - acc: 0.9923 - val_loss: 6.3244 - val_acc: 0.2392\n",
            "Epoch 283/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0328 - acc: 0.9904 - val_loss: 6.1494 - val_acc: 0.2288\n",
            "Epoch 284/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0314 - acc: 0.9902 - val_loss: 6.1498 - val_acc: 0.2180\n",
            "Epoch 285/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 5.9823 - val_acc: 0.2396\n",
            "Epoch 286/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0259 - acc: 0.9924 - val_loss: 6.2670 - val_acc: 0.2348\n",
            "Epoch 287/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0174 - acc: 0.9939 - val_loss: 6.3368 - val_acc: 0.2260\n",
            "Epoch 288/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0172 - acc: 0.9948 - val_loss: 6.5056 - val_acc: 0.2300\n",
            "Epoch 289/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0235 - acc: 0.9929 - val_loss: 6.9686 - val_acc: 0.1932\n",
            "Epoch 290/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0171 - acc: 0.9947 - val_loss: 6.3303 - val_acc: 0.2228\n",
            "Epoch 291/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0261 - acc: 0.9920 - val_loss: 6.3599 - val_acc: 0.2300\n",
            "Epoch 292/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0302 - acc: 0.9906 - val_loss: 6.3874 - val_acc: 0.2180\n",
            "Epoch 293/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0285 - acc: 0.9910 - val_loss: 6.7087 - val_acc: 0.1956\n",
            "Epoch 294/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0236 - acc: 0.9926 - val_loss: 6.2461 - val_acc: 0.2360\n",
            "Epoch 295/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0260 - acc: 0.9921 - val_loss: 6.2119 - val_acc: 0.2144\n",
            "Epoch 296/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0243 - acc: 0.9927 - val_loss: 6.5067 - val_acc: 0.2332\n",
            "Epoch 297/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0231 - acc: 0.9925 - val_loss: 5.9529 - val_acc: 0.2412\n",
            "Epoch 298/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0266 - acc: 0.9920 - val_loss: 6.6215 - val_acc: 0.2184\n",
            "Epoch 299/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0248 - acc: 0.9922 - val_loss: 6.7436 - val_acc: 0.2104\n",
            "Epoch 300/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0228 - acc: 0.9931 - val_loss: 6.1952 - val_acc: 0.2048\n",
            "Epoch 301/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0220 - acc: 0.9939 - val_loss: 6.3552 - val_acc: 0.2064\n",
            "Epoch 302/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 6.3162 - val_acc: 0.2532\n",
            "Epoch 303/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0308 - acc: 0.9904 - val_loss: 6.2859 - val_acc: 0.2236\n",
            "Epoch 304/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0266 - acc: 0.9920 - val_loss: 6.5413 - val_acc: 0.2156\n",
            "Epoch 305/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0240 - acc: 0.9927 - val_loss: 6.5352 - val_acc: 0.2148\n",
            "Epoch 306/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0244 - acc: 0.9925 - val_loss: 6.5555 - val_acc: 0.2032\n",
            "Epoch 307/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0257 - acc: 0.9928 - val_loss: 6.4398 - val_acc: 0.2040\n",
            "Epoch 308/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0251 - acc: 0.9923 - val_loss: 6.0206 - val_acc: 0.2448\n",
            "Epoch 309/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0213 - acc: 0.9928 - val_loss: 6.5524 - val_acc: 0.2124\n",
            "Epoch 310/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0216 - acc: 0.9928 - val_loss: 6.6478 - val_acc: 0.2088\n",
            "Epoch 311/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0223 - acc: 0.9930 - val_loss: 6.2831 - val_acc: 0.2448\n",
            "Epoch 312/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0264 - acc: 0.9916 - val_loss: 6.3189 - val_acc: 0.2316\n",
            "Epoch 313/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0216 - acc: 0.9927 - val_loss: 6.6865 - val_acc: 0.2032\n",
            "Epoch 314/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0236 - acc: 0.9931 - val_loss: 6.4306 - val_acc: 0.1932\n",
            "Epoch 315/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0205 - acc: 0.9931 - val_loss: 6.6894 - val_acc: 0.2008\n",
            "Epoch 316/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0222 - acc: 0.9929 - val_loss: 6.2803 - val_acc: 0.2396\n",
            "Epoch 317/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0293 - acc: 0.9908 - val_loss: 6.2160 - val_acc: 0.2180\n",
            "Epoch 318/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0268 - acc: 0.9920 - val_loss: 6.5570 - val_acc: 0.1992\n",
            "Epoch 319/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 0.0167 - acc: 0.9942 - val_loss: 6.4468 - val_acc: 0.2504\n",
            "Epoch 320/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0207 - acc: 0.9931 - val_loss: 7.0695 - val_acc: 0.2092\n",
            "Epoch 321/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0277 - acc: 0.9916 - val_loss: 6.7130 - val_acc: 0.1920\n",
            "Epoch 322/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0212 - acc: 0.9938 - val_loss: 6.3507 - val_acc: 0.2232\n",
            "Epoch 323/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0193 - acc: 0.9941 - val_loss: 6.2424 - val_acc: 0.2156\n",
            "Epoch 324/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0238 - acc: 0.9925 - val_loss: 6.5911 - val_acc: 0.2088\n",
            "Epoch 325/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0243 - acc: 0.9929 - val_loss: 6.2307 - val_acc: 0.2212\n",
            "Epoch 326/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0233 - acc: 0.9921 - val_loss: 6.4862 - val_acc: 0.1996\n",
            "Epoch 327/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0211 - acc: 0.9926 - val_loss: 6.3714 - val_acc: 0.2152\n",
            "Epoch 328/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0184 - acc: 0.9939 - val_loss: 6.5284 - val_acc: 0.2376\n",
            "Epoch 329/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0237 - acc: 0.9927 - val_loss: 6.6131 - val_acc: 0.2040\n",
            "Epoch 330/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0241 - acc: 0.9925 - val_loss: 6.3124 - val_acc: 0.2284\n",
            "Epoch 331/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0200 - acc: 0.9931 - val_loss: 6.6291 - val_acc: 0.2156\n",
            "Epoch 332/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0280 - acc: 0.9908 - val_loss: 6.1877 - val_acc: 0.2176\n",
            "Epoch 333/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 6.3217 - val_acc: 0.2224\n",
            "Epoch 334/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0261 - acc: 0.9928 - val_loss: 6.5853 - val_acc: 0.2036\n",
            "Epoch 335/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 6.4123 - val_acc: 0.2140\n",
            "Epoch 336/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0206 - acc: 0.9934 - val_loss: 6.4668 - val_acc: 0.2040\n",
            "Epoch 337/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0249 - acc: 0.9910 - val_loss: 6.2271 - val_acc: 0.2224\n",
            "Epoch 338/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0242 - acc: 0.9920 - val_loss: 6.4191 - val_acc: 0.2244\n",
            "Epoch 339/1000\n",
            "22500/22500 [==============================] - 2s 84us/step - loss: 0.0222 - acc: 0.9931 - val_loss: 6.5827 - val_acc: 0.2100\n",
            "Epoch 340/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0223 - acc: 0.9936 - val_loss: 6.5680 - val_acc: 0.1964\n",
            "Epoch 341/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0286 - acc: 0.9918 - val_loss: 6.4119 - val_acc: 0.2196\n",
            "Epoch 342/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0287 - acc: 0.9912 - val_loss: 6.3062 - val_acc: 0.2200\n",
            "Epoch 343/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0253 - acc: 0.9923 - val_loss: 6.3666 - val_acc: 0.2360\n",
            "Epoch 344/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 6.6403 - val_acc: 0.2096\n",
            "Epoch 345/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 6.4861 - val_acc: 0.2040\n",
            "Epoch 346/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 6.5044 - val_acc: 0.2120\n",
            "Epoch 347/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 6.5104 - val_acc: 0.2108\n",
            "Epoch 348/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0226 - acc: 0.9928 - val_loss: 6.7959 - val_acc: 0.1784\n",
            "Epoch 349/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0196 - acc: 0.9933 - val_loss: 6.4167 - val_acc: 0.2060\n",
            "Epoch 350/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 6.4694 - val_acc: 0.2284\n",
            "Epoch 351/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0354 - acc: 0.9898 - val_loss: 6.2600 - val_acc: 0.2112\n",
            "Epoch 352/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0232 - acc: 0.9930 - val_loss: 6.2793 - val_acc: 0.2136\n",
            "Epoch 353/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0275 - acc: 0.9909 - val_loss: 6.4674 - val_acc: 0.1996\n",
            "Epoch 354/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0227 - acc: 0.9932 - val_loss: 6.0190 - val_acc: 0.2304\n",
            "Epoch 355/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0220 - acc: 0.9932 - val_loss: 6.3283 - val_acc: 0.2444\n",
            "Epoch 356/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0188 - acc: 0.9941 - val_loss: 6.2114 - val_acc: 0.2284\n",
            "Epoch 357/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0183 - acc: 0.9936 - val_loss: 6.5162 - val_acc: 0.2160\n",
            "Epoch 358/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0238 - acc: 0.9924 - val_loss: 6.0434 - val_acc: 0.2320\n",
            "Epoch 359/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 6.3821 - val_acc: 0.2180\n",
            "Epoch 360/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0190 - acc: 0.9945 - val_loss: 6.1252 - val_acc: 0.2452\n",
            "Epoch 361/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0164 - acc: 0.9946 - val_loss: 6.6452 - val_acc: 0.2084\n",
            "Epoch 362/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 6.2518 - val_acc: 0.2456\n",
            "Epoch 363/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0307 - acc: 0.9906 - val_loss: 6.5724 - val_acc: 0.2284\n",
            "Epoch 364/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 6.5403 - val_acc: 0.2128\n",
            "Epoch 365/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0190 - acc: 0.9941 - val_loss: 6.6027 - val_acc: 0.2292\n",
            "Epoch 366/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0217 - acc: 0.9928 - val_loss: 6.6292 - val_acc: 0.2228\n",
            "Epoch 367/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0213 - acc: 0.9932 - val_loss: 6.7901 - val_acc: 0.2280\n",
            "Epoch 368/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0238 - acc: 0.9925 - val_loss: 6.6544 - val_acc: 0.2324\n",
            "Epoch 369/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0230 - acc: 0.9928 - val_loss: 6.6871 - val_acc: 0.2188\n",
            "Epoch 370/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0225 - acc: 0.9934 - val_loss: 6.7012 - val_acc: 0.2164\n",
            "Epoch 371/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0253 - acc: 0.9920 - val_loss: 6.4617 - val_acc: 0.2112\n",
            "Epoch 372/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 6.3072 - val_acc: 0.2304\n",
            "Epoch 373/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 6.6313 - val_acc: 0.2180\n",
            "Epoch 374/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0191 - acc: 0.9938 - val_loss: 6.4809 - val_acc: 0.2220\n",
            "Epoch 375/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0203 - acc: 0.9941 - val_loss: 6.5507 - val_acc: 0.2100\n",
            "Epoch 376/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 6.3317 - val_acc: 0.2096\n",
            "Epoch 377/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 6.4610 - val_acc: 0.2280\n",
            "Epoch 378/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0203 - acc: 0.9930 - val_loss: 6.4973 - val_acc: 0.2452\n",
            "Epoch 379/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0276 - acc: 0.9920 - val_loss: 6.3808 - val_acc: 0.2296\n",
            "Epoch 380/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0242 - acc: 0.9924 - val_loss: 6.6335 - val_acc: 0.2108\n",
            "Epoch 381/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0235 - acc: 0.9929 - val_loss: 6.2491 - val_acc: 0.2344\n",
            "Epoch 382/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0183 - acc: 0.9938 - val_loss: 6.3049 - val_acc: 0.2228\n",
            "Epoch 383/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0191 - acc: 0.9941 - val_loss: 6.2409 - val_acc: 0.2368\n",
            "Epoch 384/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 6.7426 - val_acc: 0.2220\n",
            "Epoch 385/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0220 - acc: 0.9928 - val_loss: 6.3141 - val_acc: 0.2240\n",
            "Epoch 386/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0211 - acc: 0.9935 - val_loss: 6.3274 - val_acc: 0.1988\n",
            "Epoch 387/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 6.3082 - val_acc: 0.2316\n",
            "Epoch 388/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0182 - acc: 0.9940 - val_loss: 6.9510 - val_acc: 0.2068\n",
            "Epoch 389/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0219 - acc: 0.9928 - val_loss: 6.8078 - val_acc: 0.2340\n",
            "Epoch 390/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0190 - acc: 0.9943 - val_loss: 6.2904 - val_acc: 0.2316\n",
            "Epoch 391/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 6.5938 - val_acc: 0.2300\n",
            "Epoch 392/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0279 - acc: 0.9920 - val_loss: 6.7805 - val_acc: 0.2060\n",
            "Epoch 393/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0223 - acc: 0.9930 - val_loss: 6.9217 - val_acc: 0.1836\n",
            "Epoch 394/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0238 - acc: 0.9929 - val_loss: 6.6649 - val_acc: 0.2036\n",
            "Epoch 395/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0211 - acc: 0.9929 - val_loss: 6.4909 - val_acc: 0.2184\n",
            "Epoch 396/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 6.8628 - val_acc: 0.2300\n",
            "Epoch 397/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0196 - acc: 0.9941 - val_loss: 6.5413 - val_acc: 0.2296\n",
            "Epoch 398/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0231 - acc: 0.9937 - val_loss: 6.7132 - val_acc: 0.2428\n",
            "Epoch 399/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0226 - acc: 0.9933 - val_loss: 6.5112 - val_acc: 0.2072\n",
            "Epoch 400/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0226 - acc: 0.9933 - val_loss: 6.3180 - val_acc: 0.2312\n",
            "Epoch 401/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0185 - acc: 0.9938 - val_loss: 6.8230 - val_acc: 0.1972\n",
            "Epoch 402/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0179 - acc: 0.9944 - val_loss: 6.5094 - val_acc: 0.2356\n",
            "Epoch 403/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0220 - acc: 0.9935 - val_loss: 6.5660 - val_acc: 0.2256\n",
            "Epoch 404/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 6.6071 - val_acc: 0.2200\n",
            "Epoch 405/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0275 - acc: 0.9913 - val_loss: 6.5076 - val_acc: 0.2268\n",
            "Epoch 406/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0255 - acc: 0.9925 - val_loss: 6.3076 - val_acc: 0.2304\n",
            "Epoch 407/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0180 - acc: 0.9939 - val_loss: 6.5127 - val_acc: 0.2276\n",
            "Epoch 408/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0219 - acc: 0.9934 - val_loss: 6.8390 - val_acc: 0.1888\n",
            "Epoch 409/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0238 - acc: 0.9930 - val_loss: 6.2395 - val_acc: 0.2012\n",
            "Epoch 410/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 6.5773 - val_acc: 0.2272\n",
            "Epoch 411/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0187 - acc: 0.9941 - val_loss: 6.5998 - val_acc: 0.2384\n",
            "Epoch 412/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0222 - acc: 0.9928 - val_loss: 6.6919 - val_acc: 0.2220\n",
            "Epoch 413/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0232 - acc: 0.9925 - val_loss: 6.8257 - val_acc: 0.2044\n",
            "Epoch 414/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 0.0186 - acc: 0.9944 - val_loss: 6.5502 - val_acc: 0.2160\n",
            "Epoch 415/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0211 - acc: 0.9932 - val_loss: 6.4524 - val_acc: 0.2356\n",
            "Epoch 416/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0201 - acc: 0.9937 - val_loss: 7.2878 - val_acc: 0.1972\n",
            "Epoch 417/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0163 - acc: 0.9954 - val_loss: 6.3414 - val_acc: 0.2364\n",
            "Epoch 418/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0178 - acc: 0.9946 - val_loss: 6.2063 - val_acc: 0.2240\n",
            "Epoch 419/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0193 - acc: 0.9939 - val_loss: 6.5678 - val_acc: 0.2300\n",
            "Epoch 420/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 6.5600 - val_acc: 0.2388\n",
            "Epoch 421/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0254 - acc: 0.9922 - val_loss: 6.2812 - val_acc: 0.2488\n",
            "Epoch 422/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0196 - acc: 0.9933 - val_loss: 6.1917 - val_acc: 0.2328\n",
            "Epoch 423/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0210 - acc: 0.9930 - val_loss: 6.5258 - val_acc: 0.2120\n",
            "Epoch 424/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 6.4843 - val_acc: 0.2344\n",
            "Epoch 425/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0216 - acc: 0.9936 - val_loss: 6.4787 - val_acc: 0.2240\n",
            "Epoch 426/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 6.9838 - val_acc: 0.2120\n",
            "Epoch 427/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0188 - acc: 0.9942 - val_loss: 6.4368 - val_acc: 0.2008\n",
            "Epoch 428/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 6.5785 - val_acc: 0.2072\n",
            "Epoch 429/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0227 - acc: 0.9932 - val_loss: 6.7432 - val_acc: 0.2004\n",
            "Epoch 430/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0215 - acc: 0.9936 - val_loss: 6.3695 - val_acc: 0.2064\n",
            "Epoch 431/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0232 - acc: 0.9928 - val_loss: 6.3641 - val_acc: 0.2084\n",
            "Epoch 432/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0218 - acc: 0.9933 - val_loss: 6.5541 - val_acc: 0.2204\n",
            "Epoch 433/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 6.5507 - val_acc: 0.2216\n",
            "Epoch 434/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0158 - acc: 0.9947 - val_loss: 6.9156 - val_acc: 0.2052\n",
            "Epoch 435/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 6.4925 - val_acc: 0.2192\n",
            "Epoch 436/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0183 - acc: 0.9946 - val_loss: 6.4015 - val_acc: 0.2168\n",
            "Epoch 437/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0198 - acc: 0.9939 - val_loss: 6.3055 - val_acc: 0.2500\n",
            "Epoch 438/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0199 - acc: 0.9943 - val_loss: 6.0603 - val_acc: 0.2204\n",
            "Epoch 439/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0196 - acc: 0.9940 - val_loss: 6.8271 - val_acc: 0.1968\n",
            "Epoch 440/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0197 - acc: 0.9940 - val_loss: 6.3021 - val_acc: 0.2312\n",
            "Epoch 441/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0223 - acc: 0.9934 - val_loss: 6.6863 - val_acc: 0.2100\n",
            "Epoch 442/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0198 - acc: 0.9940 - val_loss: 6.3192 - val_acc: 0.2296\n",
            "Epoch 443/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0201 - acc: 0.9939 - val_loss: 6.4406 - val_acc: 0.2284\n",
            "Epoch 444/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0215 - acc: 0.9936 - val_loss: 6.6210 - val_acc: 0.2240\n",
            "Epoch 445/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0188 - acc: 0.9944 - val_loss: 6.2371 - val_acc: 0.2380\n",
            "Epoch 446/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0218 - acc: 0.9934 - val_loss: 6.6083 - val_acc: 0.2060\n",
            "Epoch 447/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0238 - acc: 0.9929 - val_loss: 6.6280 - val_acc: 0.2028\n",
            "Epoch 448/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0173 - acc: 0.9945 - val_loss: 6.7669 - val_acc: 0.2232\n",
            "Epoch 449/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0195 - acc: 0.9942 - val_loss: 6.6002 - val_acc: 0.2076\n",
            "Epoch 450/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0199 - acc: 0.9947 - val_loss: 6.5600 - val_acc: 0.2192\n",
            "Epoch 451/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 6.7049 - val_acc: 0.1992\n",
            "Epoch 452/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 6.6151 - val_acc: 0.2228\n",
            "Epoch 453/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0225 - acc: 0.9925 - val_loss: 6.7292 - val_acc: 0.2092\n",
            "Epoch 454/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0184 - acc: 0.9941 - val_loss: 6.4298 - val_acc: 0.2276\n",
            "Epoch 455/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 6.6491 - val_acc: 0.2084\n",
            "Epoch 456/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 6.3575 - val_acc: 0.2160\n",
            "Epoch 457/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 6.4877 - val_acc: 0.2072\n",
            "Epoch 458/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0218 - acc: 0.9940 - val_loss: 6.3034 - val_acc: 0.2184\n",
            "Epoch 459/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 6.6820 - val_acc: 0.2076\n",
            "Epoch 460/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0244 - acc: 0.9926 - val_loss: 6.4614 - val_acc: 0.2236\n",
            "Epoch 461/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0198 - acc: 0.9941 - val_loss: 6.1237 - val_acc: 0.2228\n",
            "Epoch 462/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0183 - acc: 0.9945 - val_loss: 6.5367 - val_acc: 0.2264\n",
            "Epoch 463/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0239 - acc: 0.9924 - val_loss: 6.6468 - val_acc: 0.2200\n",
            "Epoch 464/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 6.6164 - val_acc: 0.1892\n",
            "Epoch 465/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 6.6437 - val_acc: 0.2004\n",
            "Epoch 466/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0203 - acc: 0.9941 - val_loss: 6.4664 - val_acc: 0.2204\n",
            "Epoch 467/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0173 - acc: 0.9948 - val_loss: 6.5497 - val_acc: 0.2204\n",
            "Epoch 468/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9959 - val_loss: 6.5249 - val_acc: 0.2292\n",
            "Epoch 469/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9958 - val_loss: 6.7309 - val_acc: 0.2284\n",
            "Epoch 470/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 6.6367 - val_acc: 0.2056\n",
            "Epoch 471/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0208 - acc: 0.9936 - val_loss: 6.5030 - val_acc: 0.2156\n",
            "Epoch 472/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 6.1278 - val_acc: 0.2412\n",
            "Epoch 473/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 6.5445 - val_acc: 0.2176\n",
            "Epoch 474/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9951 - val_loss: 6.8397 - val_acc: 0.1896\n",
            "Epoch 475/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0222 - acc: 0.9935 - val_loss: 6.6956 - val_acc: 0.2104\n",
            "Epoch 476/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 6.7073 - val_acc: 0.2016\n",
            "Epoch 477/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 0.0156 - acc: 0.9944 - val_loss: 6.8648 - val_acc: 0.1908\n",
            "Epoch 478/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0174 - acc: 0.9947 - val_loss: 6.5655 - val_acc: 0.2184\n",
            "Epoch 479/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0179 - acc: 0.9945 - val_loss: 6.4625 - val_acc: 0.2100\n",
            "Epoch 480/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0191 - acc: 0.9942 - val_loss: 6.1922 - val_acc: 0.2264\n",
            "Epoch 481/1000\n",
            "22500/22500 [==============================] - 2s 84us/step - loss: 0.0146 - acc: 0.9951 - val_loss: 6.3434 - val_acc: 0.2240\n",
            "Epoch 482/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9944 - val_loss: 6.8921 - val_acc: 0.2264\n",
            "Epoch 483/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0180 - acc: 0.9948 - val_loss: 6.5748 - val_acc: 0.2312\n",
            "Epoch 484/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0205 - acc: 0.9939 - val_loss: 6.5496 - val_acc: 0.2128\n",
            "Epoch 485/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9952 - val_loss: 6.9350 - val_acc: 0.2404\n",
            "Epoch 486/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 6.6412 - val_acc: 0.2216\n",
            "Epoch 487/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0162 - acc: 0.9951 - val_loss: 6.5578 - val_acc: 0.2120\n",
            "Epoch 488/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 6.7448 - val_acc: 0.2108\n",
            "Epoch 489/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0185 - acc: 0.9938 - val_loss: 6.1812 - val_acc: 0.2232\n",
            "Epoch 490/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0146 - acc: 0.9956 - val_loss: 6.9225 - val_acc: 0.2004\n",
            "Epoch 491/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0163 - acc: 0.9956 - val_loss: 6.5433 - val_acc: 0.2044\n",
            "Epoch 492/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0245 - acc: 0.9929 - val_loss: 6.5573 - val_acc: 0.1824\n",
            "Epoch 493/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0184 - acc: 0.9941 - val_loss: 6.8473 - val_acc: 0.2088\n",
            "Epoch 494/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9951 - val_loss: 6.6218 - val_acc: 0.2112\n",
            "Epoch 495/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0193 - acc: 0.9944 - val_loss: 6.9518 - val_acc: 0.1960\n",
            "Epoch 496/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0237 - acc: 0.9933 - val_loss: 6.7312 - val_acc: 0.2080\n",
            "Epoch 497/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0173 - acc: 0.9946 - val_loss: 6.5838 - val_acc: 0.2124\n",
            "Epoch 498/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0165 - acc: 0.9954 - val_loss: 6.7172 - val_acc: 0.2176\n",
            "Epoch 499/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 7.1960 - val_acc: 0.1868\n",
            "Epoch 500/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 6.6173 - val_acc: 0.2228\n",
            "Epoch 501/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0205 - acc: 0.9942 - val_loss: 6.5612 - val_acc: 0.2060\n",
            "Epoch 502/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0210 - acc: 0.9946 - val_loss: 6.4255 - val_acc: 0.2172\n",
            "Epoch 503/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 6.7208 - val_acc: 0.1972\n",
            "Epoch 504/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 6.5252 - val_acc: 0.2092\n",
            "Epoch 505/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0186 - acc: 0.9943 - val_loss: 6.9818 - val_acc: 0.2008\n",
            "Epoch 506/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0204 - acc: 0.9931 - val_loss: 6.4131 - val_acc: 0.2288\n",
            "Epoch 507/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0180 - acc: 0.9942 - val_loss: 6.6588 - val_acc: 0.2148\n",
            "Epoch 508/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0141 - acc: 0.9956 - val_loss: 6.7044 - val_acc: 0.2052\n",
            "Epoch 509/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 6.6984 - val_acc: 0.1828\n",
            "Epoch 510/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0179 - acc: 0.9941 - val_loss: 6.2340 - val_acc: 0.2300\n",
            "Epoch 511/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0206 - acc: 0.9942 - val_loss: 6.0794 - val_acc: 0.2300\n",
            "Epoch 512/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0209 - acc: 0.9944 - val_loss: 6.3694 - val_acc: 0.2220\n",
            "Epoch 513/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0183 - acc: 0.9943 - val_loss: 6.4263 - val_acc: 0.2120\n",
            "Epoch 514/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0157 - acc: 0.9956 - val_loss: 6.6580 - val_acc: 0.2032\n",
            "Epoch 515/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0202 - acc: 0.9934 - val_loss: 6.5902 - val_acc: 0.2176\n",
            "Epoch 516/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0279 - acc: 0.9922 - val_loss: 6.7449 - val_acc: 0.2004\n",
            "Epoch 517/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0203 - acc: 0.9942 - val_loss: 6.6235 - val_acc: 0.2220\n",
            "Epoch 518/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 6.2082 - val_acc: 0.2264\n",
            "Epoch 519/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0127 - acc: 0.9960 - val_loss: 6.3946 - val_acc: 0.2072\n",
            "Epoch 520/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0209 - acc: 0.9936 - val_loss: 6.2603 - val_acc: 0.2300\n",
            "Epoch 521/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 6.7384 - val_acc: 0.2128\n",
            "Epoch 522/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 6.0209 - val_acc: 0.2352\n",
            "Epoch 523/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 6.3117 - val_acc: 0.2024\n",
            "Epoch 524/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 6.9605 - val_acc: 0.2108\n",
            "Epoch 525/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0209 - acc: 0.9938 - val_loss: 6.2976 - val_acc: 0.2300\n",
            "Epoch 526/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0175 - acc: 0.9948 - val_loss: 6.4450 - val_acc: 0.2184\n",
            "Epoch 527/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0195 - acc: 0.9942 - val_loss: 6.2222 - val_acc: 0.2216\n",
            "Epoch 528/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0174 - acc: 0.9941 - val_loss: 6.3621 - val_acc: 0.2260\n",
            "Epoch 529/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0176 - acc: 0.9946 - val_loss: 6.6278 - val_acc: 0.2132\n",
            "Epoch 530/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 6.4876 - val_acc: 0.2364\n",
            "Epoch 531/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9957 - val_loss: 6.7334 - val_acc: 0.2144\n",
            "Epoch 532/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0147 - acc: 0.9951 - val_loss: 6.6295 - val_acc: 0.2188\n",
            "Epoch 533/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9952 - val_loss: 7.0812 - val_acc: 0.2088\n",
            "Epoch 534/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0202 - acc: 0.9935 - val_loss: 6.5923 - val_acc: 0.2304\n",
            "Epoch 535/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0198 - acc: 0.9940 - val_loss: 6.5804 - val_acc: 0.2140\n",
            "Epoch 536/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 6.6069 - val_acc: 0.2076\n",
            "Epoch 537/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 6.7132 - val_acc: 0.2216\n",
            "Epoch 538/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0236 - acc: 0.9930 - val_loss: 6.6384 - val_acc: 0.2008\n",
            "Epoch 539/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9952 - val_loss: 6.5766 - val_acc: 0.2260\n",
            "Epoch 540/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9959 - val_loss: 6.4321 - val_acc: 0.2300\n",
            "Epoch 541/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0142 - acc: 0.9953 - val_loss: 6.7623 - val_acc: 0.2076\n",
            "Epoch 542/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0198 - acc: 0.9939 - val_loss: 6.6830 - val_acc: 0.2180\n",
            "Epoch 543/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9955 - val_loss: 6.9979 - val_acc: 0.2280\n",
            "Epoch 544/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0128 - acc: 0.9967 - val_loss: 7.0376 - val_acc: 0.1988\n",
            "Epoch 545/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 6.7790 - val_acc: 0.2148\n",
            "Epoch 546/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0164 - acc: 0.9951 - val_loss: 6.3024 - val_acc: 0.2320\n",
            "Epoch 547/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 6.5749 - val_acc: 0.2324\n",
            "Epoch 548/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 6.6483 - val_acc: 0.2008\n",
            "Epoch 549/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 6.7988 - val_acc: 0.2064\n",
            "Epoch 550/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 7.0455 - val_acc: 0.2040\n",
            "Epoch 551/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9952 - val_loss: 6.4160 - val_acc: 0.2124\n",
            "Epoch 552/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0172 - acc: 0.9948 - val_loss: 6.9244 - val_acc: 0.2256\n",
            "Epoch 553/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 6.5106 - val_acc: 0.2248\n",
            "Epoch 554/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0217 - acc: 0.9933 - val_loss: 6.3993 - val_acc: 0.2068\n",
            "Epoch 555/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0164 - acc: 0.9951 - val_loss: 6.6287 - val_acc: 0.2120\n",
            "Epoch 556/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0135 - acc: 0.9958 - val_loss: 6.1514 - val_acc: 0.2372\n",
            "Epoch 557/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0199 - acc: 0.9939 - val_loss: 6.5580 - val_acc: 0.2296\n",
            "Epoch 558/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0265 - acc: 0.9927 - val_loss: 6.3164 - val_acc: 0.2408\n",
            "Epoch 559/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0166 - acc: 0.9951 - val_loss: 6.4327 - val_acc: 0.2124\n",
            "Epoch 560/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 6.4191 - val_acc: 0.2148\n",
            "Epoch 561/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0168 - acc: 0.9944 - val_loss: 6.3987 - val_acc: 0.2128\n",
            "Epoch 562/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0164 - acc: 0.9948 - val_loss: 6.8149 - val_acc: 0.2184\n",
            "Epoch 563/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 6.5235 - val_acc: 0.2212\n",
            "Epoch 564/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 6.7466 - val_acc: 0.2232\n",
            "Epoch 565/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0208 - acc: 0.9941 - val_loss: 6.7161 - val_acc: 0.2152\n",
            "Epoch 566/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0184 - acc: 0.9947 - val_loss: 6.8622 - val_acc: 0.2184\n",
            "Epoch 567/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0175 - acc: 0.9942 - val_loss: 6.5067 - val_acc: 0.2180\n",
            "Epoch 568/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0120 - acc: 0.9956 - val_loss: 6.4233 - val_acc: 0.2144\n",
            "Epoch 569/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0210 - acc: 0.9942 - val_loss: 6.0942 - val_acc: 0.2436\n",
            "Epoch 570/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 6.5446 - val_acc: 0.2100\n",
            "Epoch 571/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0170 - acc: 0.9951 - val_loss: 6.4579 - val_acc: 0.2404\n",
            "Epoch 572/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0180 - acc: 0.9949 - val_loss: 6.5256 - val_acc: 0.2240\n",
            "Epoch 573/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 6.3416 - val_acc: 0.2172\n",
            "Epoch 574/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 6.2703 - val_acc: 0.2284\n",
            "Epoch 575/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0164 - acc: 0.9945 - val_loss: 6.6739 - val_acc: 0.1992\n",
            "Epoch 576/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0155 - acc: 0.9954 - val_loss: 6.6614 - val_acc: 0.2144\n",
            "Epoch 577/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0204 - acc: 0.9940 - val_loss: 6.6652 - val_acc: 0.2300\n",
            "Epoch 578/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0210 - acc: 0.9934 - val_loss: 6.4954 - val_acc: 0.2160\n",
            "Epoch 579/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 6.7494 - val_acc: 0.1964\n",
            "Epoch 580/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 6.6440 - val_acc: 0.1996\n",
            "Epoch 581/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0156 - acc: 0.9948 - val_loss: 6.3055 - val_acc: 0.2200\n",
            "Epoch 582/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0172 - acc: 0.9953 - val_loss: 6.4145 - val_acc: 0.2068\n",
            "Epoch 583/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0209 - acc: 0.9939 - val_loss: 6.5409 - val_acc: 0.2144\n",
            "Epoch 584/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0178 - acc: 0.9941 - val_loss: 6.5718 - val_acc: 0.2248\n",
            "Epoch 585/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 6.7063 - val_acc: 0.2168\n",
            "Epoch 586/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9964 - val_loss: 6.5916 - val_acc: 0.2236\n",
            "Epoch 587/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0158 - acc: 0.9955 - val_loss: 6.6825 - val_acc: 0.2200\n",
            "Epoch 588/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0166 - acc: 0.9952 - val_loss: 6.7511 - val_acc: 0.2064\n",
            "Epoch 589/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0211 - acc: 0.9938 - val_loss: 6.5927 - val_acc: 0.2224\n",
            "Epoch 590/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0163 - acc: 0.9947 - val_loss: 6.7710 - val_acc: 0.2080\n",
            "Epoch 591/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9954 - val_loss: 6.4579 - val_acc: 0.2148\n",
            "Epoch 592/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 6.5194 - val_acc: 0.2120\n",
            "Epoch 593/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 6.5479 - val_acc: 0.2332\n",
            "Epoch 594/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 6.4351 - val_acc: 0.2360\n",
            "Epoch 595/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0202 - acc: 0.9943 - val_loss: 6.4499 - val_acc: 0.2184\n",
            "Epoch 596/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 6.7925 - val_acc: 0.2076\n",
            "Epoch 597/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 6.4468 - val_acc: 0.2184\n",
            "Epoch 598/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0126 - acc: 0.9963 - val_loss: 6.6039 - val_acc: 0.2188\n",
            "Epoch 599/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9955 - val_loss: 6.8987 - val_acc: 0.2104\n",
            "Epoch 600/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 6.5437 - val_acc: 0.2444\n",
            "Epoch 601/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0178 - acc: 0.9954 - val_loss: 6.7089 - val_acc: 0.2240\n",
            "Epoch 602/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0165 - acc: 0.9948 - val_loss: 6.6548 - val_acc: 0.2064\n",
            "Epoch 603/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0190 - acc: 0.9939 - val_loss: 6.3408 - val_acc: 0.2204\n",
            "Epoch 604/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9958 - val_loss: 6.5140 - val_acc: 0.2096\n",
            "Epoch 605/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 6.6107 - val_acc: 0.2112\n",
            "Epoch 606/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0212 - acc: 0.9936 - val_loss: 6.3560 - val_acc: 0.2348\n",
            "Epoch 607/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0253 - acc: 0.9931 - val_loss: 6.0901 - val_acc: 0.2392\n",
            "Epoch 608/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0180 - acc: 0.9947 - val_loss: 6.6567 - val_acc: 0.2200\n",
            "Epoch 609/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0159 - acc: 0.9952 - val_loss: 6.6384 - val_acc: 0.2164\n",
            "Epoch 610/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0179 - acc: 0.9946 - val_loss: 6.4082 - val_acc: 0.2256\n",
            "Epoch 611/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9956 - val_loss: 6.8201 - val_acc: 0.1988\n",
            "Epoch 612/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0185 - acc: 0.9944 - val_loss: 6.3823 - val_acc: 0.2336\n",
            "Epoch 613/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 6.4383 - val_acc: 0.2096\n",
            "Epoch 614/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 6.8948 - val_acc: 0.2120\n",
            "Epoch 615/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0187 - acc: 0.9946 - val_loss: 6.4190 - val_acc: 0.2164\n",
            "Epoch 616/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0158 - acc: 0.9949 - val_loss: 6.3743 - val_acc: 0.2288\n",
            "Epoch 617/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0193 - acc: 0.9938 - val_loss: 6.3986 - val_acc: 0.2208\n",
            "Epoch 618/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 6.3354 - val_acc: 0.2348\n",
            "Epoch 619/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0156 - acc: 0.9957 - val_loss: 6.4777 - val_acc: 0.2088\n",
            "Epoch 620/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9958 - val_loss: 6.4749 - val_acc: 0.2252\n",
            "Epoch 621/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0169 - acc: 0.9948 - val_loss: 6.4762 - val_acc: 0.2248\n",
            "Epoch 622/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0150 - acc: 0.9957 - val_loss: 6.8559 - val_acc: 0.2176\n",
            "Epoch 623/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 6.5711 - val_acc: 0.2276\n",
            "Epoch 624/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 6.3235 - val_acc: 0.2288\n",
            "Epoch 625/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 6.6483 - val_acc: 0.2200\n",
            "Epoch 626/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 6.7339 - val_acc: 0.2116\n",
            "Epoch 627/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0186 - acc: 0.9944 - val_loss: 6.4125 - val_acc: 0.2476\n",
            "Epoch 628/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0171 - acc: 0.9948 - val_loss: 6.2052 - val_acc: 0.2324\n",
            "Epoch 629/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0178 - acc: 0.9954 - val_loss: 6.2534 - val_acc: 0.2180\n",
            "Epoch 630/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9956 - val_loss: 6.6303 - val_acc: 0.2136\n",
            "Epoch 631/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0210 - acc: 0.9948 - val_loss: 6.2283 - val_acc: 0.2472\n",
            "Epoch 632/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0228 - acc: 0.9933 - val_loss: 6.4872 - val_acc: 0.2076\n",
            "Epoch 633/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0181 - acc: 0.9948 - val_loss: 6.1298 - val_acc: 0.2280\n",
            "Epoch 634/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0133 - acc: 0.9960 - val_loss: 6.3376 - val_acc: 0.2228\n",
            "Epoch 635/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9950 - val_loss: 6.3509 - val_acc: 0.2072\n",
            "Epoch 636/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9958 - val_loss: 6.2097 - val_acc: 0.2292\n",
            "Epoch 637/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0168 - acc: 0.9948 - val_loss: 5.9943 - val_acc: 0.2448\n",
            "Epoch 638/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 6.3177 - val_acc: 0.2244\n",
            "Epoch 639/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0117 - acc: 0.9968 - val_loss: 6.2585 - val_acc: 0.2348\n",
            "Epoch 640/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0153 - acc: 0.9956 - val_loss: 6.8515 - val_acc: 0.2224\n",
            "Epoch 641/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0174 - acc: 0.9953 - val_loss: 6.8298 - val_acc: 0.2160\n",
            "Epoch 642/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0179 - acc: 0.9952 - val_loss: 6.5942 - val_acc: 0.2084\n",
            "Epoch 643/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 6.8484 - val_acc: 0.2040\n",
            "Epoch 644/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0161 - acc: 0.9951 - val_loss: 6.8562 - val_acc: 0.2028\n",
            "Epoch 645/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0192 - acc: 0.9950 - val_loss: 6.4772 - val_acc: 0.2304\n",
            "Epoch 646/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0138 - acc: 0.9958 - val_loss: 6.5057 - val_acc: 0.2084\n",
            "Epoch 647/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0145 - acc: 0.9957 - val_loss: 6.3071 - val_acc: 0.2304\n",
            "Epoch 648/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0154 - acc: 0.9956 - val_loss: 6.5119 - val_acc: 0.2052\n",
            "Epoch 649/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0202 - acc: 0.9940 - val_loss: 6.5923 - val_acc: 0.2120\n",
            "Epoch 650/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0186 - acc: 0.9943 - val_loss: 6.2718 - val_acc: 0.2176\n",
            "Epoch 651/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0140 - acc: 0.9961 - val_loss: 6.2209 - val_acc: 0.2284\n",
            "Epoch 652/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 6.2576 - val_acc: 0.2276\n",
            "Epoch 653/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0198 - acc: 0.9940 - val_loss: 6.6038 - val_acc: 0.2216\n",
            "Epoch 654/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0202 - acc: 0.9941 - val_loss: 6.3245 - val_acc: 0.2120\n",
            "Epoch 655/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0191 - acc: 0.9941 - val_loss: 6.8203 - val_acc: 0.2084\n",
            "Epoch 656/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0173 - acc: 0.9947 - val_loss: 6.3633 - val_acc: 0.2320\n",
            "Epoch 657/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 6.6476 - val_acc: 0.2136\n",
            "Epoch 658/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 6.5333 - val_acc: 0.2208\n",
            "Epoch 659/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0120 - acc: 0.9965 - val_loss: 6.4522 - val_acc: 0.2196\n",
            "Epoch 660/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0251 - acc: 0.9928 - val_loss: 6.4271 - val_acc: 0.2188\n",
            "Epoch 661/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0210 - acc: 0.9940 - val_loss: 6.2637 - val_acc: 0.2108\n",
            "Epoch 662/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9951 - val_loss: 6.4127 - val_acc: 0.2172\n",
            "Epoch 663/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 6.0861 - val_acc: 0.2312\n",
            "Epoch 664/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0174 - acc: 0.9944 - val_loss: 6.3343 - val_acc: 0.2296\n",
            "Epoch 665/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 6.4492 - val_acc: 0.2176\n",
            "Epoch 666/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0162 - acc: 0.9954 - val_loss: 6.2185 - val_acc: 0.2344\n",
            "Epoch 667/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9955 - val_loss: 6.3054 - val_acc: 0.2328\n",
            "Epoch 668/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0127 - acc: 0.9961 - val_loss: 6.4622 - val_acc: 0.2288\n",
            "Epoch 669/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 6.4590 - val_acc: 0.2348\n",
            "Epoch 670/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0196 - acc: 0.9950 - val_loss: 6.5298 - val_acc: 0.2336\n",
            "Epoch 671/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0150 - acc: 0.9949 - val_loss: 6.2808 - val_acc: 0.2360\n",
            "Epoch 672/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9961 - val_loss: 6.5875 - val_acc: 0.2324\n",
            "Epoch 673/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 6.7263 - val_acc: 0.2292\n",
            "Epoch 674/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0235 - acc: 0.9933 - val_loss: 6.5549 - val_acc: 0.2176\n",
            "Epoch 675/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0231 - acc: 0.9935 - val_loss: 6.3449 - val_acc: 0.2324\n",
            "Epoch 676/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0159 - acc: 0.9952 - val_loss: 6.6667 - val_acc: 0.2300\n",
            "Epoch 677/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 6.9872 - val_acc: 0.1960\n",
            "Epoch 678/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0179 - acc: 0.9949 - val_loss: 6.5189 - val_acc: 0.2244\n",
            "Epoch 679/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0130 - acc: 0.9962 - val_loss: 6.5442 - val_acc: 0.2012\n",
            "Epoch 680/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0115 - acc: 0.9964 - val_loss: 6.5141 - val_acc: 0.2048\n",
            "Epoch 681/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 6.6820 - val_acc: 0.2236\n",
            "Epoch 682/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9952 - val_loss: 6.7557 - val_acc: 0.2188\n",
            "Epoch 683/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9957 - val_loss: 7.3001 - val_acc: 0.2060\n",
            "Epoch 684/1000\n",
            "22500/22500 [==============================] - 2s 84us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 6.8022 - val_acc: 0.2276\n",
            "Epoch 685/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0185 - acc: 0.9948 - val_loss: 6.7142 - val_acc: 0.2104\n",
            "Epoch 686/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0161 - acc: 0.9953 - val_loss: 6.5215 - val_acc: 0.2260\n",
            "Epoch 687/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 6.8286 - val_acc: 0.2136\n",
            "Epoch 688/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 6.5283 - val_acc: 0.2368\n",
            "Epoch 689/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0188 - acc: 0.9948 - val_loss: 6.4875 - val_acc: 0.2256\n",
            "Epoch 690/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9956 - val_loss: 6.6754 - val_acc: 0.1992\n",
            "Epoch 691/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 6.4089 - val_acc: 0.2152\n",
            "Epoch 692/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9953 - val_loss: 6.6347 - val_acc: 0.1976\n",
            "Epoch 693/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9958 - val_loss: 6.9152 - val_acc: 0.1928\n",
            "Epoch 694/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9953 - val_loss: 6.6257 - val_acc: 0.2252\n",
            "Epoch 695/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0212 - acc: 0.9944 - val_loss: 6.8385 - val_acc: 0.2028\n",
            "Epoch 696/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0167 - acc: 0.9953 - val_loss: 6.8045 - val_acc: 0.2008\n",
            "Epoch 697/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9955 - val_loss: 6.4683 - val_acc: 0.2284\n",
            "Epoch 698/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0110 - acc: 0.9967 - val_loss: 6.5608 - val_acc: 0.2144\n",
            "Epoch 699/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0134 - acc: 0.9968 - val_loss: 6.4764 - val_acc: 0.2160\n",
            "Epoch 700/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0134 - acc: 0.9961 - val_loss: 6.7273 - val_acc: 0.2152\n",
            "Epoch 701/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 6.7522 - val_acc: 0.2148\n",
            "Epoch 702/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0167 - acc: 0.9949 - val_loss: 6.8119 - val_acc: 0.2276\n",
            "Epoch 703/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0172 - acc: 0.9948 - val_loss: 6.5280 - val_acc: 0.2380\n",
            "Epoch 704/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0177 - acc: 0.9948 - val_loss: 6.6104 - val_acc: 0.1992\n",
            "Epoch 705/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9951 - val_loss: 7.0783 - val_acc: 0.2012\n",
            "Epoch 706/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0186 - acc: 0.9944 - val_loss: 6.5240 - val_acc: 0.2260\n",
            "Epoch 707/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0153 - acc: 0.9956 - val_loss: 6.4634 - val_acc: 0.2128\n",
            "Epoch 708/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0134 - acc: 0.9961 - val_loss: 6.9427 - val_acc: 0.2136\n",
            "Epoch 709/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0102 - acc: 0.9967 - val_loss: 6.6631 - val_acc: 0.2144\n",
            "Epoch 710/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0146 - acc: 0.9963 - val_loss: 6.6912 - val_acc: 0.2088\n",
            "Epoch 711/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0151 - acc: 0.9957 - val_loss: 6.4235 - val_acc: 0.2356\n",
            "Epoch 712/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0136 - acc: 0.9961 - val_loss: 6.6120 - val_acc: 0.2216\n",
            "Epoch 713/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9959 - val_loss: 6.6070 - val_acc: 0.2088\n",
            "Epoch 714/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9960 - val_loss: 6.3850 - val_acc: 0.2344\n",
            "Epoch 715/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 6.5299 - val_acc: 0.2252\n",
            "Epoch 716/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0153 - acc: 0.9953 - val_loss: 6.1327 - val_acc: 0.2268\n",
            "Epoch 717/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0207 - acc: 0.9939 - val_loss: 6.4386 - val_acc: 0.2344\n",
            "Epoch 718/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0156 - acc: 0.9955 - val_loss: 6.2039 - val_acc: 0.2516\n",
            "Epoch 719/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 6.5228 - val_acc: 0.2156\n",
            "Epoch 720/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0139 - acc: 0.9961 - val_loss: 6.7343 - val_acc: 0.2128\n",
            "Epoch 721/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0172 - acc: 0.9948 - val_loss: 6.3533 - val_acc: 0.2400\n",
            "Epoch 722/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0201 - acc: 0.9940 - val_loss: 6.4548 - val_acc: 0.2336\n",
            "Epoch 723/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 6.4427 - val_acc: 0.2216\n",
            "Epoch 724/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0138 - acc: 0.9954 - val_loss: 6.3810 - val_acc: 0.2276\n",
            "Epoch 725/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9961 - val_loss: 6.8193 - val_acc: 0.2160\n",
            "Epoch 726/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 6.5164 - val_acc: 0.2188\n",
            "Epoch 727/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9953 - val_loss: 7.0861 - val_acc: 0.2072\n",
            "Epoch 728/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 6.9773 - val_acc: 0.2088\n",
            "Epoch 729/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0132 - acc: 0.9956 - val_loss: 6.4947 - val_acc: 0.2324\n",
            "Epoch 730/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0127 - acc: 0.9963 - val_loss: 6.5182 - val_acc: 0.2324\n",
            "Epoch 731/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 6.6872 - val_acc: 0.2308\n",
            "Epoch 732/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0196 - acc: 0.9940 - val_loss: 6.4584 - val_acc: 0.2428\n",
            "Epoch 733/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0176 - acc: 0.9943 - val_loss: 6.4006 - val_acc: 0.2256\n",
            "Epoch 734/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0203 - acc: 0.9940 - val_loss: 6.4981 - val_acc: 0.2224\n",
            "Epoch 735/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 6.4093 - val_acc: 0.2252\n",
            "Epoch 736/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 6.2113 - val_acc: 0.2412\n",
            "Epoch 737/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0129 - acc: 0.9970 - val_loss: 6.6456 - val_acc: 0.2200\n",
            "Epoch 738/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0124 - acc: 0.9963 - val_loss: 6.8219 - val_acc: 0.2088\n",
            "Epoch 739/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0189 - acc: 0.9950 - val_loss: 6.7155 - val_acc: 0.2100\n",
            "Epoch 740/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0205 - acc: 0.9941 - val_loss: 6.7356 - val_acc: 0.2072\n",
            "Epoch 741/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 6.4915 - val_acc: 0.2332\n",
            "Epoch 742/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 6.9291 - val_acc: 0.2088\n",
            "Epoch 743/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0120 - acc: 0.9956 - val_loss: 6.5417 - val_acc: 0.2108\n",
            "Epoch 744/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 6.4818 - val_acc: 0.2416\n",
            "Epoch 745/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0191 - acc: 0.9946 - val_loss: 6.6070 - val_acc: 0.2232\n",
            "Epoch 746/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 6.5576 - val_acc: 0.2184\n",
            "Epoch 747/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 6.6321 - val_acc: 0.2220\n",
            "Epoch 748/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9959 - val_loss: 6.4219 - val_acc: 0.2348\n",
            "Epoch 749/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 6.6069 - val_acc: 0.2232\n",
            "Epoch 750/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9957 - val_loss: 6.6923 - val_acc: 0.2252\n",
            "Epoch 751/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0151 - acc: 0.9959 - val_loss: 6.8974 - val_acc: 0.1888\n",
            "Epoch 752/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0112 - acc: 0.9968 - val_loss: 6.6724 - val_acc: 0.2116\n",
            "Epoch 753/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0153 - acc: 0.9959 - val_loss: 6.7273 - val_acc: 0.2028\n",
            "Epoch 754/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0117 - acc: 0.9965 - val_loss: 6.3318 - val_acc: 0.2392\n",
            "Epoch 755/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0143 - acc: 0.9959 - val_loss: 6.4713 - val_acc: 0.2032\n",
            "Epoch 756/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0143 - acc: 0.9957 - val_loss: 6.8220 - val_acc: 0.2112\n",
            "Epoch 757/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0175 - acc: 0.9948 - val_loss: 6.7176 - val_acc: 0.2312\n",
            "Epoch 758/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 6.8408 - val_acc: 0.2044\n",
            "Epoch 759/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 6.6817 - val_acc: 0.2180\n",
            "Epoch 760/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 6.5168 - val_acc: 0.2236\n",
            "Epoch 761/1000\n",
            "22500/22500 [==============================] - 2s 90us/step - loss: 0.0127 - acc: 0.9959 - val_loss: 6.8857 - val_acc: 0.2028\n",
            "Epoch 762/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0129 - acc: 0.9956 - val_loss: 7.2545 - val_acc: 0.1904\n",
            "Epoch 763/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0182 - acc: 0.9952 - val_loss: 6.6212 - val_acc: 0.2292\n",
            "Epoch 764/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0139 - acc: 0.9958 - val_loss: 6.5378 - val_acc: 0.2200\n",
            "Epoch 765/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0204 - acc: 0.9946 - val_loss: 6.5083 - val_acc: 0.2112\n",
            "Epoch 766/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 6.8959 - val_acc: 0.2040\n",
            "Epoch 767/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 6.7686 - val_acc: 0.2360\n",
            "Epoch 768/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0111 - acc: 0.9968 - val_loss: 6.6056 - val_acc: 0.2300\n",
            "Epoch 769/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0147 - acc: 0.9956 - val_loss: 6.6699 - val_acc: 0.2284\n",
            "Epoch 770/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0132 - acc: 0.9968 - val_loss: 6.8183 - val_acc: 0.2408\n",
            "Epoch 771/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0183 - acc: 0.9948 - val_loss: 6.5149 - val_acc: 0.2244\n",
            "Epoch 772/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0154 - acc: 0.9959 - val_loss: 7.0176 - val_acc: 0.2224\n",
            "Epoch 773/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0162 - acc: 0.9956 - val_loss: 6.6912 - val_acc: 0.2232\n",
            "Epoch 774/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 6.4094 - val_acc: 0.2016\n",
            "Epoch 775/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9958 - val_loss: 6.4657 - val_acc: 0.2256\n",
            "Epoch 776/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0163 - acc: 0.9952 - val_loss: 6.5051 - val_acc: 0.2096\n",
            "Epoch 777/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0097 - acc: 0.9965 - val_loss: 6.6850 - val_acc: 0.2208\n",
            "Epoch 778/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0133 - acc: 0.9964 - val_loss: 6.8064 - val_acc: 0.2280\n",
            "Epoch 779/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 6.3384 - val_acc: 0.2260\n",
            "Epoch 780/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 6.5773 - val_acc: 0.2244\n",
            "Epoch 781/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0174 - acc: 0.9945 - val_loss: 6.5847 - val_acc: 0.2448\n",
            "Epoch 782/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 6.4595 - val_acc: 0.2324\n",
            "Epoch 783/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0153 - acc: 0.9960 - val_loss: 6.3348 - val_acc: 0.2392\n",
            "Epoch 784/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 6.7083 - val_acc: 0.2212\n",
            "Epoch 785/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0160 - acc: 0.9955 - val_loss: 6.5438 - val_acc: 0.2372\n",
            "Epoch 786/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 6.2422 - val_acc: 0.2372\n",
            "Epoch 787/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0161 - acc: 0.9954 - val_loss: 6.4723 - val_acc: 0.2188\n",
            "Epoch 788/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9954 - val_loss: 6.5464 - val_acc: 0.2312\n",
            "Epoch 789/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 6.7584 - val_acc: 0.2328\n",
            "Epoch 790/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 6.6378 - val_acc: 0.2268\n",
            "Epoch 791/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 6.9115 - val_acc: 0.2192\n",
            "Epoch 792/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0155 - acc: 0.9952 - val_loss: 6.9615 - val_acc: 0.2160\n",
            "Epoch 793/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0172 - acc: 0.9949 - val_loss: 6.4265 - val_acc: 0.2240\n",
            "Epoch 794/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9953 - val_loss: 6.5484 - val_acc: 0.2360\n",
            "Epoch 795/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 6.6341 - val_acc: 0.2284\n",
            "Epoch 796/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0157 - acc: 0.9958 - val_loss: 6.3446 - val_acc: 0.2432\n",
            "Epoch 797/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0182 - acc: 0.9945 - val_loss: 6.6045 - val_acc: 0.2344\n",
            "Epoch 798/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0167 - acc: 0.9954 - val_loss: 6.5940 - val_acc: 0.2596\n",
            "Epoch 799/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0171 - acc: 0.9957 - val_loss: 6.6697 - val_acc: 0.2220\n",
            "Epoch 800/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0129 - acc: 0.9961 - val_loss: 6.5838 - val_acc: 0.2300\n",
            "Epoch 801/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0144 - acc: 0.9955 - val_loss: 6.6787 - val_acc: 0.2284\n",
            "Epoch 802/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0172 - acc: 0.9945 - val_loss: 6.2659 - val_acc: 0.2128\n",
            "Epoch 803/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 6.4881 - val_acc: 0.2372\n",
            "Epoch 804/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 6.7756 - val_acc: 0.2064\n",
            "Epoch 805/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9955 - val_loss: 6.6947 - val_acc: 0.2248\n",
            "Epoch 806/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 6.6523 - val_acc: 0.2232\n",
            "Epoch 807/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9955 - val_loss: 6.6786 - val_acc: 0.2200\n",
            "Epoch 808/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0141 - acc: 0.9965 - val_loss: 6.8372 - val_acc: 0.2328\n",
            "Epoch 809/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0177 - acc: 0.9956 - val_loss: 6.6744 - val_acc: 0.2288\n",
            "Epoch 810/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 6.7540 - val_acc: 0.2204\n",
            "Epoch 811/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0130 - acc: 0.9964 - val_loss: 6.5955 - val_acc: 0.2148\n",
            "Epoch 812/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 6.6890 - val_acc: 0.2084\n",
            "Epoch 813/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 6.7017 - val_acc: 0.2216\n",
            "Epoch 814/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 6.8550 - val_acc: 0.2092\n",
            "Epoch 815/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 6.9200 - val_acc: 0.2012\n",
            "Epoch 816/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 6.9801 - val_acc: 0.2076\n",
            "Epoch 817/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0165 - acc: 0.9954 - val_loss: 6.3760 - val_acc: 0.2180\n",
            "Epoch 818/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 6.4738 - val_acc: 0.2300\n",
            "Epoch 819/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9966 - val_loss: 6.7255 - val_acc: 0.2108\n",
            "Epoch 820/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 6.7092 - val_acc: 0.2324\n",
            "Epoch 821/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0140 - acc: 0.9958 - val_loss: 6.8021 - val_acc: 0.2244\n",
            "Epoch 822/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 6.9033 - val_acc: 0.2264\n",
            "Epoch 823/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 6.6518 - val_acc: 0.2064\n",
            "Epoch 824/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 6.7071 - val_acc: 0.2188\n",
            "Epoch 825/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 6.6371 - val_acc: 0.2252\n",
            "Epoch 826/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 6.3640 - val_acc: 0.2372\n",
            "Epoch 827/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9957 - val_loss: 6.6871 - val_acc: 0.2100\n",
            "Epoch 828/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9965 - val_loss: 6.6539 - val_acc: 0.2108\n",
            "Epoch 829/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0113 - acc: 0.9962 - val_loss: 6.5396 - val_acc: 0.2248\n",
            "Epoch 830/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0178 - acc: 0.9955 - val_loss: 6.4749 - val_acc: 0.2152\n",
            "Epoch 831/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0167 - acc: 0.9951 - val_loss: 6.7412 - val_acc: 0.2192\n",
            "Epoch 832/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 7.1181 - val_acc: 0.2140\n",
            "Epoch 833/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0127 - acc: 0.9958 - val_loss: 6.5548 - val_acc: 0.2280\n",
            "Epoch 834/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0132 - acc: 0.9962 - val_loss: 6.4630 - val_acc: 0.2368\n",
            "Epoch 835/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9959 - val_loss: 6.8220 - val_acc: 0.2172\n",
            "Epoch 836/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9958 - val_loss: 6.8566 - val_acc: 0.2304\n",
            "Epoch 837/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0130 - acc: 0.9959 - val_loss: 6.5905 - val_acc: 0.2180\n",
            "Epoch 838/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 7.0851 - val_acc: 0.1980\n",
            "Epoch 839/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0145 - acc: 0.9961 - val_loss: 6.7011 - val_acc: 0.2180\n",
            "Epoch 840/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0114 - acc: 0.9964 - val_loss: 7.1872 - val_acc: 0.2020\n",
            "Epoch 841/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0119 - acc: 0.9970 - val_loss: 7.0533 - val_acc: 0.2048\n",
            "Epoch 842/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0130 - acc: 0.9961 - val_loss: 6.7056 - val_acc: 0.2116\n",
            "Epoch 843/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 6.9858 - val_acc: 0.2168\n",
            "Epoch 844/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0113 - acc: 0.9961 - val_loss: 6.8553 - val_acc: 0.2068\n",
            "Epoch 845/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 6.7243 - val_acc: 0.2224\n",
            "Epoch 846/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 6.6875 - val_acc: 0.2308\n",
            "Epoch 847/1000\n",
            "22500/22500 [==============================] - 2s 84us/step - loss: 0.0167 - acc: 0.9952 - val_loss: 7.1217 - val_acc: 0.2268\n",
            "Epoch 848/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0148 - acc: 0.9961 - val_loss: 6.7268 - val_acc: 0.2512\n",
            "Epoch 849/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0162 - acc: 0.9949 - val_loss: 6.9727 - val_acc: 0.2004\n",
            "Epoch 850/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9956 - val_loss: 6.7891 - val_acc: 0.2108\n",
            "Epoch 851/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0160 - acc: 0.9956 - val_loss: 6.6601 - val_acc: 0.2132\n",
            "Epoch 852/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0099 - acc: 0.9968 - val_loss: 6.5875 - val_acc: 0.2120\n",
            "Epoch 853/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0129 - acc: 0.9964 - val_loss: 6.6397 - val_acc: 0.2176\n",
            "Epoch 854/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0140 - acc: 0.9963 - val_loss: 6.8038 - val_acc: 0.2104\n",
            "Epoch 855/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 6.9566 - val_acc: 0.2020\n",
            "Epoch 856/1000\n",
            "22500/22500 [==============================] - 2s 89us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 6.6951 - val_acc: 0.2220\n",
            "Epoch 857/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0121 - acc: 0.9960 - val_loss: 6.8144 - val_acc: 0.2036\n",
            "Epoch 858/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 6.6437 - val_acc: 0.2132\n",
            "Epoch 859/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0192 - acc: 0.9947 - val_loss: 6.4745 - val_acc: 0.2096\n",
            "Epoch 860/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0153 - acc: 0.9958 - val_loss: 6.7219 - val_acc: 0.2072\n",
            "Epoch 861/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0129 - acc: 0.9962 - val_loss: 6.7251 - val_acc: 0.1992\n",
            "Epoch 862/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0119 - acc: 0.9961 - val_loss: 6.4704 - val_acc: 0.2448\n",
            "Epoch 863/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0141 - acc: 0.9962 - val_loss: 6.4073 - val_acc: 0.2252\n",
            "Epoch 864/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0114 - acc: 0.9963 - val_loss: 6.4876 - val_acc: 0.2136\n",
            "Epoch 865/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0178 - acc: 0.9946 - val_loss: 6.5313 - val_acc: 0.2272\n",
            "Epoch 866/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0126 - acc: 0.9958 - val_loss: 6.6128 - val_acc: 0.2200\n",
            "Epoch 867/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0102 - acc: 0.9974 - val_loss: 6.5981 - val_acc: 0.2148\n",
            "Epoch 868/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0126 - acc: 0.9964 - val_loss: 6.4301 - val_acc: 0.2188\n",
            "Epoch 869/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0134 - acc: 0.9961 - val_loss: 6.8314 - val_acc: 0.2244\n",
            "Epoch 870/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0143 - acc: 0.9957 - val_loss: 6.8543 - val_acc: 0.1996\n",
            "Epoch 871/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0163 - acc: 0.9951 - val_loss: 6.8041 - val_acc: 0.2008\n",
            "Epoch 872/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9954 - val_loss: 6.6037 - val_acc: 0.2156\n",
            "Epoch 873/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9964 - val_loss: 6.5652 - val_acc: 0.2072\n",
            "Epoch 874/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 7.0407 - val_acc: 0.2092\n",
            "Epoch 875/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0121 - acc: 0.9965 - val_loss: 6.8130 - val_acc: 0.2164\n",
            "Epoch 876/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 7.0759 - val_acc: 0.2092\n",
            "Epoch 877/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0140 - acc: 0.9956 - val_loss: 6.8043 - val_acc: 0.2192\n",
            "Epoch 878/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0142 - acc: 0.9957 - val_loss: 6.7220 - val_acc: 0.2296\n",
            "Epoch 879/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 7.0019 - val_acc: 0.2044\n",
            "Epoch 880/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 7.0125 - val_acc: 0.2168\n",
            "Epoch 881/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0181 - acc: 0.9949 - val_loss: 6.9120 - val_acc: 0.2348\n",
            "Epoch 882/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 6.7474 - val_acc: 0.2240\n",
            "Epoch 883/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0136 - acc: 0.9962 - val_loss: 6.4749 - val_acc: 0.2400\n",
            "Epoch 884/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0127 - acc: 0.9966 - val_loss: 6.3817 - val_acc: 0.2268\n",
            "Epoch 885/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 6.4415 - val_acc: 0.2280\n",
            "Epoch 886/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 6.5023 - val_acc: 0.2352\n",
            "Epoch 887/1000\n",
            "22500/22500 [==============================] - 2s 91us/step - loss: 0.0104 - acc: 0.9968 - val_loss: 6.4589 - val_acc: 0.2328\n",
            "Epoch 888/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 6.7298 - val_acc: 0.2076\n",
            "Epoch 889/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 6.9575 - val_acc: 0.2180\n",
            "Epoch 890/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0194 - acc: 0.9949 - val_loss: 6.6206 - val_acc: 0.2352\n",
            "Epoch 891/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0193 - acc: 0.9944 - val_loss: 6.5400 - val_acc: 0.2336\n",
            "Epoch 892/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0145 - acc: 0.9960 - val_loss: 6.6005 - val_acc: 0.2164\n",
            "Epoch 893/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9961 - val_loss: 6.7695 - val_acc: 0.1980\n",
            "Epoch 894/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0191 - acc: 0.9940 - val_loss: 6.3635 - val_acc: 0.2308\n",
            "Epoch 895/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0191 - acc: 0.9944 - val_loss: 6.7351 - val_acc: 0.2196\n",
            "Epoch 896/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0115 - acc: 0.9961 - val_loss: 6.7092 - val_acc: 0.2020\n",
            "Epoch 897/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0131 - acc: 0.9962 - val_loss: 6.4920 - val_acc: 0.2332\n",
            "Epoch 898/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9961 - val_loss: 6.8018 - val_acc: 0.2016\n",
            "Epoch 899/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 6.2100 - val_acc: 0.2308\n",
            "Epoch 900/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0158 - acc: 0.9955 - val_loss: 6.2891 - val_acc: 0.2316\n",
            "Epoch 901/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 6.4276 - val_acc: 0.2196\n",
            "Epoch 902/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 6.8503 - val_acc: 0.1956\n",
            "Epoch 903/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0129 - acc: 0.9968 - val_loss: 6.3914 - val_acc: 0.2288\n",
            "Epoch 904/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 6.4804 - val_acc: 0.2372\n",
            "Epoch 905/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0113 - acc: 0.9960 - val_loss: 6.6969 - val_acc: 0.2168\n",
            "Epoch 906/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 7.0971 - val_acc: 0.2044\n",
            "Epoch 907/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9956 - val_loss: 6.9282 - val_acc: 0.1940\n",
            "Epoch 908/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9960 - val_loss: 6.4295 - val_acc: 0.2360\n",
            "Epoch 909/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0154 - acc: 0.9954 - val_loss: 6.7383 - val_acc: 0.2316\n",
            "Epoch 910/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0137 - acc: 0.9962 - val_loss: 6.4911 - val_acc: 0.2344\n",
            "Epoch 911/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 6.6510 - val_acc: 0.2068\n",
            "Epoch 912/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 6.7092 - val_acc: 0.2248\n",
            "Epoch 913/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0140 - acc: 0.9961 - val_loss: 6.8269 - val_acc: 0.2096\n",
            "Epoch 914/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 6.7788 - val_acc: 0.2036\n",
            "Epoch 915/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0161 - acc: 0.9954 - val_loss: 6.4785 - val_acc: 0.2088\n",
            "Epoch 916/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0119 - acc: 0.9962 - val_loss: 6.6612 - val_acc: 0.2180\n",
            "Epoch 917/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0141 - acc: 0.9960 - val_loss: 6.8104 - val_acc: 0.2112\n",
            "Epoch 918/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0113 - acc: 0.9972 - val_loss: 6.8381 - val_acc: 0.2168\n",
            "Epoch 919/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0114 - acc: 0.9966 - val_loss: 6.5734 - val_acc: 0.2232\n",
            "Epoch 920/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0131 - acc: 0.9961 - val_loss: 7.2303 - val_acc: 0.1896\n",
            "Epoch 921/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0159 - acc: 0.9956 - val_loss: 6.7855 - val_acc: 0.2140\n",
            "Epoch 922/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0188 - acc: 0.9950 - val_loss: 6.3613 - val_acc: 0.2348\n",
            "Epoch 923/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0119 - acc: 0.9966 - val_loss: 6.5364 - val_acc: 0.2128\n",
            "Epoch 924/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0121 - acc: 0.9962 - val_loss: 6.2088 - val_acc: 0.2404\n",
            "Epoch 925/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0146 - acc: 0.9956 - val_loss: 6.9844 - val_acc: 0.2020\n",
            "Epoch 926/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 6.5651 - val_acc: 0.2344\n",
            "Epoch 927/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0139 - acc: 0.9960 - val_loss: 6.5145 - val_acc: 0.2172\n",
            "Epoch 928/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0130 - acc: 0.9963 - val_loss: 6.4875 - val_acc: 0.2248\n",
            "Epoch 929/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 6.4053 - val_acc: 0.2064\n",
            "Epoch 930/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 6.7005 - val_acc: 0.2236\n",
            "Epoch 931/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0136 - acc: 0.9963 - val_loss: 6.8031 - val_acc: 0.2300\n",
            "Epoch 932/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0155 - acc: 0.9958 - val_loss: 6.8695 - val_acc: 0.2072\n",
            "Epoch 933/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0141 - acc: 0.9959 - val_loss: 6.9069 - val_acc: 0.2168\n",
            "Epoch 934/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 6.8178 - val_acc: 0.1928\n",
            "Epoch 935/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 6.8025 - val_acc: 0.2152\n",
            "Epoch 936/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0106 - acc: 0.9970 - val_loss: 6.8920 - val_acc: 0.2004\n",
            "Epoch 937/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 6.7331 - val_acc: 0.2068\n",
            "Epoch 938/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 6.8200 - val_acc: 0.2272\n",
            "Epoch 939/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0171 - acc: 0.9950 - val_loss: 6.5584 - val_acc: 0.2240\n",
            "Epoch 940/1000\n",
            "22500/22500 [==============================] - 2s 87us/step - loss: 0.0138 - acc: 0.9962 - val_loss: 6.4767 - val_acc: 0.2272\n",
            "Epoch 941/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0099 - acc: 0.9968 - val_loss: 6.8166 - val_acc: 0.2220\n",
            "Epoch 942/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0115 - acc: 0.9968 - val_loss: 6.5305 - val_acc: 0.2268\n",
            "Epoch 943/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0114 - acc: 0.9968 - val_loss: 6.6589 - val_acc: 0.2180\n",
            "Epoch 944/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0131 - acc: 0.9964 - val_loss: 7.0781 - val_acc: 0.2044\n",
            "Epoch 945/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0154 - acc: 0.9956 - val_loss: 6.8928 - val_acc: 0.2060\n",
            "Epoch 946/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0179 - acc: 0.9952 - val_loss: 7.2741 - val_acc: 0.2300\n",
            "Epoch 947/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 6.6614 - val_acc: 0.2196\n",
            "Epoch 948/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0111 - acc: 0.9965 - val_loss: 6.5931 - val_acc: 0.2260\n",
            "Epoch 949/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 6.9514 - val_acc: 0.2112\n",
            "Epoch 950/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0146 - acc: 0.9949 - val_loss: 6.7580 - val_acc: 0.2224\n",
            "Epoch 951/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 6.8727 - val_acc: 0.2032\n",
            "Epoch 952/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0161 - acc: 0.9955 - val_loss: 6.6381 - val_acc: 0.2332\n",
            "Epoch 953/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0196 - acc: 0.9949 - val_loss: 6.9911 - val_acc: 0.2044\n",
            "Epoch 954/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0182 - acc: 0.9945 - val_loss: 6.5445 - val_acc: 0.2316\n",
            "Epoch 955/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0136 - acc: 0.9963 - val_loss: 6.7396 - val_acc: 0.2088\n",
            "Epoch 956/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0109 - acc: 0.9967 - val_loss: 6.6255 - val_acc: 0.2256\n",
            "Epoch 957/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 6.6559 - val_acc: 0.2152\n",
            "Epoch 958/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0152 - acc: 0.9957 - val_loss: 6.3951 - val_acc: 0.2180\n",
            "Epoch 959/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 6.6323 - val_acc: 0.2248\n",
            "Epoch 960/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0144 - acc: 0.9957 - val_loss: 6.6398 - val_acc: 0.2292\n",
            "Epoch 961/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0103 - acc: 0.9971 - val_loss: 6.5787 - val_acc: 0.2220\n",
            "Epoch 962/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0133 - acc: 0.9962 - val_loss: 6.3752 - val_acc: 0.2356\n",
            "Epoch 963/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0106 - acc: 0.9971 - val_loss: 6.4417 - val_acc: 0.2348\n",
            "Epoch 964/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0186 - acc: 0.9949 - val_loss: 6.3538 - val_acc: 0.2520\n",
            "Epoch 965/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0200 - acc: 0.9940 - val_loss: 6.4023 - val_acc: 0.2068\n",
            "Epoch 966/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0130 - acc: 0.9958 - val_loss: 6.2195 - val_acc: 0.2352\n",
            "Epoch 967/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 6.4478 - val_acc: 0.2152\n",
            "Epoch 968/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0145 - acc: 0.9960 - val_loss: 6.8316 - val_acc: 0.1968\n",
            "Epoch 969/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0173 - acc: 0.9952 - val_loss: 6.6790 - val_acc: 0.2196\n",
            "Epoch 970/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0122 - acc: 0.9962 - val_loss: 6.4313 - val_acc: 0.2220\n",
            "Epoch 971/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0139 - acc: 0.9960 - val_loss: 6.6725 - val_acc: 0.2268\n",
            "Epoch 972/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0118 - acc: 0.9967 - val_loss: 6.7931 - val_acc: 0.2208\n",
            "Epoch 973/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0107 - acc: 0.9970 - val_loss: 6.6631 - val_acc: 0.2176\n",
            "Epoch 974/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0156 - acc: 0.9956 - val_loss: 6.9318 - val_acc: 0.2368\n",
            "Epoch 975/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0182 - acc: 0.9952 - val_loss: 6.6358 - val_acc: 0.2140\n",
            "Epoch 976/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0099 - acc: 0.9972 - val_loss: 6.8792 - val_acc: 0.2080\n",
            "Epoch 977/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0120 - acc: 0.9967 - val_loss: 7.0132 - val_acc: 0.2036\n",
            "Epoch 978/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 6.8864 - val_acc: 0.2144\n",
            "Epoch 979/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0102 - acc: 0.9970 - val_loss: 6.5127 - val_acc: 0.2348\n",
            "Epoch 980/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 6.7605 - val_acc: 0.2244\n",
            "Epoch 981/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0144 - acc: 0.9965 - val_loss: 6.6624 - val_acc: 0.2152\n",
            "Epoch 982/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0133 - acc: 0.9962 - val_loss: 6.5200 - val_acc: 0.2300\n",
            "Epoch 983/1000\n",
            "22500/22500 [==============================] - 2s 84us/step - loss: 0.0184 - acc: 0.9946 - val_loss: 6.3267 - val_acc: 0.2256\n",
            "Epoch 984/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0165 - acc: 0.9952 - val_loss: 6.2752 - val_acc: 0.2280\n",
            "Epoch 985/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0104 - acc: 0.9972 - val_loss: 6.3925 - val_acc: 0.2216\n",
            "Epoch 986/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 6.1795 - val_acc: 0.2276\n",
            "Epoch 987/1000\n",
            "22500/22500 [==============================] - 2s 88us/step - loss: 0.0109 - acc: 0.9969 - val_loss: 6.5548 - val_acc: 0.2128\n",
            "Epoch 988/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0144 - acc: 0.9960 - val_loss: 6.5532 - val_acc: 0.2108\n",
            "Epoch 989/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 6.6610 - val_acc: 0.2156\n",
            "Epoch 990/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 6.5713 - val_acc: 0.2224\n",
            "Epoch 991/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0150 - acc: 0.9956 - val_loss: 6.6351 - val_acc: 0.2084\n",
            "Epoch 992/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0160 - acc: 0.9952 - val_loss: 6.7328 - val_acc: 0.2192\n",
            "Epoch 993/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0146 - acc: 0.9957 - val_loss: 6.5077 - val_acc: 0.2472\n",
            "Epoch 994/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0176 - acc: 0.9949 - val_loss: 6.5038 - val_acc: 0.2144\n",
            "Epoch 995/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0154 - acc: 0.9962 - val_loss: 6.4658 - val_acc: 0.2104\n",
            "Epoch 996/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0128 - acc: 0.9965 - val_loss: 6.5703 - val_acc: 0.2288\n",
            "Epoch 997/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0152 - acc: 0.9964 - val_loss: 6.3558 - val_acc: 0.2464\n",
            "Epoch 998/1000\n",
            "22500/22500 [==============================] - 2s 85us/step - loss: 0.0133 - acc: 0.9963 - val_loss: 6.3592 - val_acc: 0.2356\n",
            "Epoch 999/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0100 - acc: 0.9973 - val_loss: 6.0607 - val_acc: 0.2460\n",
            "Epoch 1000/1000\n",
            "22500/22500 [==============================] - 2s 86us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 6.5132 - val_acc: 0.2344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fV5IZOGxGtEq",
        "colab_type": "code",
        "outputId": "1d7f90db-901f-43fe-bdee-1867e6c3c7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                       batch_size=100, verbose=1)\n",
        "print('Test accuracy:', score[1]) #всё ещё мало, но уже лучше. Видимо, нужно было взять эмбеддинги большего объёма или большей размерности."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 31us/step\n",
            "Test accuracy: 0.24791999965906142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QNX4_J4fisoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Results"
      ]
    },
    {
      "metadata": {
        "id": "kVxY1wkTosow",
        "colab_type": "code",
        "outputId": "cb8f068a-aa7e-48e9-c804-946fcf7837fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#посмотрим на результаты\n",
        "\n",
        "y_test = encoder.inverse_transform(y_test)\n",
        "y_pred = encoder.inverse_transform(y_pred)\n",
        "\n",
        "print('True:', y_test[:10])\n",
        "print('Predicted:', y_pred[:10]) #выбивается из ряда 10 с предсказанным значением 4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True: [ 9 10  9 10  9  8  9  8  9 10]\n",
            "Predicted: [10  8  4 10  8  8  7 10  7 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cb_9HJdGLh0T",
        "colab_type": "code",
        "outputId": "455242ea-b8c6-4de5-94af-aaa52d7a3e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        }
      },
      "cell_type": "code",
      "source": [
        "#построим матрицу ошибок\n",
        "\n",
        "classes = [1, 2, 3, 4, 7, 8, 9, 10]\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
        "\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(8)\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAM9CAYAAABZqnZLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEx5JkiRJxfp/vc4fWJeuFlAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wS78f1UTNipR",
        "colab_type": "code",
        "outputId": "9365ecc0-842e-4db2-f3d8-4b497e5211ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#попробуем классифицировать новый текст\n",
        "\n",
        "new_text = \"\"\"What a unique production! Netflix definitely got something (very) right here. In fact, I wish there would be more quality content like this.\n",
        "Every single episode is intriguing and spectacular; it can be very violent at times, funny and sad. The art is just breathtaking. Writing is on point.\n",
        "So far I liked \"Sonnie's Edge\", \"The Witness\" and \"Beyond the Aquila Rift, \"Good Hunting\" and \"Zima Blue\" the best. More, please, Netflix!\"\"\"\n",
        "#источник -- https://www.imdb.com/review/rw4723901 , рейтинг -- 10\n",
        "x_new = pad_sequences([text_to_sequence(tokenizer.tokenize(new_text), vocab, vocab_size)], maxlen=100, padding='post')\n",
        "cl_new = model.predict_classes(x_new)[0]\n",
        "print(classes[cl_new])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ej5UsYDSrJFS",
        "colab_type": "code",
        "outputId": "5345bfbc-277b-4830-ad17-e4fd52d1754c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "new_text = \"\"\"If nobody does, I will. After the critically panned Date Movie, Epic Movie, and Meet the Spartans, these two assholes decide to make another. It's the same formula, they make fun of popular movies in a tired, unfunny fashion.\n",
        "I saw it with a few friends, hoping maybe I could get maybe one or two laughs out of it (I didn't expect anything). When I came out, I was seriously stunned at how lame the movie was. One friend actually liked it, all I had to say was, \"What have you been smoking lately?\".\n",
        "I'm not even going to bother explaining the plot, since there really isn't a plot at all. All I can say is, don't waste your money watching the film. It contains no genuinely funny humor and is one of the worst movies ever made. And everyone thought Meet the Spartans bad, wait until they get a load of this one.\"\"\"\n",
        "#источник -- https://www.imdb.com/review/rw1938122 , рейтинг -- 1\n",
        "x_new = pad_sequences([text_to_sequence(tokenizer.tokenize(new_text), vocab, vocab_size)], maxlen=100, padding='post')\n",
        "cl_new = model.predict_classes(x_new)[0]\n",
        "print(classes[cl_new])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7JPW9iw669aY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
        "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
        "636-659. \\\\\n",
        "* Learning Word Vectors for Sentiment Analysis\n",
        "Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts\n",
        "Stanford University,\n",
        "Stanford, CA 94305\n",
        "* Howard J., Ruder S. (2018) Universal Language Model Fine-tuning for Text Classification\n",
        "* http://ai.stanford.edu/~amaas/data/sentiment/index.html\n",
        "* https://github.com/stanfordnlp/GloVe"
      ]
    },
    {
      "metadata": {
        "id": "1rE5R7-NLTS9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}